---
title             : "How social contexts shape active learning"
shorttitle        : "Active learning is social"

author: 
  - name          : "Kyle MacDonald"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Stanford University"

author_note: |
  Conceptual Analysis of Dissertation Area. 
  
  Readers: Michael C. Frank, Hyowon Gweon, and Anne Fernald

abstract: |
  Children's rapid conceptual development is one of the more remarkable features of human cognition. How do they learn so much so quickly? Social learning theories argue for the importance of learning from rich input provided by more knowledgeable others. In contrast, active learning accounts focus on children's efficient information seeking skills as a path to knowledge acquisition. In this paper, I suggest that an important step towards a complete theory of early learning is to understand how active learning unfolds within social contexts. To integrate the two accounts, I use the theory of Optimal Experiment Design (OED), which formalizes human inquiry as a decision process that maximizes expected utility with respect to the goal of gaining new information. I argue that this integration allows for recent insights into children's social learning to increase our understanding of how children make information gathering decisions.
  
keywords          : "active learning, social learning, decision making, optimal experiment design, theory"
wordcount         : "X"

bibliography      : ["cada_library.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no

lang              : "english"
class             : "man"
header-includes   :
  - \usepackage{afterpage}
linkcolor         : blue
urlcolor          : blue
output            : 
  papaja::apa6_pdf:
    toc: true
    toc_depth: 2
---

```{r load_packages, include = FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo=F, warning=F, cache=T, message=F, sanitize=T)
library("papaja")
library(knitr); library(tidyverse); library(spelling); library(xtable)
```
\newpage

# Introduction 

Human learning is remarkable. Consider that children, despite limitations on general processing capabilities, acquire new lexical concepts at a high rate, eventually reaching an adult vocabulary ranging from 50,000 to 100,000 words [@bloom2002children]. And they accomplish this all while also developing motor skills, learning social norms, and building causal knowledge. How do we explain children's prodigious learning abilities?  

Social learning accounts point out that children do not solve these problems on their own. Instead, children are typically surrounded by parents, other knowledgeable adults, or older peers -- all of whom are likely ot know more than they do and are want to facilitate their learning. Social learning accounts also emphasize how social contexts can bootstrap children's learning via several mechanisms. For example, work on early language acquisition shows that social partners provide input that is tuned to children's cognitive abilities [@fernald1987acoustic; @eaves2016infant], that guides children's attention to important features in the world [@yu2007unified], and that increases levels of sustained attention, which results in better learning [@yu2016social; @kuhl2007speech]. 

Social contexts also change the computations (i.e., inferences) that support children's learning from evidence. Recent work in the fields of concept learning and causal intervention suggests that the presence of another person engages a set of psychological processes where the learner reasons about *why* other people performed specific actions. The critical insight comes from knowing that another person intentionally selected examples, allowing children to make stronger inferences that speed learning [@frank2009using; @bonawitz2016computational; @shafto2014rational]. For example, children learn at different rates after observing the same evidence depending on whether they thought the behavior was accidental (less informative) or intentional (more informative). Moreover, adults and children will make even stronger inferences if they believe that another person selected their actions with the goal of helping them learn (i.e., teaching) [@shafto2012learning].

However, children are not passive recipients of information -- from people or the world. Instead, children actively select behaviors -- for example, asking questions or choosing where to allocate visual attention -- that change the content, pacing, and sequence of their learning experience. Recent theories of cognitive development have proposed the metaphor of "child as an intuitive scientist" and characterized early learning as a process of exploration and hypothesis testing following principles of the scientific method [@gopnik1999scientist; @schulz2012origins]. Moreover, recent empirical work across a variety of domains -- education [@grabinger1995rich], machine learning [@settles2012active; @castro2009human], and cognitive science [@markant2014better] -- has directly compared learning trajectories in contexts marked by self-directed choice (active learning) as compared to settings where the learner has less control (passive learning). The upshot of this work is that active contexts often lead to faster learning rates by enhancing attention and arousal or by providing learners with better information that is linked to their current goals, beliefs, and interests (see @gureckis2012self for a review). 

Thus, children are capable of guiding their own learning and social contexts provide particularly good learning environments. But how can we integrate these two proposals? Answering this question represents a significant step towards a complete theory of early learning since children's cognitive development often unfolds within social contexts and learners must integrate this social information when making decisions about what to learn. 

In this paper, I propose an integrative account of active learning within social contexts. I use the framework of Optimal Experiment Design [@emery1998optimal; @lindley1956measure] as a conceptual tool to bring social learning processes into contact with the underlying decision making that supports active learning. The key insight is that learning in the presence of other people plays a direct role in determining the *usefulness* of different actions. I organized the paper as follows. First, I define  "active" and "social" learning to provide limits on the scope of phenomena that the integrative account aims to address. Then, I review the behavioral evidence showing that social ([Part I](#p1)) and active ([Part II](#p2)) contexts change how learning unfolds. From there I present the theory of Optimal Experiment Design (OED) ([Part III](#p3)) as a formal framework for understanding the decision-making process that supports active learning. Finally, I conclude by highlighting a series of novel links between the social learning account and self-directed choice, taking a step towards understanding how active learning unfolds within social contexts ([Part IV](#p4)).

# The scope of the integrative account

Many theories of cognitive development have considered the relative contributions of "active" learning and "social" input to children's cognitive development. As a result, the terms are semantically "overloaded." So before reviewing the empirical evidence, it is worth defining "active learning" and "social contexts." I also want to scope the behaviors that the integrative account attempts to explain and highlight several distinctions that come up throughout the paper, including the different *timescales* through which social contexts affect active learning and the importance of others' *goals* for explaining social learning phenomena. 

Learning can be "active" in a variety of ways. First, a child could be physically active, and this movement could change what information they extract from the experience. There is a large body of research that explores the effects of action experience on infants' learning (see @kontra2012embodied for a review of work on embodied cognition). One classic example from @needham2002pick shows that infants who physically hold and manipulate objects will outperform a control group on measures of object attention and exploration. Second, active learning could refer to children's contribution to processing incoming information. For example, young learners do not just passively accept other people's claims and will reject answers that conflict with their knowledge [@pea1982origins]. Third, children might engage in self-generated "active" explanations. @lombrozo2006structure review evidence that 'self-explanation'can lead to better learning. Finally, active learning could refer to a decision-making process where children select, sequence, and pace their own learning experiences.

Here, I focus on active learning effects that arise via decision making. The key assumption is that active learners are trying to maximize the usefulness of their actions when choosing to gather information. By scoping the account to information seeking *decisions*, I do not aim to ignore the importance of other forms of active learning; instead, my goal is to constrain the space of possible connections between the active and social learning theories. Moreover, decisions during active learning still capture a rich set of behaviors, including pointing, eye movements, verbal question asking, and causal interventions. 

Learning can also be "social" in a variety of ways. First, children could learn with another person present but without attending to or directly interacting with them. Research in social psychology shows that the mere presence of other people can facilitate performance of simple tasks and impair the performance of complex tasks [@uziel2007individual; @cottrell1968social]. Second, children could learn by looking to others as a guide, observing or imitating their behavior. In fact, children's capacity for faithful imitation is a critical feature separating human from non-human learning [@call2005copying]. Finally, children could both attend to the person and directly interact with them, entering a communicative learning context that engages powerful psychological reasoning processes that change learning. 

In this paper, I define a "social context" as a learning environment where another agent is present. This definition includes all of the social learning behaviors -- observation, imitation, and learning from direct interaction -- discussed above. I use this broad definition to highlight the diverse ways that social contexts could shape children's decisions during learning. It is important to point out that the effects of social input could operate on at least three timescales: (1)  in-the-moment (e.g., imitating another person), (2)  over development (e.g., prior social input shaping current decisions), and (3) over cultural/evolutionary history (e.g., learning 
a conventionalized language system). This paper does not focus on timescales, but in particular sections, I highlight when they are relevant to the discussion. 

In sum, the goal of this paper is to propose an integrative account of active learning within social contexts. I chose a specific definition of active learning -- choices to seek information -- and I will show that a range of social learning phenomena could shape these decisions. Before presenting the integrative account, I review evidence that both social and active learning (a) modulate processes such as attention and memory, (b) provide information that is particularly "good" for learning, and (c) change the strength of children's inferences and generalization.

# Part I: Learning from other people {#p1}

Social learning theories argue that children's rapid conceptual development is facilitated by the uniquely human capacity to transmit and acquire information from other people. A primary benefit of learning from others is that children gain access to knowledge that has accumulated over many generations; information that would be far too complex for any individual to figure out on their own [@boyd2011cultural]. In addition to the cumulative effects, social contexts facilitate in-the-moment learning since more knowledgeable others can select input that is most useful for children's learning [@shafto2012learning; @kline2015learn] and information that is likely to generalize beyond the current context [@csibra2009natural].

There is a large body of empirical work on social learning across a variety of domains, e.g., language acquisition, causal learning, and concept learning. Importantly, these social learning effects operate through different pathways such as guiding attention, providing better information, and changing the strength of children's inferences. In this section, I briefly review the evidence for each pathway, with the goal of providing a high-level taxonomy of social learning effects. 

## Social contexts enhance attention and memory

From infancy humans preferentially attend to social information. For example, newborn infants prefer to look at face-like patterns compared to other abstract configurations [@johnson1991newborns] and even show a preference for faces that make direct eye contact compared to faces that avert gaze [@farroni2002eye]. In the auditory domain, newborns prefer to listen to speech over non-speech [@vouloumanos2007listening], their mother's voice over strangers' voices [@decasper1987human], and infant-directed speech over adult-directed speech [@cooper1990preference; @pegg1992preference; @fernald1987acoustic]. Moreover, recent work by @yu2016social, using head-mounted eye trackers to record parent-child interactions, shows that one-year-olds will sustain visual attention to an object longer when their parents had previously looked at that object.

These early attentional biases lead to differential learning in the presence of another person. For example, 4-month-olds show better memory for faces if that face gazed directly at them as compared to memory for a face with averted gaze  [@farroni2007direct]. They also show enhanced memory for objects if an adult gazed at that object during learning [@reid2005adult; @cleveland2007joint]. Converging evidence comes from @thiessen2005infant's work, showing that 7-month-olds perform better at word segmentation from infant-directed speech compared to adult-directed speech.

@kuhl2007speech refer to these effects as "social gating" phenomena since the presence of another person activates or enhances children's underlying computational learning mechanisms. One particularly striking piece of evidence for the social gating hypothesis comes from @kuhl2003foreign study of infants' foreign-language phonetic learning. In this experiment, 9- to 10-month-old English-learning infants listened to Mandarin speakers either via live interactions or audiovisual recordings. Only the infants who heard Mandarin within social interactions were able to discriminate Mandarin-specific phonemes. In contrast, infants in the audiovisual recording condition showed no evidence of learning the phonemes despite similar amounts of exposure. @kuhl2003foreign also found that infants in the social interaction condition had higher rates of visual attention to the speaker, suggesting that the social context enhanced learning by increasing children's attention to the input.
 
Additional evidence comes from studies showing that when adults interact with an avatar controlled by a person rather than a computer, they experience higher levels of arousal, learn more, and pay more attention [@okita2008mere]. And recent work by @roseberry2014skype found that children learn equally well from interactions with a person in a video chat (e.g., Skype) if they established social contingency, but they did not learn from watching communication between an adult and another child.

The common thread across this work is that the presence of another person increases attention. And as a result, social input becomes more salient and more likely to come into contact with general learning mechanisms. These changes occur within the child (endogenous effects) and in-the-moment of learning. However, social contexts can also provide better information, leading to exogenous effects on learning. In fact, social learning theories often start from the premise that early environments are unique because children are surrounded by people who know more than they do. Moreover, these individuals are invested in children's learning. Together, these features lead to contexts where more knowledgeable others select learning experiences that are particularly beneficial.

## Social contexts provide "good" information

The idea that children's input might be shaped to facilitate their learning is a fundamental aspect of several theories of cognitive development [e.g., Zone of Proximal Development [@vygotsky1987zone], Guided Participation [@rogoff1993guided], and Natural Pedagogy [@csibra2009natural]]. But how do social environments provide useful information? 

One compelling set of evidence is that caregivers alter their communication style when speaking to children. Empirical work shows that when adults talk to children, they exaggerate prosody, reduce speed, shorten utterances, and elevate both pitch and affect (for a review, see @fernald1984expanded). Subsequent empirical work shows that these features can help infants solve a variety of language acquisition challenges, including vowel learning [@adriaans2017prosodic; @de2003investigating], word segmentation [@fernald1991prosody; @thiessen2005infant], word recognition [@singh2009influences], and word learning [@graf2013infant]. 

Additional evidence that social contexts provide information tuned to individual learners comes from work on infants' early vocal production. For example, @goldstein2008social measured whether infants modified their babbling to produce more speech-like sounds after interacting with caregivers who provided either contingent or non-contingent responses to their babbling. Only infants in the contingent feedback condition changed their vocalization behavior to produce more adult-like language forms. @goldstein2008social hypothesized that the contingent input was particularly useful because it occurred soon after infants' vocalizations, making it easier to compare any discrepancies. 

Converging support comes from research on children's early word learning. Social-pragmatic theories of language acquisition have long emphasized the importance of social cues for reducing referential uncertainty [@bloom2002children; @clark2009first; @hollich2000breaking]. Empirical work by @yu2012embodied shows that young learners tend to retain words that are accompanied by clear referential cues (e.g., adults' pointing and gaze direction), which serve to make a single object dominant in the visual field  [@yu2013joint; @yu2005role]. Moreover, correlational studies show positive links between early vocabulary development and parents' tendency to refer to objects that children are already attending to (i.e., "follow-in" labeling) [@tomasello1986joint].

Together, these findings provide evidence that social contexts are likely to contain "useful" information. Similar to the attention/memory effects, these effects occur in-the-moment of learning. However, they are properties of the input, and their usefulness is derived from processes external to the learner, but internal to the learner's social partner (e.g., an adult reading the child's direction of gaze and providing a label).  Social contexts also shape learning by engaging a sophisticated set of social reasoning processes that change how much children learn from new evidence.

## Social contexts shape inferences and generalization

One defining feature of social learning is that people's actions are not random. Instead, people select behaviors with respect to some goal (e.g., to communicate a concept). If children are sensitive to others' goal-directed behavior, then they can reason about *why* someone chose an action. And this reasoning process can change how people interpret superficially similar behaviors.

Recent empirical and modeling work has formalized this social reasoning process within the framework of Bayesian models of cognition [@shafto2012learning; @frank2014inferring; @goodman2016pragmatic]. Under this account, social learning is a process of belief updating that depends on two factors: the learner 's beliefs before seeing any evidence and what the learner thinks about the process that generated the evidence. If the learner assumes that someone selects an action with the intention to communicate, they can make "stronger" inferences. ^[Formally, these models change the likelihood term in Bayes theorem to capture a person’s theory of how data are generated. I will discuss  links between this formalization and the active learning account in [Part IV](#p4).]

For example, @goodman2009cause presented adults with written descriptions of the following causal learning scenarios. Someone generates a causal effect (e.g., growing flowers) by performing two actions at the same time (e.g., pouring a yellow liquid and a blue liquid). The person who generated the effect was either the participant or another person who already knew the causal structure. The participants' task was to identify the correct causal structure. When participants thought the other person was knowledgeable, they were more likely to think that performing *both* actions was necessary. In contrast, when the participant-generated the causal effect on their own (not knowing the causal structure), adults were less sure that both actions were necessary. @shafto2012learning interpreted these results as a psychological reasoning process such as: "if the other person were knowledgeable and wanted to generate the effect, then he would perform both actions." This finding also suggests that learners assume that others' goal-directed behaviors will be efficient and they should avoid performing unnecessary actions (e.g., pressing two buttons when pressing one would have been sufficient). 

Similar effects of psychological reasoning on inference occur in word learning [@xu2007word; @frank2014inferring], selective trust in testimony [@shafto2012epistemic], tool use [@sage2011disentangling], and concept learning [@shafto2014rational]. Moreover, there is evidence that even young learners' inferences are sensitive to the presence of goal-directed behaviors. For example, @yoon2008communication showed that 8-month-olds encode an object's identity if attention was directed by a communicative point, but they will encode an object's spatial location if attention was directed by a non-communicative reach. And @senju2008gaze found that infants will follow another person's gaze only if the gaze event was preceded by relevant, communicative cues (e.g., infant-directed speech or direct eye contact). 

In addition to being easier to learn, information from other people is more likely to generalize beyond the current learning context. @csibra2009natural argue that an assumption of *generalizability* is fundamental to "Natural Pedagogy" -- a uniquely human communication system that allows adults to pass cultural knowledge to children. In these contexts, adults generate ostensive signals such as direct gaze, infant-directed speech, and infant-directed actions. These signals, in turn, direct infants' attention towards the adult, and bias infants to expect generalizable information.

Experimental work testing predictions of Natural Pedagogy shows that children tend to think that information presented in communicative contexts is generalizable [@yoon2008communication; @butler2012preschoolers]. For example,  @butler2012preschoolers showed that preschoolers were more likely to expect a novel causal property (e.g., magnetism) to generalize to new objects with the same shape if the causal property was demonstrated with pedagogical cues. Moreover, corpus analyses show that generic language (e.g., "birds fly") is common in everyday adult-child conversations [@gelman2008generic], suggesting that this generalizable information is prevalent in children's daily experience.

Across these studies, learners interpreted similar information in different ways depending on their assumptions about others' goals. These effects are different from the attentional (internal to the learner) and informational (external to the learner) explanations reviewed above in that the inferences based on social information are part of the underlying computations that support learning. However, parallel to Kuhl's Social Gating account, Natural Pedagogy argues that the presence of pedagogical cues enhances processes internal to the learner such as attention. These theories and empirical work receive additional support from evolutionary models that emphasize the importance of pedagogy for the accumulation of human cultural knowledge [@kline2015learn; @boyd2011cultural].

## Social learning summary

The work on social learning reviewed in this section highlight several points. First, from an early age, children are surrounded by other people who know more than they do. Moreover, these more knowledgeable agents are invested in children's development and motivated to provide good learning opportunities. Second, children are driven to interact with other people, and these interactions are engaging and social partners guide attention to relevant information. Finally, social learning triggers a set of psychological reasoning mechanisms that build off children's capacity for detecting goal-directed behavior. Critically, the output of this reasoning is stronger inferences, allowing children to get more information out of the same amount of input. 

However, it is clear that social input cannot account for all of children's rapid conceptual development, and that children are not just passive recipients of input from the world or other people. Instead, they actively process information and select behaviors that change what they learn. A parallel body of research on this topic -- under the umbrella term of "active learning" -- has developed alongside social learning theories. In the next section, I present the active learning account and the empirical work with the goal of clarifying the variety of ways that children shape their learning.



\afterpage{
```{r table1, results = "asis"}
learning_type_table <- read_csv(file = "tables/active_social_overview.csv", trim_ws = T)
bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(xtable(learning_type_table,
             align = c('l', 'p{1.5in}', '|', 'p{2in}', '|', 'p{2in}'),
             label = "act_soc",
             caption = "High level summary of three different paths through which active and social contexts influence learning. See Part I (social learning) and Part 2 (active learning) for more details and reviews of the behavioral evidence."
             ),
      include.rownames=FALSE, 
      hline.after=c(0,1,2,3),
      sanitize.text.function=function(x){x},
      sanitize.colnames.function=bold,
      caption.placement = 'top', 
      table.placement = "tb",
      comment = F)
```
\clearpage
}

# Part II: Learning on your own {#p2}

The idea that children are "active" learners has also been an influential aspect of classic theories of cognitive development [e.g., @bruner1961act; @berlyne1960conflict]. Recent theorizing has characterized cognitive development as a process of active hypothesis testing and theory revision following the principles of scientific inquiry [@schulz2012origins; @gopnik1999scientist]. Under this account, children drive their conceptual development by selecting actions to test theories about how the world works.

The effects of active learning have also been the focus of much empirical work in education [@grabinger1995rich; @prince2004does], machine learning [@settles2012active; @ramirez2017active], and cognitive psychology [@castro2009human; @chi2009active]. The common thread across these diverse bodies of work is that active contexts -- where people have control over their experience -- lead to different (and often more rapid) learning outcomes when compared to passive contexts where people do not have control over the flow of information. 

But how does active control change the way people learn? In this section, I present evidence for three mechanisms. These pathways parallel the social learning effects reviewed in [Part I](#p1). First, active learning contexts enhance attention and memory, leading to stronger learning. Second, active learners use their uncertainty to select experiences that cater to their goals, beliefs, and capabilities. Third, active learning results in weaker inferences and generalization since there is no guarantee that self-generated examples will be informative.  I conclude [Part II](#p2) with a discussion of why active learning might be particularly challenging to study. These challenges motivate the formalization of human inquiry as Optimal Experiment Design that I present in [Part III](#p3).

## Active contexts enhances attention and memory

A growing body of research shows that active control changes processes such as attention and arousal that support learning.  In these experiments, researchers have compared learning outcomes for active and passive contexts across a variety of tasks such as episodic memory, casual intervention, and concept learning. The common finding is that active contexts result in faster and more robust learning. In a review of this literature, @markant2016enhanced propose that increased attention and memory drives the active learning advantage, with the precise effect determined by the type of control given to the learner (e.g., timing,  content, timing & content). ^[For example, consider a child who is playing with a set of toys and turns to ask their parent, "What's this?" Here, the child is in control of both the selection (which toy gets labeled) and the timing (when the labeling event occurs) of information.]  

One compelling demonstration of the effects of different types of control comes from @markant2014deconstructing where they "deconstructed" the active learning process. Participants memorized the identities and locations of objects hidden in a grid. @markant2014deconstructing varied the *level* of control that participants had over the learning experience. Participants could control either: (1) the next location in the grid, (2) which item to reveal next, (3) the duration of each learning trial, and/or (4) the time between learning trials (i.e., inter-stimulus-interval or ISI). There was also a "yoked"  control group of participants who saw the training data generated by the active learners. The yoked condition is critical for equating the informational content across learners while varying the level of control. There was an advantage in spatial memory for all levels of control, including the lowest amount in the ISI-only condition. These results suggest that learners benefitted from being able to coordinate the timing of information with their attentional processes, starting the next trial after they finished processing the previous one and once they were ready to learn something new.

Developmental studies have also used the deconstructing approach and found parallel active learning advantages for 6- to 8-year-olds in a spatial memory task [@ruggeri2016active]. Other work has found similar benefits in word learning (@partridge2015young; see also @kachergis2013actively for evidence in adults) and understanding causal structures [@schulz2012origins]. For example, @sobel2006importance showed that preschoolers who generated interventions on a causal system learned more compared to yoked participants who either passively observed the same sequence of actions or re-created the same choices made by others (but see @mccormack2016children). Moreover, even infants benefit from active engagement with the learning environment. For example, @begus2014infants found that 16-month-olds show better memory for information provided about an object they had demonstrated an interest in via pointing compared to an object that infants had previously ignored.

Additional evidence that active control enhances attention and memory comes from research on children's engagement with educational technology (for a review, see @hirsh2015putting). For example, @calvert2005control exposed preschool-aged children to two sessions of reading a computer storybook with an adult and manipulated whether the adult or the child controlled the mouse and could advance the story. Children in the adult-control condition showed a decrease in attention to the storybook materials in the second session. In contrast, children who were given control maintained a constant level of engagement across both sessions, suggesting that active control provided a buffer against children losing interest in a repetitive task.

These results parallel the findings on attention/memory effects in social learning reviewed in [Part I](#p1). Both active and social processes can modulate processes internal to the learner to facilitate in-the-moment learning. However, the effects of active control go beyond changing lower-level cognitive processes and modulate the *quality of information* that learners get from the world.  

## Active contexts provide "good" information

One defining feature of active learning is that people gather information that is useful for their development. This benefit arises because the learner has privileged access to their prior knowledge and current hypotheses, which they leverage to create more helpful learning contexts (e.g., asking a question about something that is particularly confusing). Research on this aspect of active learning focuses on how learners select actions to generate useful information, often comparing learning outcomes to passive contexts where the learner does not have control over the environment. 

For example, @castro2009human directly compared adults' category learning in active vs. passive contexts to predictions from statistical learning theory to quantify any difference in human performance relative to the optimal model predictions. Participants saw a sequence of 3-D objects on a computer screen that varied along a single, continuous dimension (spiky to smooth) and were given feedback as to which category the stimulus belonged to. The participants' task was to learn the correct category boundary. In the active condition, learners could select which object they wanted to be labeled; whereas, in the passive condition, participants saw stimuli generated randomly from the correct categories. Active learning was always superior to passive learning with participants learning the category structure in less time and achieving higher levels of accuracy. However, human learners did not reach the performance of the optimal model, and the advantage for active over passive learning decreased in the more difficult (i.e., noisier) learning tasks. 

Using a similar approach, @markant2014better investigated the effects of active vs. passive hypothesis testing on the rate of adults’ category learning. They varied the difficulty of the learning task by testing two different types of category structures: a rule-based category, which differed along a single dimension (easier to learn), and an information-integration category, which varied along two dimensions (harder to learn). In the active condition, the learner could choose specific observations to test their beliefs; whereas, in the passive version, the sequence of data was generated randomly by the experiment. @markant2014better also included a "yoked" condition where participants saw sequences of observations created by active learners but did not have control over the sequence. Similar to the @castro2009human findings, active participants learned the category structure faster and achieved a higher overall accuracy rate compared to the passive learners and the yoked-passive learners. @markant2014better suggest that active learning was better because self-generated observations are linked to the learner's hypothesis. Importantly, the advantage for active learners over the yoked participants suggests that the information value was linked to the individual learner. Also, the active learning advantage only held for the less complex, rule-based category.

The effects of active engagement also show up in studies of language use. For example, @schober1989understanding asked pairs of adults to complete a task where one person (the director) used natural language to inform another person (the matcher) what order to arrange tangrams (geometric objects, called tans, which are put together to form shapes) in a 4x4 matrix. The matcher had a different level of control depending on condition assignment: (1) could actively participate (i.e., talk to the director), (2) could listen to the recorded conversation of director-matcher and pause the tape, and (3) could listen to the entire discussion but not pause the tape. Results showed that active participation led to a marked advantage over passive listening. Interestingly, the ability to stop the tape did not improve accuracy, suggesting that the active advantage was caused by informational value and not by control over the timing/ pacing of information. Also, participants in the passive conditions reported frustration (e.g., "I don't know what 'this one' means!) with being unable to correct early failures of understanding the novel conventions developed by the director. Thus, no amount of control over timing could make up for the lack of control over the information *content* in the overhearing conditions. @schober1989understanding propose that conversations are a form of active information gathering about others' intentions, and when people are unable to participate, they lose access to critical information that supports later comprehension.

These findings illustrate several points. First, the quality of active exploration was fundamentally linked to the learner's understanding of the task: if the representation was weak, then self-directed learning was less useful.  Second, the benefits of active control were tied to the individual learner's prior knowledge and current hypotheses such that the same sequence of data did not provide "good" information for another person. And third, the benefits of active learning diminished with increased task difficulty because learners struggled to generate helpful examples. These challenges will come up again in [Part III](#p3) when I outline the formalization of human inquiry.

### Can children select "good" information?

Research on children's pointing shows that young learners, who are not yet capable of more sophisticated information seeking behaviors such as verbal questions, can use nonverbal actions to facilitate learning. For example, @wu2015caregivers found that adults generate a higher number of object labels for objects that their 12-month-olds pointed to, suggesting that the infants' pointing elicited information that was especially useful for concrete word learning (for converging evidence, see @kishimoto2007pointing; @goldin2007young; and @olson2011infants). Moreover, work by @begus2012infant found that infants point more in the presence of a knowledgeable person compared to an incompetent person, suggesting that points signal a desire to learn as opposed to sharing attention. Finally, infants who produce more pointing gestures have larger vocabularies later in development [@rowe2009early], providing additional evidence that even young infants are capable of generating actions that elicit information to support learning. 

Later in development, when children being to acquire the requisite productive language skills, they start asking verbal questions to gather information. For example, in a corpus analysis of four children's parent-child conversations, @chouinard2007children found that children begin asking questions early in development (18 months) and at an impressive rate, ranging from 70-198 questions per hour of conversation. @chouinard2007children also coded the children's intent, finding that 71% of questions were to gather information, as opposed to seeking attention or clarification. Other corpus analyses provide converging evidence that questions are common in parent-child conversations [@davis1932form] and that children use them to gather knowledge [@bova2013investigating], persisting when they do not receive a satisfactory explanation [@frazier2009preschoolers]. 

Perhaps the most robust evidence that children are capable of efficient self-directed learning comes from research on causal learning. In these studies, children see a novel toy with an unknown causal structure. Then they play (design experiments) to figure out how the toy works. A nice feature of these tasks is that the space of possible actions and hypotheses are constrained such that it becomes possible to quantify the usefulness of children's causal interventions and compare them to the predictions of formal models of optimal information seeking (see [Part III](#p3)). Specifically, empirical work has found that preschoolers integrate prior beliefs and evidence to alter how they explore a causal system (e.g., testing a toy to learn the concept of balance-relations) [@bonawitz2012children]. Children spend more time exploring an object for which they saw confounded evidence for its causal structure, i.e., where there was more to be learned [@schulz2007serious]. And children become more efficient in producing causal interventions, as measured by informativeness, as they get older (6-8 years of age) [@mccormack2016children]. 

Moreover, even 8-month-old infants selectively explore objects that violate their prior expectations. @stahl2015observing showed infants events that violated an expectation about objects, either solidity, continuity, or support. They coded the types of actions that infants chose to perform on the objects during subsequent free play. Infants explored differently depending on the type of violation (e.g., banging the object after seeing a violation of solidity). The infants also spent more time playing with objects that violated expectations, and as a result, learned more about them. These results demonstrate an early sensitivity to uncertainty with infants using actions to test specific hypotheses that were linked to their prior experience.

Research on infants' selective visual and auditory attention provides another example of children's effective active learning. These studies start from two assumptions: that children possess limited cognitive resources and that children would benefit by attending to information that is likely to be learned. For example, @kidd2012goldilocks  measured 7- and 8-month-olds' visual attention to a monitor that displayed a sequence of familiar objects (e.g., a toy truck). Within each series, infants saw trials that varied along a continuum from low to high complexity.  Complexity was a measure of how surprising the current object was relative to the previous objects in that sequence. For example, if there were two objects (truck and ball) in a set, and the child saw [Truck-Truck-Truck-Truck] and the next trial was Truck, then this would be low surprisal/complexity. In contrast, if the child had seen the sequence [Truck-Ball-Ball-Ball] and the subsequent trial was a Truck, then this trial would be high surprisal/complexity. Infants looked longest on trials of intermediate complexity, choosing to disengage sooner when the object was either highly predictable or highly surprising. @kidd2014goldilocks extended these results to the auditory domain, showing a similar pattern of increased attention to sequences of intermediate complexity for nonsocial sounds such as a door closing or a train whistle. Kidd and her colleagues interpret these results as infants using prior experience to guide selective attention to find learnable information that is neither too simple (nothing to be gained) nor too complicated (too much to process).

There is also evidence that infants avoid spending time on information that is unlearnable. For example, @gerken2011infants tested whether 17-month-olds would increase attention to a stream of input that consisted of a learnable structure (i.e., Russian feminine words take the endings oj and u, and masculine words take the endings ya and yem) as opposed to a random stream of input without any information to extract (i.e., word endings that are not diagnostic of category structure). Infants dishabituated sooner when listening to the unlearnable stream, suggesting that they were tracking the pace of learning and choosing to stop information gathering if progress was low. 

## Active contexts shape inferences and generalization

Active learning contexts also change the strength of learners' inferences and generalization. In contrast to the social learning effects discussed in Part I, active learners assume "weak" sampling, believing that examples are not generated from the true concept. This assumption, in turn, leads learners to make less-restrictive inferences and generalize more broadly. That is, active learners are aware that there the evidence they generate is not guaranteed to be informative, and they update their beliefs accordingly.

For example, @xu2007sampling tested 4-year-olds and adults' word generalization. In the task, participants learned the correct extension of a novel word after seeing three examples drawn from a set of 30 unfamiliar objects. The set of objects consisted of two basic-level categories (15 objects) and within each of the basic categories, there were three smaller, subordinate categories (5 objects) that varied in color, texture, and orientation. Participants saw three labeled examples from the subordinate category. The critical manipulation was whether the examples were selected by a teacher who knew the correct word extension (social) or by the learner (active) who did not know the appropriate extension. Both adults and children made stronger inferences in the teacher-driven condition, saying that the new word referred to the subordinate category; whereas, in the learner-driven case, children and adults tended to generalize the word to the basic-level. 

@xu2007sampling explain these results as a sensitivity to the process that generated examples. When a knowledgeable teacher produced the labels, there was the good reason to think that the examples were linked to word meaning. Thus it would be surprising to see three examples from the smaller subordinate category. However, the active learners had no reason to think they generated examples from the true category, and therefore they extended the novel word more broadly to the basic-level. The takeaway from work is that even young children appear sensitive to the informativeness of the process that generates examples, and use this information to change how much they update beliefs based on new evidence. 

## Active learning summary

The work on active learning reviewed in this section highlights several points. First, from an early age, children are capable of efficient information seeking. Second, active learning is a complex area of research, covering a wide range of actions (e.g., pointing, visual attention, causal interventions, and verbal questions) and supported by a variety of cognitive processes. Moreover, active learning is by definition linked to the idiosyncrasy of individuals, and thus, does not function similarly across individuals, contexts, and learning domains. Finally, there is a multitude of factors that could influence the quality of children's active learning, creating a broad space of possibilities for researchers to test. 

One way to constrain the space of hypotheses is to use formal models of the information seeking process. One useful approach is to perform an ideal observer analysis [@geisler2003ideal] where a model is created to solve a task using all of the available information in the environment. This model does not include processing constraints such as limited attention or memory, and as a result, only produces errors based on the complexity or uncertainty present in the environment. By ignoring the processing level, these models allow researchers to focus on the structure of the learning task and the information available in the world. Moreover, the "ideal" model performance can then be compared to human behavior to see how much of the available information people use to solve the problem. This approach does not aim to make claims about human optimality; instead, the ideal-observer can be used as a method for scientific progress because it forces researchers to explicitly define the process of active learning as separable, underlying components, which can become the target of research. 

Over the past three decades, researchers in both developmental and cognitive psychology have used the ideal-observer approach to understand human inquiry. Researchers have leveraged formal models of scientific reasoning that fall under the umbrella term Optimal Experiment Design (OED). The original purpose of the OED models was to help scientists select the best experiment from a set of possible experiments, where "best" is defined as the experiment that leads to the highest amount of information gained about the scientific phenomenon. Using this formalization, researchers have asked whether people's information seeking behaviors look qualitatively similar to predictions from OED models. Moreover, this approach has the benefit of using the same mathematical formalization as recent models of social learning: Bayesian ideal observer models [@shafto2012epistemic; @frank2009using; @goodman2016pragmatic]. These parallel formalizations suggest a way forward for integrating the active and social learning theories. This point is a focus of [Part IV](#p4).   

# Part III: A formal account of active learning {#p3}

Optimal Experiment Design (OED) [@emery1998optimal; @nelson2005finding; @lindley1956measure] is a statistical framework for quantifying the "usefulness" of experiments.  @lindley1956measure described the approach as a transition from viewing statistics as binary decision making to a practice of gathering information about the "state of nature" (p. 987). The concrete proposal is to design studies that maximize expected information gain (a measure borrowed from Information Theory and discussed in more detail below) and continue to collect data until the information gained reaches a pre-determined threshold.

The OED approach allows scientists to make design choices that maximize the effectiveness of their experiments, reducing inefficiency and cost. Consider the following toy example borrowed from @ouyang2016practical where a researcher is interested in designing the best experiment to figure out whether people think a coin is fair or biased (i.e., a trick coin). Here the researcher's hypotheses correspond to different models of the coin [$M_{fair}: Bernoulli(p = 0.5)$] and [$M_{bias}: Bernoulli(p)$ where $p \sim Uniform(0,1)$] and the experiments correspond to different sequences of coin flips that she could select as stimuli. Imagine that the researcher has limited time or resources and can only show a sequence of four coin flips, creating a space of 16 possible experiments. An OED model allows the researcher to select the best experiment that maximally differentiates the two hypotheses. For example, OED provides an answer to the question: how much better would it be to use [$HHHH$] versus [$HTHT$]? Here, [$HHHH$] is more informative because both the bias and the fair coin models make the same predictions for the [$HTHT$] experiment, meaning we would not learn much from this test.

An applied example comes from @nelson2010experience where they used an OED model to differentiate competing theories of information seeking during adults' category learning. They created an OED model of their task, which included the design choices (what combination of features to show participants) and the relevant behavioral hypotheses (the different theories of category learning). They used the model to simulate the outcomes of using different stimulus sets, allowing them to choose stimuli for which the competing theories made very different predictions, speeding the rate of discovery.

\afterpage{
```{r fig.pos = "H", out.width="100%", fig.cap = "Schematic of an active causal learning context using the decomposition of Optimal Experiment Design. The learner generates an inquiry goal to learn how the toy works. She then considers hypotheses, including her subjective belief in each, placing stronger belief in the simpler, disjunctive hypotheses: only Button A or Button B. Next, she considers her possible queries (actions) and the potential outcomes if she took those actions. Together, these components quantify the expected usefulness of each action. If the learner chooses optimally, she picks the action that maximizes this expected utility. In this case, she chooses to press either Button A or B, but does not press both buttons since this action would produce confounded evidence and fail to reduce her uncertainty. See Part III in the text for mathematical details of the OED model."}

grid::grid.raster(png::readPNG("../cada_schematic/cada_schematic.001.png"))
```
\clearpage
}

@coenen2017asking provide a thorough review of the OED framework and its links to human information seeking. They outline the four critical parts of an OED model: (1) a set of hypotheses, (2) a set of queries (i.e., actions) to learn about the hypotheses, (3) a way to model the types of answers that each query could elicit, and (4) a way to score each answer with respect to the learning goal. They also highlight the importance of understanding learners' inquiry goals (what do people want to learn?) for engaging OED-like reasoning. The critical point is that without a clear learning goal, it becomes challenging to instantiate the hypotheses, questions, and answers that a learner should consider. In the rest of this section, I provide the mathematical details of the OED approach as described in @coenen2017asking. The goal is to provide a concrete foundation for the conceptual analysis of how social learning contexts can influence different components of active learning. 

The OED model quantifies the *expected utility* of different information seeking actions. Formally, the set of queries is defined as $Q_1, Q_2,..., Q_n = \{Q\}$. The expected utility of each query ($EU(Q)$) is a function of two factors: (1) the probability of obtaining a specific answer $P(a)$ weighted by (2) the usefulness of that answer for achieving the learning goal $U(a)$.

$$EU(Q) = \sum_{a\in q}{P(a)U(a)}$$
\noindent
There are a variety of ways to define the usefulness function to score each answer. An exhaustive review is beyond the scope of this paper (for a detailed analysis of different approaches, see @nelson2005finding). One standard method is to use *information gain*, which is defined as the change in the learner's overall uncertainty (difference in entoropy) before and after receiving an answer.

$$U(a) = ent(H) - ent(H|a)$$

\noindent
Where $ent(H)$ is defined using Shannon entropy ^[Shannon entropy is a measure of unpredictability or amount of uncertainty in the learner's probability distribution over hypotheses. Intuitively, higher entropy distributions are more uncertain and harder to predict. For example, if the learner believes that all hypotheses are equally likely, then they are in a state of high uncertainty/entropy. In contrast, if the learner firmly believes in one hypothesis, then uncertainty/entropy is low.] [@mackay2003information], which provides a measure of the overall amount of uncertainty in the learner's beliefs about the candidate hypotheses. 

$$ent(H) = -\sum_{a\in A}{P(h)log_2P(h)}$$
\noindent
The conditional entropy computation is the same, but takes into account the change in the learner's beliefs after seeing an answer.

$$ ent(H|a) = -\sum_{h\in H}{P(h|a)logP(h|a)} $$
\noindent
To calculate the change in the learner's belief in a hypothesis $P(h|a)$, we use Bayes rule. 

$$ P(h|a) = \frac{P(h)P(a|h)}{P(a)} $$ 

\noindent
If the researcher defines all these parts of the OED model (hypotheses, questions, answers, and the usefulness function), then selecting the optimal query is straightforward. The learner performs the expected utility computation for each query in the set of possible queries and picks the one that maximizes utility. In practice, the learner considers each possible answer, scores the answer with the usefulness function, and weights the score using the probability of getting that answer. 

Before reviewing the behavioral evidence for OED-like reasoning in adults and children, I will present a worked example of how to compute the expected utility of a single query. The goal is to provide simple calculations that illustrate how reasoning about hypotheses, questions, and answers can lead to selecting useful actions. This example is slightly modified from @nelson2005finding. ^[In the [appendix](#app), I include example code for instantiating the OED calculations as functions in the R programming language.] 

Imagine that you are a biologist, and you come across a new animal that you think belongs to one of two species: "glom" or "fizo." You cannot directly query the category identity, but you can gather information about the presence or absence of two features (eats meat? or is nocturnal?) that you know from prior research are more or less likely for each of the species. The following probabilities summarise this prior knowledge:

  * $P(eatsMeat \mid glom) = 0.1$  
  * $P(eatsMeat \mid fizo) = 0.9$
  * $P(nocturnal \mid glom) = 0.3$  
  * $P(nocturnal \mid fizo) = 0.5$. 

\noindent  
You also know from previous research that the probability of seeing a glom or a fizo in the wild is:

  * $P(glom) = 0.7$ 
  * $P(fizo) = 0.3$ 

\noindent  
Which feature should you test: eats meat? or sleeps at night? Intuitively, it seems better to test whether the creature eats meat because an answer to this question provides good evidence about whether the animal is a fizo since $P(eatsMeat \mid fizo) = 0.9$. However, the OED computation allows the biologist to go beyond this intuition and compute precisely how much better it is to ask the "eats meat?" question. All the scientist has to do is pass her knowledge about the hypotheses and features through the expected utility computation. 

Here are the steps of the OED computation for calculating the utility of the "eats meat?" question. First, we use Bayes rule to calculate how much our beliefs would change if we received a "yes" or a "no" answer. ^[Note that the $P(eatsMeat)$ term is computed by taking $P(eatsMeat) = [P(eatsMeat \mid glom) \ times P(glom)] + [P(eatsMeat \mid fizo) \times P(fizo)] = (0.1 \times 0.7) + (0.9 \times 0.3) = 0.34$]

$$ P(glom \mid eatsMeat) = \frac{P(eatsMeat \mid glom) \times P(glom)}{P(eatsMeat)} = \frac{0.1 \times 0.7}{0.34} = 0.21 $$ 

\noindent
Next, we calculate the uncertainty over the Species hypothesis before doing any experiment. We do this by computing the prior entropy.

$$
\begin{aligned}
ent(Species) &= -\sum_{h\in H}{P(h) \times log_2P(h)} \\
 &= [-P(glom) \times log_2P(glom)]+[-P(fizo) \times log_2P(fizo)]\\
 &= [-(0.7 \times log_2(0.7)] + [-(0.3 \times log_2(0.3)]\\
 &= 0.88
\end{aligned}
$$

\noindent
To calculate information gain, we also need to compute our uncertainty over hypotheses conditional on seeing each answer, or the posterior entropy. First, for the "yes" answer:

$$
\begin{aligned}
ent(Species|eatsMeat = yes) &= -\sum_{a\in A}P(Species \mid eatsMeat = yes) \times log_2P(species \mid eatsMeat = yes) \\
&= [0.21 \times log_2(0.21)] + [0.79 \times log_2(0.79)]\\
&=  0.73
\end{aligned}
$$

\noindent
We use the difference between the prior and posterior entropy to compute the utility of the "yes" answer.

$$
\begin{aligned}
U(a = yes) &= ent(Species) - ent(Species \mid eatsMeat = yes)\\
&= 0.88 - 0.73 \\
&= 0.15
\end{aligned}
$$

\noindent
Next, we do the same process for the "no" answer. First, we calculate the posterior entropy.

$$ 
\begin{aligned}
ent(Species|eatsMeat = no) &= -\sum_{a\in A}{P(Species \mid eatsMeat = no) \times log_2P(species \mid eatsMeat = no)}\\
&= [0.95 \times log_2(0.95)] + [0.05 \times log_2(0.05)]\\
&=  0.27
\end{aligned}
$$

\noindent
Again, we use the difference between the prior and posterior entropy to compute the utility of the "no" answer.

$$ 
\begin{aligned}
U(a = no) &= ent(Species) - ent(Species \mid eatsMeat = no)\\
&= 0.88 - 0.27 \\
&= 0.61
\end{aligned}
$$

\noindent
Note that the $U(a = no) > U(a = yes)$. This captures the intuition that learning that the animal does not eat meat would provide strong evidence against the "fizo" hypothesis since $P(eatsMeat \mid fizo) = 0.9$. Finally, to compute the overall expected information gain for the **"eats meat?" question**, we weight the utility of each answer by its probability:

$$
\begin{aligned}
EU(Q = eatsMeat) &= \sum_{a\in A}{P(a)U(a)} \\
&= [P(eatsMeat = yes) \times U(eatsMeat = yes)] + \\& \qquad \qquad \qquad [P(eatsMeat = no) \times U(eatsMeat = no)]\\
&= [0.34 \times 0.15] + [0.66 \times 0.61]\\
&= 0.46
\end{aligned}
$$

If we performed the same steps to calculate the expected utility of the "sleeps at night?" question, we get $EU(Q = sleepsNight) = 0.026$. So if the biologist wants to maximize the chance of gaining useful information, she should select the "eats meat?" experiment since $EU(Q = eatsMeat) > EU(Q = sleepsNight)$.

\afterpage{
```{r fig.pos = "H", out.width="100%",fig.cap = "Schematic of an active word learning context using the decomposition of Optimal Experiment Design. Social input (hearing a novel word) triggers an inquiry goal. Then the learner considers potential hypotheses for the candidate word-object links, weighting each hypothesis by its prior probability. In this case, the learner thinks that the new word is less likely to refer to the familiar object BALL. Next, he considers possible queries (actions) and the potential outcomes of those actions. Note that in the word learning context, the child must direct queries towards a social partner, which provides the learner with more possible queries: both verbal (questions) and nonverbal (eye gaze; pointing). Note that the social partner must interpret the goal of the child's nonverbal queries. If the learner selects the action to maximize expected utility, then he would ask the most informative question, which removes all uncertainty for the meaning of 'dax' -- 'What's that called?' If he does select the relatively less informative action of asking about a single object, he would be unlikely to ask about the familiar object BALL since there is less information to be gained from this query based on his prior beliefs."}

grid::grid.raster(png::readPNG("../cada_schematic/cada_schematic.002.png"))
```
\clearpage
}

### Evidence of OED-like reasoning in human behavior

A growing body of psychological research has used the OED framework as a metaphor for active learning. The idea is that when people make decisions, they engage in a similar process of evaluating the "usefulness" of different actions relative to their learning goals. And they select behaviors that maximize the potential for gaining information. A success of the OED account is that it can capture a wide range of information seeking behaviors, including verbal question asking [@ruggeri2015children], planning interventions in causal learning tasks [@cook2011science], and decisions about where to look during scene understanding [@najemnik2005optimal]. Figures 1 and 2 present schematic overviews of how OED principles could shape the learning process for two of these domains -- causal learning (Figure 1) and word learning (Figure 2).

One compelling use case of OED metaphor as a model of human behavior comes from @nelson2005finding study of eye movements during novel concept learning. Their model combined Bayesian probabilistic learning, which represents current knowledge as a probability distribution over concepts, with an OED model that calculated the usefulness of different patterns of eye movements. Here, eye movements were modeled as a type of question-asking behavior that gathered visual information about the target concept. @nelson2005finding found that participants' eye movements aligned with predictions from the OED model. Specifically, participants changed the dynamics of eye movements depending on how well they learned the target concepts. Early in learning, when the concepts were unfamiliar, the model generated a broader, less efficient distribution of fixations to explore all candidate features that could be used to categorize the stimulus. However, after the model began to learn the target concepts, eye movement patterns shifted to become more efficient and focused on a single stimulus dimension to maximize accuracy. This shift from exploratory to efficient eye movements matched adult performance on the task, suggesting that people's behavior was sensible given the structure of the learning problem and the uncertainty in the context.

Recent developmental work has used OED models to ask whether children are capable of selecting efficient behaviors that maximize learning goals. For example, @legare2013use used a modified question asking game where 4- to 6-year-old children saw 16 cards with a drawing of an animal on them. The animals varied along several dimensions, including type, size, and pattern. Children could ask the experimenter yes/no questions to figure out which animal card was hidden in a box. @legare2013use coded questions as constraint-seeking (narrowing the set of possible cards by gathering information about a particular dimension (e.g., "Is it red?"), confirmatory (questions that provided redundant information), or ineffective that did not provide any useful information (e.g., "Does it have a tail?"). All children produced a high proportion of the more useful, constraint-seeking questions. Moreover, the number of constraint-seeking questions was correlated with accuracy in guessing the identity of the hidden card. @legare2013use interpreted these results as evidence for OED-like reasoning in children's question asking. Other work using the question-game finds that children prefer to direct questions to someone who is knowledgeable compared to someone who is inaccurate or ignorant, providing additional support for the OED hypothesis [@mills2011determining; @mills2010preschoolers].

Another developmental example comes from @cook2011science study of causal learning ^[See Figure 1 for a schematic overview of the active causal learning context according the OED decomposition.]. They showed preschoolers a device that played music when beads were placed on top of it and manipulated the usefulness of different actions that children could take to test the device. Half of the children saw evidence that all types of beads could make the machine work, while the other half learned that only specific types of beads (defined by color) could make it go. Next, children could choose one of two sets of beads to test the machine. In one set the beads were stuck together, in the other, they could be separated. Children who learned that only some of the beads worked were twice as likely to select the separable beads. This finding suggests that children were reasoning about the amount of information they could gain by choosing the detachable beads since this choice would allow them to test each bead independently. In contrast, the children who believed that all beads worked had less to gain by picking the separable set. This result is compelling because it provides evidence that children's were reasoning about a decision (separable vs. stuck together beads) that would influence a future opportunity to generate useful information. 

Although the OED approach has provided a formal account of seemingly unconstrained information seeking behaviors, there are several ways in which it falls short as an explanation of human self-directed learning. @coenen2017asking argue that OED models make several critical assumptions about the learner and the learning task, including (1) the hypotheses/questions/answers under consideration, (2) that people are actually engaging in some expected utility computation in order to maximize the goal of knowledge acquisition, and (3) that the learner has sufficient cognitive capacities to carry out the calculations. 

In the next section, I argue that limitations of the OED approach can be productively reconstrued as opportunities for understanding how learning from other people could scaffold active learning. I focus on integrating research and theory on social learning with five key components of the OED model: inquiry goals, hypotheses, questions, answers, and stopping rules (see Figures 1 and 2 for an overview). The proposal is that learning from more knowledgeable others provides the building blocks for children to engage in effective self-directed learning.

# Part IV: Active learning within social contexts {#p4}

Why is it important to integrate social contexts with active learning? First, children do not re-invent knowledge of the world, and while they can learn a tremendous amount from their behaviors, much of their generalization and abstraction is shaped by input from other people. Also, social learning can sometimes be the only way to learn something. Finally, children are often surrounded by parents, other adults, and older peers – all of whom may know more about the world than they do, creating contexts where the opportunity for social learning is ubiquitous. 

Second, there is a body of empirical work showing that active learning can be biased and ineffective in systematic ways. For example, work by @klahr2004equivalence showed that elementary school-aged children were less effective at discovering the principles of well-controlled experiments from their self-directed learning, but were capable of learning these principles from direct instruction. @markant2014better showed that active exploration provided no benefit over passive input in category learning when there was a mismatch between the target concept and adults' prior hypotheses going into the learning task. And @mccormack2016children found that 6-7 year-olds showed no benefit from active interventions on a causal system compared to observing another person perform the interventions.

In a comprehensive review of the self-directed learning literature, @gureckis2012self point out that the quality of active exploration is linked to aspects of the learner’s understanding of the task: if the representation is weak, then self-directed learning will be biased and ineffective. @coenen2017asking go one step further and propose specific challenges for research on active learning. Here is a sampling of those open questions that are most relevant to this paper:

  *  What triggers inquiry behaviors in the first place?
  *  How do people construct a set of hypotheses?
  *  How do people generate a set of queries?
  *  What makes a "good" answer?
  *  How do people generate and weight possible answers to their queries?
  *  How does learning from answers affect query selection and belief change?

\noindent
In the next section, I propose that theories of social learning accounts can start to address these challenges. I start from the OED model outlined in @coenen2017asking, and use it to integrate social and active learning. The benefit of this formalization is that it makes the different components of active learning explicit, making salient the aspects that might be particularly challenging for young learners. Moreover, I think that we can reconstrue these "challenges" to the OED account as opportunities for understanding the role that other people in children's active learning. In each sub-section, I define the challenge of active learning, discuss how social contexts could address each challenge, and highlight prior research that connects the active and social learning accounts.

## Goals

An inquiry goal refers to the underlying motivation for people's information seeking behaviors. Often this is defined as a search for the correct hypothesis amongst a set of candidate hypotheses. Some examples of plausible inquiry goals that children might hold are:

  * Is this person a reliable source of information? (selective learning)
  * What is this speaker referring to? (word learning)
  * What types of objects are called "daxes"? (category learning)
  * How does this toy work? (causal learning)
  * Where should I look next? (allocation of visual attention)

\noindent
The importance of an explicit inquiry goal is that without a goal, it becomes difficult for the active learner to compare the utilities of different behaviors. That is, the learner cannot evaluate whether an action will lead to learning progress. @coenen2017asking illustrate this point,

> The importance of such goals is made clear by the fact that in experiments designed to evaluate OED principles, participants are usually instructed on the goal of a task and are often incentivized by some monetary reward tied to achieving participants that goal. Similarly, in developmental studies, children are often explicitly asked to answer certain questions, solve a particular problem, or choose between a set of actions. (p. 32-33)

\noindent
Thus, a prerequisite for understanding children's self-directed learning is a way to characterize children's goals. However, this is not trivial since children could consider a range of goals at any moment and there is no guarantee that learning progress be one of them. In fact, one line of theorizing about the OED hypothesis as a model of human inquiry argues that we should only expect to see effective information seeking in contexts where there are precise tasks and learning goals. For example, when a parent gives their child a new toy with several buttons on it and says, "Let's figure out how this toy works!" In this case, it becomes possible to ask whether the child approaches the task efficiently by selecting actions that provide useful information about the toy's causal structure.   

This example illustrates how children's interactions with other people could play a role in triggering inquiry behavior. Both adults and older peers can construct contexts with clear learning goals to support children's information seeking. This connection draws on influential ideas in cognitive development that frame social learning as a form of scaffolding (Zone of Proximal Development [@vygotsky1987zone], Guided Participation [@rogoff1993guided], and Guided Play [@weisberg2013guided]). Under these accounts, adults place children in contexts that present something new to be learned but importantly contain learning goals that are achievable given children's current capabilities. 

One example comes from @weisberg2013guided "guided play" proposal. They define guided play as an intermediate learning context, falling between unstructured free play and constrained direct instruction. The precise boundaries between these contexts are challenging to define, but the critical dimension is the level of control that the adult has over the interaction. @weisberg2013guided present the following example to highlight the difference between guided play and direct instruction:

> For example, a teacher with the goal of teaching new vocabulary words could take a direct instruction approach, by telling children the meanings of the new words they encounter in a storybook or by showing examples: "This is a helmet. A helmet goes on your head to stop your head from getting hurt if you fall off your bike." Or, she could take a guided-play approach, introducing the new words in the context of a child's play episode while encouraging children to think broadly about the word's meaning: "She's got a helmet on while riding her bike. What do you think would happen if she fell off her bike and wasn't wearing her helmet? (p. 106) 

\noindent
While these contexts appear to be quite similar, the key difference is whether the child initiated the activity. In free play, the child drives the interaction; whereas, in direct instruction, the more knowledgeable person explicitly tells the learner what to do, asks questions, and demonstrates new concepts. @weisberg2013guided propose the guided play provides the right combination of structure and opportunity for exploration, leading to better learning.  

One less-emphasized feature of the guided play proposal is the adult's role in establishing a clear learning goal. In the previous example, in the absence of a social partner, it is unclear what goals the child would pursue when playing with the storybook. However, if there is an adult who has knowledge about the book and communicates that she wants to talk about it, then the child can begin to seek information. In the language of the OED framework, the adult creates a context that triggers inquiry goals, which scaffolds children's active learning. See the "goals" panel in Figure 3 for another example of how a social partner could communicate an inquiry goal in a causal learning context.

In addition to communicating goals, the mere presence of other people changes children's tendency to detect whether they understand something. This capacity for monitoring one's uncertainty is a sub-component of metacognition (thinking about thinking) and has been the focus of much developmental research (see @lyons2010metacognitive for a review). The upshot of this work is that while children might be capable of showing behaviors that are sensitive to uncertainty (e.g., selectively exploring an object with ambiguous causal structure), the ability to explicitly access the underlying representation of uncertainty is slower develop. 

The primary evidence for this slow developmental trajectory is children's failures to monitor and verbally report their uncertainty, even when it should be obvious. For example, @markman1979realizing had elementary school aged children read paragraphs containing inconsistent information (e.g., "fish can't see without light, and there's no light at the bottom of the ocean, but some fish at the bottom of the ocean only know their food by its color."). After reading the paragraph, children answered a series of ten questions that gave them the opportunity to ask for clarification about the inconsistencies in the text. Overall, children performed poorly, as @markman1979realizing put it, "even highly motivated children" were unable to detect inconsistencies in the incoming information. However, if the experimenter gave children a warning or a challenge to find a problem with the essay, then they were able to generate more questions, suggesting that they more likely to monitor uncertainty while reading.

While not discussed in these terms, the "warning" manipulation can be reconstrued as an intervention of the social context on children's expectations about incoming information. Perhaps children approached @markman1979realizing's task with the default expectation that the adult would provide complete and helpful information, making it less important to allocate resources to uncertainty monitoring. In fact, the assumption that other people will be helpful is a critical feature of social learning theories, and the empirical work on children's pedagogical sampling assumptions reviewed in [Part I](#p1) provides empirical support. However, when the social context shifts these expections, then children might be more likely to monitor the input for inconsistencies, and in turn, be more likely to generate inquiry goals. 

Converging evidence comes a study by @kim2016young where they measured 3- to 4-year-olds' uncertainty monitoring in contexts where children either did or did not expect to communicate with another person. In the task, children were either knowledgeable or ignorant about which toys an experimenter hid in a box. In the "informing" condition, children had to tell another person about the contents of the box, but they were given the opportunity to "opt-out" of responding if they were unsure ("Max wants to know what’s inside the box. Can you help him? If you do not want to tell him, it’s okay. I can tell him."). In the "explicit" condition, children only reported on their uncertainty. Interestingly, the children who had the potential to inform another person showed higher rates of uncertainty monitoring, opting-out more often when they did not know what was inside the box. Similar to the @markman1979realizing study, the social context shifted children's expectations, making them more likely to detect lack of knowledge. These results also connect with work showing that the process of generating explanations for other people can reveal inconsistencies in understanding [@lombrozo2006structure].

Another interesting effect of social contexts on children's goals comes from work exploring how social input can shape children's implicit theories of intelligence [@dweck1988social]. Implicit theories of intelligence refer to children's internal working models of the world and provide general frameworks for processing information and generating predictions about behavior. @dweck1988social propose a cognitive model where holding different implicit theories of intelligence leads children to adopt different goal orientations, which manifest in different choice behavior during learning. For example, if a child holds the belief that intelligence is malleable (an incremental theory), they will want to increase competence (select a learning goal) and therefore be more likely to choose tasks that facilitate learning. 

Empirical work shows that social partners can directly intervene on children's learning vs. performance goals. For example, @elliott1988goals manipulated elementary school-aged children's goals by presenting them with a choice between one of two tasks described in the following ways:

  * *Performance task*. In this box we have problems of different levels. Some are hard, some are easier. If you pick this box, although you won't learn new things, it will really show me what kids can do.
  * *Learning task*. If you pick the task in this box, you'll probably learn a lot of new things. But you'll probably make a bunch of mistakes, get a little confused, maybe feel a little dumb at times — but eventually you'll learn some useful things.

\noindent
@elliott1988goals found that when the social partener oriented children's towards learning goals, they tended to choose the more difficult task despite being morewere likely to make mistakes and appear incompetent. In another study, @dweck1988social showed that children who already held performance goals viewed effort on a task as an index of ability, whereas children with learning goals viewed effort as a means for improvement. Moreover, both lab-based experiments and observational work provide evidence that the language adults use when praising children can influence whether children adopt an incremental theory, which lead to more inquiry goals [@cimpian2007subtle; @gunderson2013parent]. 

Taken together, the research on implicit theories suggests that social contexts can also communicate the *value* of learning goals relative to other goals that children may pursue.  The @elliott1988goals finding -- that children oriented toward learning goals selected more challenging tasks -- maps onto behaviors that the OED framework aims to characterize. That is, the goal manipulation encouraged children to select actions to make progress on learning. 

Interactions with other people can also introduce other "social" goals that influence children's information seeking. The OED framework only includes informational goals such that the utility of a behavior is determined by whether it results in a reduction of uncertainty. However, empirical and modeling work in other domains has extended the basic information-seeking account to include *situation-specific utility functions* that include goals such as saving time, money, or cognitive resources. For example, @meder2012information designed a series of experiments where "pure" information seeking goals (e.g., maximizing accuracy) were placed at odds with the reward structure of the task. The critical manipulation was the addition of asymmetric rewards for correct and incorrect categorization decisions in a binary classification task. Asymmetric rewards forced the learner to choose the less likely category to earn the highest reward (i.e., they must be willing to forego the goal of being accurate and make mistakes to get the highest score). When these goals were put in conflict, participants' behavior was mixed. Participants only reduced their preference for information seeking and improving accuracy when the asymmetric reward structure was made explicit via task instructions. However, @meder2012information take their results as evidence that people were considered goals other than pure information gain or reward maximization, suggesting the need to consider additional factors when trying to understand what behaviors people think are useful.

One important feature of social contexts is that they engage a process of psychological reasoning about others' mental lives. And once the learner starts thinking about the other person, they could begin to consider an additional set of "social" goals that may conflict with or support their learning goals. Consider the "goals" panel of the schematic active-social learning context shown in Figure 3. If the learner is worried about whether his social partner thinks he is smart, then he might prioritize actions that minimize the chance of making a mistake and perhaps not even attempt to make the toy work. Alternatively, the learner might seek out easy tasks to demonstrate his competence at the expense of choosing actions that help him learn about the world. On the other hand, the child's social partner could explicitly communicate the learning goal using natural language, e.g., "Let's learn how this toy works!" 

Recent advances in modeling pragmatic communication ^[Rational Speech Act (RSA) framework for pragmatic reasoning. The RSA approach models language comprehension and production as, "a process of recursive reasoning about what speakers would have said, given a set of communicative goals" (p.819) [@goodman2016pragmatic]] provide an interesting connection with the situation-specific-utility functions in the OED framework. For example, @yoonwon model speakers' decisions to use polite speech as opposed to direct speech (e.g., indirect language such as "I don’t think that dress looks phenomenal on you" as opposed to "It looks terrible") as a tradeoff between maximizing informational and social goals. In their model, speakers reason about whether their utterance will communicate information faithfully with as little effort as possible (information goal) and/or cause harm to one's own or another's self-image (social goal). @yoonwon's empirical results suggest that speakers are in fact balancing social and epistemic goals, suggesting that both are necessary to account for polite speech.

We can make a direct connection between the politeness model and the OED account. Both assume that people produce actions to maximize utility, but the politeness model expands the type of information that people use to compute the usefulness of an action. An intriguing possibility for future research is to adapt the utility-theoretic approach used by @yoonwon to model children's information seeking behaviors such as asking questions in different social contexts. These ideas also connect to the effects of task framing (performance vs. learning oriented) on children's decisions to attempt more challenging tasks [@dweck1988social]. The presence of another person could be modeled as an increase in the weight that children place on maximizing social goals, leading children to select easier tasks where they can appear competent. This is a reconstrual of the goal-orienting account reviewed above since it characterizes the behavior as an output from a mixture of goals as opposed to the social context triggering either a performance or a learning goal.

One significant gap in research on children's inquiry goals is an estimate of how often children experience contexts with clear learning goals in their daily lives. That is, we do not yet have a theory of the kinds of environments that would lead children to generate learning goals. However, research on *guided participation* across cultures provides an interesting counter-example [@rogoff1993guided]. @rogoff1993guided provided parents and their toddlers with a set of novel objects and coded the amount of "caregiver orienting" behavior. The study was conducted in four different cultural communities (a Mayan Indian town in Guatemala, a middle-class urban group in the United States, a tribal village in India, and a middle-class urban neighborhood in Turkey) that varied in how separated children were from adult activities and whether formal schooling was emphasized. Caregiver orienting behavior was defined as,

> Caregiver orients child involved introducing new information or structure to the child (at any point in the episode) regarding the overall goals or a key part of the event or what was expected in the situation. Orienting framed a major goal, not just specific little directives for particular actions. (p. 43)

\noindent
Parents in all four communities produced high rates of structuring and orienting behaviors (with the lowest rate of structuring being 81% of play episodes). Thus, when placed in a structured activity, adults make sure children are aware of the goal (e.g., learning the function of the novel toy). However, the communities differed in how often children were directly involved with adult activities in day-to-day life, with the children raised in rural villages often having early access to adult economic and social events. An open question is whether older peers and adults need to be directly engaged with the child to trigger inquiry goals. Perhaps increased access to observing adult goal-directed behaviors could facilitate children to generate learning goals since children would see lots of adult activities that they do not understand but are motivated to learn about (e.g., cooking, shopping, working). 

In sum, understanding children's goals represent a critical step in characterizing the relative contribution active learning to cognitive development. Social contexts have the power to trigger inquiry goals, but they also introduce social goals that might be at odds with children's information seeking. One direction for future research is to quantify the prevelance of different goals in children's everyday experience. It would be useful to know how much of children's daily activities involve settings where there is a clear learning goal and whether the goal was generated independently or communicated by older peers and adults. It would also be useful to know how the distribution of these goals change as a function of development, especially as children enter school and across different cultural contexts where children have differential access to structured (e.g., lessons and sports) vs. unstructured activies (e.g., free play). Moving beyond the lab-based studies of OED-like reasoning is not trivial and will require leveraging recent advances in large-scale observational data collection about children's daily experiences. However, it is important to ask whether the efficient information-seeking behaviors that children produce in the lab would "scale up" to the complexity of real world learning environments, especially if we want to use the OED model as an account of cognitive development.

\afterpage{
```{r fig.pos = "H", out.width="100%",fig.cap = "Schematic of active learning within a social context. Each panel shows how social information could influence a different component of the active learning process. These social effects occur in-the-moment of learning or over developmental time. Also, the cause of the social effect varies from the mere presence of another person to triggering a sophisticated psychological reasoning process about others' goal-directed behaviors. Note that the panels correspond to the different sub-sections in Part IV of the text."}

grid::grid.raster(png::readPNG("../cada_schematic/cada_schematic.003.png"))
```
\clearpage
}

## Hypotheses

Once a learing goal is established, the next step of inquiry is to decide what hypotheses to consider. Intuitively, a hypothesis is a candidate explanation about how the world works. For example, consider the schematic learning contexts shown in Figures 1 and 2. In the casual context, the hypotheses for how the toy works could include: (1) Button A, (2) Button B, (3) Buttons A and B simultaneously. In the word learning context, the child might think the new word "dax" means: (1) dax = object A, (2) dax = object B, or (3) dax = object C. ^[Note that this hypothesis space is simplified since it only considers the possibility of one-to-one word-object mappings.] 

The set of hypotheses under consideration is critical for quantifying effective self-directed learning in the OED account. The usefulness function of expected information gain outlined in [Part III](#p3) works by comparing the learner's uncertainty over hypotheses before and after she sees an answer ($U(a) = ent(H) - ent(H|a)$). Without knowing the conents of the hypothesis space, it becomes challenging to select the best choice for reducing uncertainty. Put another way; the OED framework does not readily deal with situations where learners might have to consider a large space of hypotheses, might hold the wrong hypotheses, or might perform actions without considering any hypotheses at all. This is an especially important challenge for developmental accounts that draw on OED principles since these scenarios seem quite plausible for young learners.

However, one useful function of social learning contexts is that they can provide a clear set of possible explanations for the actual state of the world. In practice, adults and older peers who have access to the correct hypothesis can constrain the space of children's hypotheses to facilitate information seeking. This effect of social context parallels the discussion of the role of social partners in constraining goals in the previous section. 

One relevant case study comes from work on children's early word learning. The challenge for a young word learner is that even the simplest of words, concrete nouns, are often used in complex contexts with multiple possible referents, which in turn have many conceptually natural properties that a speaker could talk about. This ambiguity creates the potential for an (in principle) unlimited amount of hypotheses that children could consider when trying to figure out the meaning a novel word. Remarkably, word learning proceeds despite this massive uncertainty, with estimates of adult vocabularies ranging from 50,000 to 100,000 distinct lexical concepts [@bloom2002children]. 

It does not seem plausible for children to entertain all hypotheses about possible word-object links. But which ones should they consider? One proposed solution is that word learners only consider a single word-object link at a time [@trueswell2013propose; @medina2011words]. Under this account, the child makes an initial guess about the word meaning, and then only stores that word-object link until she receives sufficient evidence that her initial hypothesis was incorrect. If she does see enough counter-evidence, then she will switch to a new, single hypothesis that better matches the statistics in the input. ^[This "propose-but-verify" account parallels work by @bonawitz2014win in the domain of causal learning, which suggests that a "Win-Stay, Lose-Sample" algorithm (inspired by efficient sampling procedures in computer science) provides a better explanation of children's hypothesis testing behaviors compared to an algorithm that enumerates the entire hypothesis space.] However, another influential account of early word learning, inspired by basic associative learning principles, argues that word learners store more than a single hypothesis. Under this theory, children's  hypothesis spaces are reduced gradually via the aggregation of word-object co-occurrence statistics across multiple labeling events [@siskind1996computational; @yu2012modeling]. Support for this account comes from experimental work showing that both adults and young infants can use word-object co-occurrence statistics to learn word meaning from individually ambiguous naming events [@smith2008infants]. Moreover, adults show evidence of being able to recall multiple word-object links from an initial naming event [@yurovsky2014algorithmic]. 

The critical difference between these proposals is how much information learners store in the hypothesis space. Some of our own work provides evidence that the social context can modulate the content of the learner's hypothesis space [@macdonald2017social]. Inspired by ideas from Social-pragmatic theories of language acquisition that emphasize the importance of social cues for word learning [@clark2009first; @hollich2000breaking; @bloom2002children], we showed adults a series of word learning contexts that varied in ambiguity depending on whether there was a useful social cue to reference available (a speaker's gaze). We then measured learners' memory for alternative word-object links. People flexibly responded to the amount of ambiguity in the input, and as uncertainty increased, they tended to store more word-object hypotheses. Moreover, we found that learners stored representations with different levels of fidelity as a function of the reliability of the social cue. When the speaker was a less reliable source of information, learners distributed attention and memory broadly, storing more hypotheses.

These results provide evidence that the content of learners' hypothesis spaces changed as a function of social information. Further suppport for this idea comes from experimental work showing that even children as young as 16 months prefer to map novel words to objects that are the target of a speaker’s gaze and not their own [@baldwin1993infants], and analyses of naturalistic parent-child labeling events shows that young learners tended to retain labels accompanied by clear referential cues, which served to make a single object dominant in the visual field [@yu2012embodied]. One important direction for future research is to measure the full causal pathway from variation in social information through children's hypothesis spaces to their information seeking behaviors. For example, it would be interesting to know whether learners' subsequent questions or decisions about where to allocate attention would be affected by the social context in which they were first exposed to a new word.

A second case study that illustrates the importance of considering the learner's hypothesis space comes from work by @lucas2014children where they compared children and adult's capacity for learning different kinds of causal structures. In the task, participants saw a series of events that consisted of a training phase where an experimenter placed objects on a box that either played or did not play music. The participant's goal was to learn which objects, or combination of objects, made the box work. In the disjunctive condition, only single objects (A or C, but not B) made the toy play music. In the conjunctive condition, only the combination of two different objects (A **and** C) would make the toy play music. After seeing several demonstrations, both children and adults were tested on ambiguous events where they could either infer a disjunctive or conjunctive causal relationship. Only children learned the conjunctive relationship, even though the evidence favored this interpretation. The authors speculate that adults were biased towards the disjunctive hypothesis since it is a more common causal relationship in everyday experience; whereas children have accumulated less experience and have diffuse prior beliefs, which caused them to update their beliefs faster when they saw evidence in favor of the conjunctive hypothesis. ^[Figure 1 illustrates a version of the active causal learning scenario. In this case, the learner believes that pressing both buttons to activate the toy is a less likely hypothesis. As a result, the query to test the conjunctive hypothesis "press both buttons" becomes less useful for gaining information since it would produce confounded evidence concerning her other, disjunctive hypotheses.]

The striking difference between adults and children in the @lucas2014children study suggests that it is not trivial to know what hypotheses children bring to the learning task. Moreover, features of the immediate social context could bias the content of children's hypothesis space. In fact, @lucas2014children suggest that, 

> Most of the time, adults do not need to dramatically change their beliefs or abandon their hypotheses for dramatically different ones. Indeed, doing so would be a liability: adults are expected to make accurate predictions and good decisions, not bold inductive leaps. Adults are also unlikely to have caregivers to correct their errors and save them from poor choices. (p. 295)

\noindent
This proposal makes a testable prediction: that contexts in which learners "feel" safe to make mistakes would lead children to consider and test a broader range of hypotheses. Another effect of the social context highlighted in @lucas2014children's study is that the experimenters scaffolded children and adults consideration of the disjunctive and conjunctive hypotheses. That is, their actions constrained the hypothesis space to isolate learning and information seeking effects. The "Hypotheses" panel of Figure 3 presents a schematic illustration of how social partners can constrain hypotheses in the moment of learning. Similar to the research on goals, the majority of the work on hypotheses has focused on lab-based studies. Thus, it is an open question as to how much of role adults play in communicating relevant hypotheses during children's daily experience.

Social information can also shape children's hypothesis space by providing the necessary input to revise children's incorrect intuitive theories about how the world works. Research on conceptual change provides evidence that children integrate social input with their current hypotheses [@gelman2009learning]. Conceptual change refers to a "radical" reconstruction of an intuitive theory about how the world works. For example, elementary school-aged children tend to hold a mixture of beliefs about the shape of the earth [@vosniadou1992mental]. These theories range from a flat earth theory that matches children's everyday perceptual experiences (i.e., walking on flat ground) to the adult-like, sphere model, which reflects the actual state of the world. Interestingly, some children hold intermediate beliefs such as a dual-earth theory where there are two earths: "a round one which is up in the sky and a flat one where people live" (p. 550). The fact that some children entertain a dual-earth theory suggests that they are actively integrating aspects of their initial theory with the information they get from other people who already hold the correct, sphere theory. Moreover, for children to hold the sphere model at all, they must have learned it from social input. 

Additional evidence for the role of social input comes from work on children's reasoning about biological concepts. For example, the concept of "alive" takes years to fully develop, with younger children (under ten years of age) often claiming that only animals, and not plants, are alive. @opfer2004revisiting tested the hypothesis that evidence of goal-directed movement is critical for children's extension of the "alive" concept. In their study, 5-year-olds' were trained in different ways to think about the concept of a "living thing" and then asked whether they believed that plants were alive. Children either learned that plants were capable of goal-directed movement (e.g., "The house plant is growing this way. It needs the sunlight over here."), that plants were capable of growth, or that plants need water to survive. Children in the goal-directed movement condition showed the most significant theory revision, saying that plants were also living things more consistently on a post-intervention categorization task. Converging evidence comes from research on the links between language experience and performance on various cognitive tasks. For example, empirical work shows that deaf children without access to a natural language perform worse on Theory of Mind tasks [@peterson2000insights]; that Korean speakers perform better than English speakers on tasks that require categorizing based on tight vs. loose distinctions, which are lexicalized in Korean [@mcdonough2003understanding]; and that exposure to a first language reduces infants' capacity to detect non-native phonetic contrasts [@maurer2014perceptual].

One upshot of the work on children's conceptual change is that certain hypotheses are more primitive and children require social input to revise them (flat earth -> spherical earth). Taken together, the case studies reviewed in this section illustrate several points relevant to the integrative active-social learning account. First, the set of hypotheses that children consider are likely to be quite different from adults (and possibly different from what the experimenter thinks the child is considering). Second, children generate hypotheses using a mixture of prior knowledge, expectations about the task, and social input. Third, there are (at least^[We could make a further distinction between the developmental and the cultural timescales, where developmental refers to information acquired from interactions with others in the child's lifetime (e.g., disjunctive causal structures are more likely to occur in the world) and cultural refers to information that has accumulated throughout human evolutionary history (e.g., access to natural language or concepts such as the spherical earth.)]) two timescales through which social learning can shape hypotheses. An in-the-moment timescale where others' behavior constrains hypotheses for the current task -- for example, referential gaze indicating candidate word-object mappings or an adult suggesting a disjunctive (one-block) vs. a conjunctive (two-block) theory for how to make a toy work. And a developmental timescale where prior interactions with other people and cultural learning modify the hypotheses that children bring to the learning task (e.g., the conceptual change and language effects reviewed above). 

## Queries

Queries in the OED framework refer to the experiments that a scientist could conduct to gather information about their hypotheses. Queries in human information seeking can refer to a variety of actions, including verbal questions, pushing a button to figure out how a toy works, and decisions about where to look. One of the strengths of the OED account is the fact that it provides general principles that explain such a broad range of behaviors.

However, the challenge for the young learner is to discover what behaviors are available and of those actions which might be particularly useful for gathering information. In this section, I illustrate how the social learning context provides valuable input to this learning process via demonstrations of useful actions that learners could take to gather information. I suggest that this process involves adults' modeling useful information seeking and children recognizing and imitating these behaviors.  

It seems obvious that children would look to older peers or adults to learn what actions are useful. However, a large body of empirical work suggests that even young infants will not imitate every action that they see. Instead, children show evidence of "rational imitation" and will look for cues about others' goals and use this information to selectively imitate. For example, @gergely2002developmental measured how often 14-month-old infants imitated an adult's actions -- turning on a light with her head (less efficient) instead of her hands (more efficient) -- as a function of whether there was a relevant explanation for selecting the less efficient action (whether the adult's hands were occupied). They found a substantial difference in imitation rates across conditions (69% in the hands-free vs. 21% in the hands-occupied), suggesting that children recognized the reason for the inefficient action and chose to ignore the means and focus on the goal of turning the light on in the most efficient way possible.

The high rates of imitation in the hands-free condition highlight another component of learning from others' actions: that children tend to overimitate behaviors even when these actions are not directly relevant to the task. For example, @call2005copying compared imitation behaviors of 2-year-old children after they watched someone demonstrate how to open a tube using only the necessary actions or using the actions plus a style component unrelated to opening the tube (e.g., removing the tube's cap with an exaggerated twisting motion). Almost all children (93%) imitated the causally irrelevant action, providing evidence that they were focused on reproducing each of the experimenter's actions and not just reproducing the outcome of opening the tube.  Other empirical work shows that social factors matter for children's decisions to imitate. @carpenter1998fourteen showed that 14- and 18-month-olds were less likely to mimic an adult's action if the action was marked verbally as a mistake (e.g., "Whoops!"). @buchsbaum2011children provide evidence that the children are more likely to overimitate when the adult is described as a "knowledgeable teacher" as opposed to "naive." And @carpenter2002understanding showed that giving children explicit information about another person's goals before a causal demonstration leads to an increase in imitation and learning of the correct casual structure. Together, the work on imitation suggests that children could use others' goal-directed, information seeking behaviors as input to help them learn what queries are useful.

Research on verbal question asking provides insight into how social input guides children's developing information seeking. First, consider that the very act of asking a question in natural language requires that children have acquired a conventionalized symbolic system, which must have been learned from social input. Second, both experimental work and corpus analyses provide evidence that children's question-asking becomes more varied and productive over the first years of life as they get exposed to more complex language input (see @chouinard2007children and @legare2013use studies reviewed in [Part II](#p2)). Moreover, as children develop, they improve the timing of their turn-taking during question-answer exchanges, reducing the length of gaps between turns [@casillas2014turn]. Interestingly, @casillas2014turn also showed that adults were sensitive to children's developing question-answering skills, waiting to ask more difficult questions until children were older, and modifying their questions if children were confused (e.g., "Who is this? -> What’s he called? -> Who is he? -> What is his name?").  

The majority of research on children's question asking has focused on aspects of the child's behavior, exploring how the type, content, and effectiveness of questions changes as children develop. However, several studies have measured children's exposure to questions in their input. For example, @yu2017peagogical coded parent-child interactions from the CHILDES database to measure the amount of "pedagogical" questions in children's input. They differentiate "pedagogical" from "information seeking" questions by coding whether the adult already knew the answer. For example, "What’s that called?" would be pedagogical; whereas,  "What did you do at school?" would be information seeking. Approximately 30% of parents' questions were pedagogical, 60% were information seeking, and 10% were rhetorical (i.e., not intended to be answered verbally). Parents also directed a smaller proportion of pedagogical questions to older children. @yu2017peagogical speculate that the function of pedagogical questions is to help children learn. 

It is interesting to consider how children might internalize adults' question asking behaviors (modifications, pedagogical questions) and incorporate them as part of their own question asking repertoire. However, more work is needed to understand the link between adults' question-asking practices and children's behaviors. This research could be especially interesting since observational studies have found that that parents' use of wh-questions predicts children's later vocabulary and verbal reasoning outcomes [@rowe2017going] and children of parents who were trained to ask "good" questions during book reading episodes at home also asked better questions during book reading sessions at school [@birbili2009helping]. One explanation for these associations is that wh-questions challenge children to produce more complex responses that build verbal abilities. However, another intriguing causal pathway is that the frequency and type of questions that parents shape children's information seeking skills by providing templates for useful questions.

After children generate a set of possible questions, they have to evaluate the relative usefulness (i.e., utility) of the different queries. But how do children learn the features of a good question? One solution is for children to observe other people's question asking behaviors, recognize which questions are useful, and leverage their imitation skills to model those behaviors. In fact, there is evidence from work with adults showing a substantial difference between people's question-generating (harder) and question-evaluation (easier) skills. For example, @rothe2015asking asked a group of adults to play a modified "Battleship" game where they had to find the location of three ships that consisted of 2-4 tiles and could be oriented in either the vertical or horizontal direction on a 6x6 grid. Participants gathered information sequentially by uncovering one tile at a time. At different points in the task, the game would stop, and participants could ask any question using natural language. @rothe2015asking used a formal OED model to measure the expected information gain of each question, and people rarely produced high information value questions. However, in a follow-up experiment @rothe2015asking had a different group of adults play the Battleship game, but this time participants had access to the list of questions generated by participants the free-form version, In this contexts, adults were quite good at recognizing and selecting high information value questions.   

Developmental work provides additional evidence of this production-comprehension asymmetry. For example, children younger than the age of three have difficulty generating appropriate verbal questions compared to their older peers in "Twenty Questions" style tasks that are designed to measure question-asking skills [@mills2011determining; @mills2010preschoolers]. However, when @mills2012little tested 3- to 5-year-old's capacity to learn from observing third-party question-answer exchanges, they found that even the youngest children were capable of using information elicited by others' yes/no questions to identify the contents of a box. Interestingly, children recognized the value of others' question-answer exchanges, paying more attention to them as compared to third-party exchanges that did not include question-answer exchanges. These results suggest that even at an age where generating questions "from scratch" might be difficult, children can observe and learn from questions that occur in their social environment. @mills2011determining also explored this phenomenon by directly manipulating whether children were exposed to a training phase where adults modeled useful questions before playing the question asking game. They found that even though the youngest children were not successful at constructing good questions, they were able to ask useful questions at a much higher rate following exposure to explicit modeling.
  
Work with elementary-school-aged children in the domain of scientific inquiry also shows that generating a good question is a challenging aspect of inquiry skills. One relevant example comes from @kuhn2008needs's intervention study comparing children trained on scientific inquiry skills (e.g., understanding the objectives of inquiry and identifying questions) to a group of slightly older students who had not participated in the direct instruction training. Children in the training group showed progress. In contrast, children in the comparison group failed to develop these formal scientific inquiry skills in the absence of a particular kind of input. kuhn2008needs summarizing the key results, 

> Consistent with the findings of Kuhn and Dean (2005), identifying a question appears to play a key role in making the rest of the inquiry cycle productive ... Like other components of the inquiry process, this skill is not one a student learns once and has mastered. (p. 555)

Another way that social contexts influence the set of possible queries is by adding a "social target" for information seeking. 
That is, the child now has an additional choice: to gather information from the non-social world or other people. The "Questions" panel in Figure 3 shows a child trying figure out how a toy works. If there is no social partner present, they could still try actions that test the system directly and seek information from the world. But if another person is present, the child now has the option to ask verbal questions or to seek help via nonverbal cues (e.g., pointing, facial expressions). 

Recent empirical work has explored the factors that influence children's decisions to seek information from other people. For example, @fitneva2013development measured 4- to 6-year-old's decisions about how to learn the features of  a novel social category: "moozles." Critically, the target concept was either visible (hair color) or invisible (knowledge of a foreign language). Children could choose to look directly at the moozle or ask a moozle expert. Children tended to "look" for the visible property and "ask"  for the invisible property. These results suggest that children have some meta-understanding of the kinds of information that is particularly useful to learn from social partners. 

Additional evidence comes from work by @lockhart2016could. They asked 5- to 11-year-old children whether a person "growing up on their own" could learn facts that varied along a dimension of learnability based on direct perceptual experience (that the sky is blue vs. that the earth is round). Children of all ages performed quite well, showing that could verbally articulate the kinds of information that would require interactions with other people. The items in this study did not test children's appreciation for more indirect forms of social learning: that is, to learn that the sky is blue relies on having a conventional language system for referring to concepts. @gelman2009learning refers to this as "a hidden level of cultural input" (p. 2). The critical point is that even in learning contexts that appear entirely self-directed, children's massive amounts of accumulated experience with other people shape the hypotheses and questions that children consider.

Another set of relevant examples comes from work on children's help-seeking behaviors. @vredenburgh2016young had children build toys that required multiple steps, and on each step, children were given the opportunity to ask for help from the experimenter. Each step varied in difficulty and children naturally varied in their toy building skill. Children asked for help when the step on more challenging steps, suggesting that preschoolers sought help systematically. Moreover, work by @gweon201116 found that 16-month-old infants are selective help-seekers, turning to a social target to request information or acting on the world depending on which information source was more likely to help them achieve their current goal. In this case, the infants' goal was to make a malfunctioning toy produce music, and the critical manipulation was whether children saw evidence that explained the likely cause of failure being the toy versus their capacity for making the toy play music. When the toy was likely to be broken, they reached for a new object (queried the world), but in contrast, when the evidence suggested that the child was the issue, then they sought help from a nearby adult. 

Some of our work has explored how the presence of another person changes the set of information seeking behaviors available  [@macdonald2017info]. Inspired by theories of natural vision that characterize eye movements as an information seeking mechanism, we asked whether children and adults would allocate more visual attention to a speaker when the linguistic signal was noisy to support the goal of rapid language understanding. We used an eye-tracking task to measure participants' gaze patterns while they processed clear or degraded speech (speech with brown noise added). Both children and adults spent more time fixating on the speaker in the degraded speech context. Interestingly, children and adults were also more accurate in word recognition even though the speech was noisy and difficult to process. This result suggests that listeners were compensating for the uncertainty in the auditory channel by gathering visual information from the speaker. Critically, listeners would not have been able to gather this information if the speaker was not present (e.g., listening to a noisy recording) and in clear view.

In sum, queries provide the tools for information seeking. However, more research is needed to understand the link between children's input and the set of questions they consider . One proposal is that children use their powerful imitative learning abilities to model the question-asking behaviors demonstrated by more knowledgeable others. Moreover, social contexts can fundamentally change the set of actions available to the learner by providing a social target for information seeking behaviors.  

## Answers

In the OED framework, answers refer to possible states of the world after the learner generates a query. An answer is useful if it results in a substantial decrease in uncertainty about the actual state of the world. The challenge for the active learner can be separated roughly into two parts: (1) figure out what which answers are likely and (2) decide how much you should learn from an answer after seeing it. The social context plays a role in each component and is the focus of the current section.

Defining the specific features of a "good" answer is challenging. Intuitively, a good answer gives the learner information that they did not already know, that they were interested in learning, and that is likely to be useful beyond the current context (i.e., to generalize). Even within the formal OED framework, there have been a variety of ways to instantiate the utility function (e.g., information gain, probability gain, and Kullback-Leibler divergence) to compute the value of an answer (see @nelson2005finding). All of these information-theoretic utility functions take into account the learner's prior beliefs represented as probability distributions over hypotheses and calculate the impact that an answer would have on the learner's beliefs represented as conditional probability distributions. 

Several social learning accounts argue that a key function of social information is to provide useful answers. For example, evolutionary models of cultural learning argue that the human capacity for efficiently transferring knowledge between individuals allows for the gradual accumulation of small improvements that eventually lead to complex tools, beliefs, and practices that would be difficult, if not impossible, for any individual to discover on their own [@kline2015learn]. @boyd2011cultural provide the following example,

> For example, a rare chance observation might allow a hunter to associate a particular spoor with a wounded polar bear, or to link the color and texture of ice with its stability on windy days just after a thaw. Such rare cues allow accurate low-cost inferences about the environment. However, most individuals will not observe these cues, and thus making the same inference will be much more difficult for them. Organisms that cannot imitate must rely on individual learning, even when it is difficult and error-prone. They are stuck with whatever information that nature offers. (p. 10921)

\noindent
The fundamental idea is that communicating useful and difficult to acquire information enhanced evolutionary fitness. Thus, there is an a priori reason to expect that information from other people will be useful. 

This concept is critical to @csibra2009natural's theory of "Natural Pedagogy" reviewed in [Part I](#p1). Specifically, they argue that an assumption of *generalizability* is a fundamental component of adults' communication with children. Their account has three elements: adults transmit generic information, adults provide ostensive cues to signal generalizable knowledge, and children show sensitivity to these cues, treating information differently when they are present. Evidence for a bias towards generalizability comes from a set of empirical studies showing that infants will generalize more often when learning information accompanied by ostensive communicative cues such as eye gaze or child-directed speech. For example, infants are more likely to generalize the positive vs. negative valence associated with a specific object-person pairing to a new person if the valence was demonstrated with pedagogical cues [@gergely2007pedagogy]. Also,  infants are more likely to encode the stable features of an object, as opposed to its location in space, if a communicative signal such as a point guided their attention [@yoon2008communication].

Even if learning occurs in a social context with a default assumption of useful and generalizable information, not all answers are equally informative. Thus, the second challenge for information seekers is to evaluate possible responses to a query to figure out how much they would update beliefs. This challenge is perhaps one of the more developed connections between the formal social and active learning accounts. Researchers have made progress in modeling the influence of different assumptions that a learner could make about the generative process of answers. For example, @shafto2012learning lay out a continuum of sampling assumptions:

  * *Weak sampling*: answers generated at random from the set of all possible answers (independent of target hypothesis)
  * *Strong sampling*: answers generated at random from the set of answers that are true of the correct hypothesis (linked to target hypothesis)
  * *Pedagogical sampling*: answers generated that maximize the learner’s belief in the correct hypothesis (linked to target hypothesis and consider alternative hypotheses)
  
\noindent
Critically, if the learner assumes strong or pedagogical sampling, then they can make stronger inferences that speed learning. For example, if we see someone press two buttons to activate a device, we are more likely to think that both buttons were necessary if that person knew how the machine worked and wanted to communicate to us how it worked. Otherwise, if one of the buttons would have been sufficient, then it would not make sense for them to perform the less efficient action of pressing both buttons. The effects of these sampling assumptions are fundamentally psychological. They require the learner to reason about others' goals and to reason about whether other people are thinking about their goals. See the "Answers" panel of Figure 3 for a visual illustration of this recursive psychological reasoning process within the active learning context. 

Empirical support for the pedagogical sampling account comes from a range of domains/tasks, including word learning [@frank2009using], pragmatic inference [@frank2012predicting], and causal reasoning [@bonawitz2011double] (see the section on inferences and generalization in social learning Part I). We can also revisit these findings and connect them directly to specific components of the OED model of human inquiry. Consider @xu2007sampling finding: that learners are "sensitive" to the sampling process that generated the examples. When a knowledgeable teacher selected the examples, learners assumed the examples indicated the true word meaning. And if this were the case, then it would be surprising to see three examples drawn from the smaller subordinate category. Formally, they modeled sensitivity to sampling assumptions by changing the learner's belief in the probability of hearing a particular label ($l_i$) given a specific object ($o_i$) and word meaning ($m$), modifying the likelihood function in their Bayesian cognitive model: $p(x_i \mid m) \propto p(l_i \mid o_i, m)$. In this case, the likelihood function for the teacher-driven condition was designed to capture the idea that learners should prefer "smaller" or more restrictive hypotheses if they are confident that the teacher generated labels based on the actual word meaning.

This formalization provides a direct connection with the OED model of human inquiry. Specifically, when a learner simulates the possible answers, she considers how much each answer will update her beliefs. This reasoning process is modeled by computing the difference between the learner's prior and posterior uncertainty (i.e., entropy): $U(a) = ent(H) - ent(H|a)$. The learners' sampling assumptions naturally enter the information seeking calculus through the posterior entropy term $ent(H|a) = -\sum_{h\in H}{P(h|a)logP(h|a)}$. Intuitively, this part of the model captures the idea that not all answers are equally useful, and answers that are generated to help us learn are more informative and should lead to a stronger change in the learner's beliefs.

The approach of building more sophisticated likelihood functions has also been used to capture another aspect of evaluating the utility of an answer: that not all social partners are equally reliable sources of information. When learning from the testimony of others, there is always a possibility that the information could be inaccurate or misleading. This reasoning process might be especially important for young learners who acquire much of their information via interactions with others. A growing body of evidence suggests that even very young infants are capable of *selective* learning, rejecting answers that conflict with their knowledge [@pea1982origins] and seeking information from people who tend to provide good answers in the past [@koenig2004trust]. 

For example, empirical work shows that preschoolers track and integrate a speaker's prior instances of accuracy to figure out if they are trustworthy and will use this information to guide subsequent learning from that speaker’s future claims [@koenig2004trust]. In these studies, children evaluate a speaker’s current testimony after the speaker establishes a record of reliability or unreliability by labeling or mislabeling familiar objects. Across these studies, preschoolers are consistently less likely to direct questions towards and learn from a previously unreliable person. Moreover, @chow2008see found that 14-month-olds are less likely to follow the gaze of a person who had been unreliable in the past, i.e., someone who had consistently directed gaze towards an empty location in space. Finally, children's selective learning appears sensitive to external cues, preferring to learn familiar over unfamiliar teachers [@corriveau2009choosing], adults over peers [@rakoczy2010bigger], and ingroup over outgroup members [@macdonald2013my].

Converging evidence comes from @gweon2014sins work on children's exploration behavior after seeing pedagogical demonstrations of varying quality. In this study, children played with toys that either had a single or multiple functions (e.g., spinning globe or flashing light) until they independently discovered the correct number of functions. Then, depending on condition assignment, they saw a puppet either teach all of the functions (informative teacher) or a subset of the functions (under-informative teacher). Finally, the puppet teacher introduced a new toy to the participant and demonstrated a single novel function. Critically, when the puppet teacher had been under-informative in their previous teaching, children spent more time exploring the object functions that the teacher did not demonstrate. That is, children did not make the stronger inference that there were no other functions to discover. 

The upshot of the selective learning literature is that children are not entirely credulous when they encounter information. Instead, they actively reason about features such as expertise and helpfulness avoiding people that they think are unreliable. Interestingly, the typical outcome measures in studies of selective learning are children's information-gathering decisions: whom to direct questions towards and how long to explore a novel toy. These behaviors map directly onto the decisions in the OED model of human inquiry and suggest that children consider the expected utility of others' answers when deciding to gather information.

Similar to the pedagogical reasoning effects, the selective learning phenomena have also been modeled by modifying the likelihood function in a Bayesian cognitive model. For example, @shafto2012epistemic proposed that selective learning in object labeling scenarios can be explained as children reasoning about both the helpfulness and knowledgeability of speakers when they produce a given label, $l$. Here the child's goal is to select a speaker that increases the chance that they get good information that matches the true state of the world ($label=correct$). Formally, they specify this likelihood function as: 

$$P(l \mid s,k,h) = \sum_b P(l \mid b,h)P(b \mid k,s)$$

\noindent
This function captures the idea that the probability of a label depends on the true state of the world and features of the speaker: their knowledge ($k$) and helpfulness ($h$). This is decomposed into two parts: (1) the speaker's belief ($b$) about the label $P(b|k,s)$, which depend on their knowledge ($k$) and the true label ($s$), and (2) the speaker's probability of producing a label that matches their belief, which depends on their helpfulness ($h$). Using this model, @shafto2012epistemic captured several qualitative findings from the selective trust literature, including children's demonstrated preference for accurate over inaccurate speakers. While the precise mathematical details of the model are less important, the key takeaway is that the same modeling approach can account for children's behavior in different domains.   This parallel suggests that children reason about the utility of answers before deciding to seek information from a social partner and after having received information from another person.

One consequence of the ideas discussed in this section is that features of the individuals who are present in a social learning context can change whether information seeking occurs at all. If a child is in a setting that is unlikely to provide useful answers, then generating an information-seeking behavior, even if the action has the potential to return useful information, becomes less valuable. Thus, a challenge for the self-directed learner is to figure out whether helpful answers are likely to occur. However, this is a less-developed area of research, and more work is needed to understand whether the expected usefulness of answers within a *context* might reduce information seeking because the costs in mental energy or time are too high. The dual consideration of costs and benefits in active learning has been the focus of recent advances in machine learning [@haertel2008return] and children's developing social cognition [@jara2015children]. It would be interesting to merge these cost-based approaches with ideas from social learning theory to ask how social contexts modify the costs of different behaviors.

## Stopping rules

A stopping rule describes a threshold that causes people to cease information seeking and generate a behavior. The concept draws on ideas from probability theory that have been used to model how random variables change as a function of time. Rules can be information or time-based. For example, when researching for a paper, a student might generate the time-based stopping rule -- read for two hours -- or a more information-based rule -- read until I understand this concept. The learner's goal is to figure out the stopping rule that balances achieving the inquiry goal with reducing unnecessary time/effort put into the task.

Studies of children's information seeking have primarily focused on measuring whether children persist if their initial request is not satisfied. For example, @frazier2009preschoolers analyzed parent-child question-answer exchanges from the CHILDES database to see if children show evidence of seeking causal explanations when they ask *how* and *why* questions. To address this hypothesis, @frazier2009preschoolers measured the probability of children re-asking the same question and the likelihood of asking a different, follow-up question after receiving either an explanatory response (e.g., CHILD: "Why you put yogurt in there?" ADULT: "Yogurt's part of the ingredients") or a non-explanatory response (e.g., CHILD: "How do you get sick?" ADULT: "I don't know."). Children were more than twice as likely to re-ask a question after getting a non-explanatory response (24%) compared to an explanatory answer (9.4%), providing evidence that they continued to collect information until their inquiry goal was satisfied.  

Converging evidence comes from @deborah2004children's work exploring children's intended meaning when they ask "What is it?" about objects. Children's propensity for asking follow-up questions was measured after they were given either a name or a functional explanation in response to an ambiguous request ("What is it?" Or "What's this?"). Similar to @frazier2009preschoolers's findings, 2- to 4-year-olds asked more follow-up questions when adults provided an object label, suggesting that they intended to ask about the object's function and persisted to get this information. Children were also more likely to change the form of their ambiguous questions to more specifically target functional explanations in the object label condition. Together, these studies suggest that young children are sensitive to when they have gathered sufficient information to address their questions. In the majority of this work, the social context influenced children's stopping decisions by giving them the information they desired. 

However, social contexts can shape children's stopping decisions in other ways. A recent body of research shows that adults' demonstrations of pedagogy directly influence children's decisions about whether to persist in exploration. For example, @bonawitz2011double showed that preschoolers spend less time exploring an object and are less likely to discover alternative object-functions after an adult explicitly taught a single function [@bonawitz2011double]. The explanation for this effect is similar to the pedagogical inference work reviewed in the "Answers" section. A pedagogical demonstration by a knowledgeable teacher provides evidence for that function and against the existence of other functions; otherwise, the teacher would have demonstrated the other features. We can reconstrue this finding as an effect of social input on children's stopping rules. When the social context indicates that there is less to learn, children adopt a lower threshold for ending their search.

It is not the case that information acquired in social contexts always reduces information search. In fact, @butler2012preschoolers study of children's inductive inferences provides evidence that a pedagogical demonstration leads to an increase in exploration. Preschoolers saw an unfamiliar object and learned a novel causal property (that the object could magnetically pick up paper clips). In one condition, the experimenter demonstrated the property with a pedagogical framing ("Look, watch this!"). In the other condition, it was an accidental demonstration ("Oops!"). After the pedagogical demonstration, children spent more than twice as much time exploring the objects and generated three times as many attempts to make the objects pick up the paper clips. 

These are seemingly contradictory effects of pedagogy on children's stopping rules. However, they both arise because socially transmitted information is more informative and warrants stronger inferences. In the causal learning case, the stronger inference is about the lack of alternative object-functions, leading to less exploration. In the inductive inference case, the stronger inference is about the generalizability of the causal property, leading to more exploration. These findings also highlight the useful distinction between social information available in the moment and social input acquired from previous interactions.

Understanding why children decide to stop gathering information is a promising area for future research. Studies could focus on children's developing capacity to reason about the cost of actions for themselves and others. This cost term is critical to deciding when it is not worth gathering additional information. In fact, recent theorizing in the field of social cognition proposes that intuitive reasoning about the costs/benefits of others actions is the core of our social cognition. @jara2016naive describe this idea as a Naive Utility Calculus where, "... human social cognition is structured around a basic understanding of ourselves and others as intuitive utility maximizers." (p. 589). 

There has also been a growing interest in developing "cost-sensitive" active learning algorithms in the field of machine learning [@haertel2008return], with researchers beginning to define costs in increasingly sophisticated ways. For example, @settles2008active point out that the cost of information gathering should not be measured as a reduction in the number of training trials if those training trials vary in length because specific questions are more challenging to answer. Thus, an efficient active learner should want to ask questions that maximize information gain, but they should also take into account the cost incurred by others (e.g., time or mental effort) to provide that information. This idea is fundamentally psychological in that it expands the utility computation to include some measure of how our behavior affects others' actions and/or mental states. Another open question is how children develop skill in reasoning about more complex costs (e.g., reputation management), and how children integrate their costs with the costs incurred by others.  

# Conclusions

In this paper, I proposed a way forward for integrating active and social learning theory. Social learning accounts emphasize the importance of rich social input that is tuned to the cognitive capacities of the learner. In contrast, active learning accounts emphasize children's powerful self-directed learning skills, arguing that children are capable of generating and efficiently testing a broad range of hypotheses.

I argued that the formal framework of Optimal Experiment Design (OED) is a useful way to characterize the effects of social contexts on children's active learning. The OED framework defines information seeking as a process of expected utility maximization for gaining information. There are four model components -- goals, hypotheses, questions, and answers -- and other factors that are important but exist outside the model such as stopping rules. I used the OED decomposition to bring social learning models and findings into contact with active learning theory, and I suggested that the social context can influence children's active learning by: 

  1. communicating and/or triggering a diverse set of goals both informational and/or social
  2. shaping the content of children's hypothesis spaces both in-the-moment and/or over a developmental timescale
  3. serving as a model of possible and useful queries for children to imitate
  4. providing useful and generalizable answers to children's queries
  5. modulating when children decide to stop collecting information 

\noindent
The heart of this proposal is that an integrative account of active learning within social contexts represents a valuable step towards understanding cognitive development. I have tried to argue that the social and active learning accounts have much to be gained by considering the other. 

Active learning accounts benefit by understanding how learners function within social contexts. This social information can allow researchers to create more sophisticated utility functions that take into account the social goals that people consider when deciding what to learn. This seems especially important for characterizing children's active learning since observational studies of learning environments suggest that opportunities to learn from social interaction are ubiquitous.  On the other hand, researchers interested in social learning can benefit from advances in the field of active learning by connecting their ideas to the rich traditions of machine learning, decision theory, and statistics. Moreover, children's information seeking decisions are often used as dependent variables in studies of social learning phenomena. Thus, a secondary benefit would be a deeper understanding of the factors that influence the measurement of social learning effects.

Finally,  research on active learning should move beyond studies lacking a social context and begin to document the presence of learning goals, constrained hypothesis spaces, and the quality of answers in children's everyday experiences. This integrative approach requires a shift from relying on highly-controlled tests of children's active learning skills to leveraging large-scale observational datasets. And while this approach adds complexity to our experiments and models, I think that the benefit will be a far greater understanding of how active learning operates over fundamentally social input.  

\newpage

# References

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = 'refs'></div>

\newpage

# Appendix {#app}

\setlength{\parindent}{0in}
\setlength{\leftskip}{0in}

R code to implement the worked example of OED presented in Part 3. First, we define some functions to make the computation of conditional probability, entropy, and information gain easier.

```{r, echo = T}
# bayes rule to compute conditional probability
compute_bayes <- function(prior_a, 
                          prior_b, 
                          likelihood) {
  (prior_a * likelihood) / prior_b
}

# entropy functions
compute_symbol_ent <- function(probability) {
  if(probability == 0) {
    0
  } else {
    (probability * log2(probability)) * -1  
  }
}

compute_entropy <- function(probability_vector) {
  sapply(probability_vector, compute_symbol_ent) %>% 
    sum() %>% 
    round(digits = 2)
}

# compute intormation gain of a single answer
compute_utility_answer <- function(prior_entropy, 
                                   posterior_entropy) {
  prior_entropy - posterior_entropy %>% 
    round(digits = 2)
}

# compute intormation gain of a question
compute_utility_question <- function(prior_entropy, 
                                     utility_answers, 
                                     probability_answers) {
  posterior_entropy <- (utility_answers * probability_answers) %>% 
    sum() %>% 
    round(digits = 2)
  prior_entropy - posterior_entropy
}
```

Next, we instantiate our prior knowledge of the world as global variables that will get passed to the expected utility functions.

```{r, echo = T}
# prior probabilities of species
prior_prob_glom <- 0.7
prior_prob_fizo <- 1 - prior_prob_glom

# conditional probabilities of features for each species
prob_meat_glom <- 0.1
prob_meat_fizo <- 0.9
prob_nocturnal_glom <- 0.3
prob_nocturnal_fizo <- 0.5
```

\noindent
Next, we use Bayes rule to compute how much our beliefs would change if we saw evidence of eating meat. To do 

$$
\begin{aligned}
P(glom \mid eatsMeat) &= \frac{P(eatsMeat \mid glom)P(glom)}{P(eatsMeat)},\\
where,\\
P(eatsMeat) &= [P(eatsMeat \mid glom)P(glom)] + [P(eatsMeat \mid fizo)P(fizo)]
\end{aligned}
$$

\noindent
In R code, we compute the prior probability of the presence and absence of the "eats meat" feature as:

```{r, echo = T}
# compute probability of the presence of eating meat
prob_meat <- (prob_meat_glom * prior_prob_glom) + 
  (prob_meat_fizo * prior_prob_fizo)

# compute probability of the absence of eating meat
prob_notMeat <- 1 - prob_meat
```

\noindent
Next, we use Bayes rule to compute the change in beliefs about species if we observed the creature eating meat.

```{r, echo = T}
# use bayes rule to compute conditional probability that glom 
# given that eats meat answer is yes
cond_prob_glom_meat <- compute_bayes(prior_a = prior_prob_glom, 
                                     prior_b = prob_meat, 
                                     likelihood = prob_meat_glom)

# use bayes rule to compute conditional probability that fizo 
# given that eats meat answer is yes
cond_prob_fizo_meat <- compute_bayes(prior_a = prior_prob_fizo, 
                                     prior_b = prob_meat, 
                                     likelihood = prob_meat_fizo)
```

\noindent
Next, we compute the expected utility of getting a specific answer ($U(eatsMeat = yes)$). Recall that we define an answer's utility as information gain, which is a function of the prior and posterior entropy.

```{r, echo = T}
# compute prior and posterior entropy
prior_entropy <- compute_entropy(c(prior_prob_fizo, 
                                   prior_prob_glom))

posterior_entropy <- compute_entropy(c(cond_prob_fizo_meat, 
                                       cond_prob_glom_meat))

# compute information gain
utility_yes_meat <- compute_utility_answer(prior_entropy, 
                                           posterior_entropy)
```

\noindent
Next, we apply the same procedure to get the utility of the answer "no" for the "eats meat?" question ($U(eatsMeat = no)$).

```{r, echo = T}
# use bayes rule to compute conditional probability that glom 
# given that eats meat answer is no
cond_prob_glom_notMeat <- compute_bayes(prior_a = prior_prob_glom, 
                                        prior_b = 1 - prob_meat, 
                                        likelihood = 1 - prob_meat_glom)

# use bayes rule to compute conditional probability that fizo 
# given that eats meat answer is no
cond_prob_fizo_notMeat <- compute_bayes(prior_a = prior_prob_fizo, 
                                        prior_b = 1 - prob_meat, 
                                        likelihood = 1 - prob_meat_fizo)

# compute prior and posterior entropy
prior_entropy <- compute_entropy(probability_vector = c(prior_prob_fizo, 
                                                        prior_prob_glom))

posterior_entropy <- compute_entropy(probability_vector = c(cond_prob_fizo_notMeat, 
                                                            cond_prob_glom_notMeat))

# compute information gain for the answer
utility_no_meat <- compute_utility_answer(prior_entropy, posterior_entropy)
```

\noindent
Finally, to compute the overall expected utility of the "eats meat?" question ($EU(Q)$), we weight the utility of each answer by the prior probability of getting that answer.

```{r, echo = T}
utility_meat_q <- compute_utility_question(prior_entropy,
                                           c(utility_yes_meat, utility_no_meat),
                                           c(prob_meat, 1 - prob_meat))

paste0("The expected utility of the eats meat question is: ", utility_meat_q)
```