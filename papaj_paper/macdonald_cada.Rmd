---
title             : "How social contexts shape active learning"
shorttitle        : "Active learning is social"

author: 
  - name          : "Kyle MacDonald"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Stanford University"

author_note: |
  Conceptual Analysis of Dissertation Area. 
  
  Readers: Michael C. Frank, Hyowon Gweon, and Anne Fernald

abstract: |
  Children's rapid conceptual development is one of the more remarkable features of human cognition. How do they learn so much so quickly? Social learning theories argue for the importance of learning from rich input provided by more knowledgeable others. In contrast, active learning accounts focus on children's efficient information seeking skills as a path to knowledge acquisition. In this paper, I suggest that an important step towards a complete theory of early learning is to understand how active learning behaviors unfold within social learning contexts. To integrate the two theoretical accounts, I use the theory of Optimal Experiment Design (OED), which formalizes human inquiry as a decision process that maximizes expected utility with respect to the goal of gaining new information. I argue that this integration allows for recent insights into children's social learning to increase our understanding of how children make decisions when learning about the world.
  
keywords          : "active learning, social learning, decision making, optimal experiment design, theory"
wordcount         : "X"

bibliography      : ["cada_library.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no

lang              : "english"
class             : "man"
header-includes   :
  - \usepackage{afterpage}
linkcolor         : blue
urlcolor          : blue
output            : 
  papaja::apa6_pdf:
    toc: true
    toc_depth: 2
---

```{r load_packages, include = FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo=F, warning=F, cache=T, message=F, sanitize=T)
library("papaja")
library(knitr); library(tidyverse); library(spelling); library(xtable)
```
\newpage

# Introduction 

Human learning is remarkable. Consider that children, despite their limitations on general processing capabilities, can acquire new lexical concepts at a high rate, eventually reaching an adult vocabulary ranging from 50,000 to 100,000 words [@bloom2002children]. And they accomplish this all while also developing motor skills, learning social norms, and building causal knowledge. How can we explain children's prodigious learning abilities?  

Social learning accounts offer a solution by pointing out that children do not solve these problems on their own. Instead, children are typically surrounded by parents, other knowledgeable adults, or older peers â€“ all of whom likely know more than they do and are interested in facilitating their learning. Social learning accounts also emphasize that social contexts can bootstrap children's learning via several mechanisms. For example, work on early language acquisition shows that social partners provide input that is tuned to children's cognitive abilities [@fernald1987acoustic; @eaves2016infant], that guides children's attention to important features in the world [@yu2007unified], and that increases levels of sustained attention, which result in better learning [@yu2016social; @kuhl2007speech]. 

Social contexts also change the computations (i.e., inferences) that support children's learning from evidence. Recent work in the fields of concept learning and causal intervention suggests that the presence of another person engages a set of psychological processes where the learner reasons about *why* other people performed specific actions. The critical insight is that knowledge that another person selected examples to help you learn, allows children to make stronger inferences that speed learning [@frank2009using; @bonawitz2016computational; @shafto2014rational]. For example, people will learn at different rates after observing the same action depending on whether they thought the behavior was accidental (less informative) or intentional (more informative. Moreover, adults and children will make even stronger inferences if they believe that another person selected their actions with the goal to help them learn (i.e., to teach) [@shafto2012learning].

However, children are not passive recipients of information -- from people or the world. Instead, children actively select behaviors -- for example, asking questions or choosing where to allocate visual attention -- that change the content, pacing, and sequence of their learning experience. Recent theories of cognitive development have proposed the metaphor of "child as an intuitive scientist" and characterized early learning as a process of exploration and hypothesis testing following principles of the scientific method [@gopnik1999scientist; @schulz2012origins]. Moreover, recent empirical work across a variety of domains -- education [@grabinger1995rich], machine learning [@settles2012active; @castro2009human], and cognitive science [@markant2014better] -- has directly compared learning trajectories in contexts marked by self-directed choice (active learning) as compared to settings where the learner has less control (passive learning). The upshot of this work is that active contexts often lead to faster learning rates by enhancing attention and arousal or by providing learners with better information that is linked to their current goals, beliefs, and interests (see @gureckis2012self for a review). 

Thus, children are capable of guiding their own learning and social contexts provide particularly good learning environments. But how can we integrate these two proposals? Answering this question represents a significant step towards a complete theory of early learning since children's cognitive development unfolds within social contexts. And learners must integrate information from other people when deciding what to learn next. 

In this paper, I propose an integrative account of active learning within social contexts. I use the framework of Optimal Experiment Design [@emery1998optimal; @lindley1956measure] as a conceptual tool to bring social learning processes into contact with the underlying decision making that supports active learning. The key insight is that learning in the presence of other people plays a direct role in determining the *usefulness* of different actions. I organized the paper as follows. First, I define  "active" and "social" learning to provide limits on the scope of phenomena that the integrative account aims to address. Then, I review the behavioral evidence showing that social ([Part I](#p1)) and active ([Part II](#p2)) contexts change how learning unfolds. From there I present the theory of Optimal Experiment Design (OED) ([Part III](#p3)) as a formal framework for understanding the decision-making process that supports active learning. Finally, I conclude by highlighting a series of novel links between social learning account and self-directed choice, taking a step towards understanding how active learning unfolds within social contexts ([Part IV](#p4)).

# The scope of the problem

Many theories of cognitive development consider the relative contributions of "active" learning and "social" input to children's cognitive development. As a result, the terms are semantically "overloaded." So before reviewing the empirical evidence for the social and active learning accounts, it is worth defining "active learning" and "social contexts." In this section, I also scope the behaviors that the integrative account attempts to explain and highlight several distinctions that come up throughout the paper, including the different *timescales* through which social contexts affect active learning and the importance of others' goals for explaining social learning phenomena. 

Learning can be "active" in a variety of ways. First, a child could be physically active, and this movement could change what information they extract from the experience. There is a large body of research that explores the effects of action experience on infants' learning (see @kontra2012embodied for a review of work on embodied cognition). One classic example from @needham2002pick shows that infants who physically hold and manipulate objects will outperform a control group who did not have the equivalent physical experience on measures of object attention and exploration. Second, active learning could refer to children's contributions to processing incoming information. For example, young learners do not just passively accept other people's claims and will reject answers that conflict with their knowledge [@pea1982origins]. Third, children might engage in self-generated "active" explanations. @lombrozo2006structure review evidence that 'self-explanation' (i.e., explaining novel information to oneself) can lead to better learning. Finally, active learning could refer to the output of a decision-making process where learners select, sequence, and pace their own learning experiences (see @gureckis2012self for a review).

Here, I focus on active learning effects that arise via decision making. The key assumption is that active learners are trying to maximize the usefulness of their actions when choosing to gather information. By scoping the paper to information seeking *decisions*, we do not aim to ignore the importance of other forms of active learning; instead, my goal is to constrain the space of possible connections between active and social learning theories. Moreover, decisions during active learning still capture a rich variety of behaviors, including pointing, eye movements, verbal question asking, and causal interventions. 

Learning can also be "social" in a variety of ways. First, children could learn with another person present but without attending to or directly interacting with that person. Research in social psychology shows that the mere presence of other people can facilitate performance of simple tasks and impair the performance of complex tasks [@uziel2007individual; @cottrell1968social]. Second, children could learn by looking to others as a guide, observing or imitating their behavior. In fact, children's capacity for faithful imitation is a critical feature separating human from non-human learning [@call2005copying]. Finally, children could both attend to the person and directly interact with them, entering a communicative learning context that engages powerful psychological reasoning that change learning processes. 

In this paper, I define a "social context" as a learning environment where another agent is present. This definition includes all of the social learning behaviors -- observation, imitation, and learning from direct interaction -- discussed above. I use a broad definition to highlight the variety of ways that social contexts could shape children's decisions during learning. It is important to point out that the effects of social input could operate on at least three timescales: (1)  in-the-moment (e.g., imitating another person), (2)  over development (e.g., prior social input shaping current decisions), and (3) over cultural/evolutionary history (e.g., learning 
a conventionalized language system). This paper does not focus on timescales, but in particular sections, I highlight when they are relevant to the discussion. 

In sum, the goal of this paper is to propose an integrative account of active learning within social contexts. I chose a specific definition of active learning -- choices to seek information -- and I will show that a range of social learning effects could shape these decisions. Before presenting the integrative account, I review evidence that both social and active learning (a) modulate processes such as attention and memory, (b) provide information that is particularly "good" for learning, and (c) change the strength of children's inferences and generalization.

# Part I: Learning from other people {#p1}

Social learning theories argue that children's rapid conceptual development is facilitated by the uniquely human capacity to transmit and acquire information from other people. One primary benefit of learning from other people is that children gain access to knowledge that has accumulated over many generations; information that would be far too complex for any individual to figure out on their own [@boyd2011cultural]. In addition to the cumulative effects, social contexts facilitate in-the-moment learning since more knowledgeable others can select input that is most useful for learning [@shafto2012learning; @kline2015learn] and likely to generalize beyond the current context [@csibra2009natural].

There is a large body of empirical work on social learning across a variety of domains, e.g., language acquisition, causal learning, and concept learning. Importantly, these social learning effects operate through different pathways such as guiding attention, providing better information, and changing the strength of children's inferences. In this section, I briefly review the evidence for each pathway, with the goal of providing a high-level taxonomy of social learning effects. 

```{r table1, results = "asis"}
learning_type_table <- read_csv(file = "tables/active_social_overview.csv", trim_ws = T)
bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(xtable(learning_type_table,
             align = c('l', 'p{1.5in}', '|', 'p{2in}', '|', 'p{2in}'),
             label = "act_soc",
             caption = "High level summary of three different paths through which active and social contexts influence learning. See Part I (social learning) and Part 2 (active learning) for more details and reviews of the behavioral evidence."
             ),
      include.rownames=FALSE, 
      hline.after=c(0,1,2,3),
      sanitize.text.function=function(x){x},
      sanitize.colnames.function=bold,
      caption.placement = 'top', 
      table.placement = "tb",
      comment = F)
```

## Social contexts enhance attention and memory

From infancy humans preferentially attend to social information. For example, newborn infants prefer to look at face-like patterns compared to other abstract configurations [@johnson1991newborns] and even show a preference for faces that make direct eye contact compared to faces that avert gaze [@farroni2002eye]. In the auditory domain, newborns prefer to listen to speech over non-speech [@vouloumanos2007listening], their mother's voice over strangers' voices [@decasper1987human], and infant-directed speech over adult-directed speech [@cooper1990preference; @pegg1992preference; @fernald1987acoustic]. Moreover, recent work by @yu2016social, using head-mounted eye trackers to record parent-child interactions, shows that one-year-olds will sustain visual attention to an object longer when their parents had previously looked at that object.

These early attentional biases lead to differential learning in the presence of another person. For example, 4-month-olds show better memory for faces if that face gazed directly at them as compared to memory for a face with averted gaze  [@farroni2007direct]. They also show enhanced memory for objects if an adult gazed at that object during learning [@reid2005adult; @cleveland2007joint]. Converging evidence comes from @thiessen2005infant's work, showing that 7-month-olds perform better at word segmentation from infant-directed speech compared to adult-directed speech.

@kuhl2007speech refer to these effects as "social gating" phenomena since the presence of another person activates or enhances children's underlying computational learning mechanisms. One particularly striking piece of evidence for the social gating hypothesis comes from @kuhl2003foreign's study of infants' foreign-language phonetic learning. In this experiment, 9-
 to 10-month-old English-learning infants listened to Mandarin speakers either via live interactions or audiovisual recordings. Only the infants who heard Mandarin within social interactions were able to discriminate Mandarin-specific phonemes. In contrast, infants in the audiovisual recording condition showed no evidence of learning. @kuhl2003foreign also found that infants in the social interaction condition had higher rates of visual attention to the speaker, suggesting that the social context enhanced learning by increasing children's attention to the input.
 
Converging evidence comes from studies showing that when adults interact with an avatar controlled by a person rather than a computer, they experience higher levels of arousal, learn more, and pay more attention [@okita2008mere]. And recent work by @roseberry2014skype found that children learn equally well from interactions with a person in a video chat (e.g., Skype) if they established social contingency, but they did not learn from watching communication between an adult and another child.

The common thread across this work is that the presence of another person increases attention. And as a result, social input becomes more salient and more likely to come into contact with general learning mechanisms. These changes occur within the child (endogenous effects) and in-the-moment of learning. However, social contexts can also provide better information, leading to exogenous effects on learning. In fact, social learning theories often start from the premise that early environments are unique because children are surrounded by people who know more than they do. Moreover, these individuals are invested in children's learning. Togher, these features create contexts where more knowledgeable others select learning experiences that are particularly beneficial.

## Social contexts provide "good" information

The idea that children's input might be shaped to facilitate their learning is a fundamental aspect of several theories of cognitive development (e.g., Zone of Proximal Development [@vygotsky1987zone], Guided Participation [@rogoff1993guided], and Natural Pedagogy [@csibra2009natural]). But how do social environments provide useful information? 

One compelling set of evidence is that caregivers alter their communication style when speaking to children. Empirical work shows that when adults talk to children, they exaggerate prosody, reduce speed, shorten utterances, and elevate both pitch and affect (for a review, see @fernald1984expanded). Subsequent empirical work shows that these features can help infants solve a variety of language acquisition challenges, including vowel learning [@adriaans2017prosodic; @de2003investigating], word segmentation [@fernald1991prosody; @thiessen2005infant], word recognition [@singh2009influences], and word learning [@graf2013infant]. 

Additional evidence that social contexts provide information tuned to individual learners comes from work on infants' early vocal production. For example, @goldstein2008social measured whether infants modified their babbling to produce more speech-like sounds after interacting with caregivers who provided either contingent or non-contingent responses to their infants' babbling. They found that only infants in the contingent feedback condition changed their vocalization behavior to produce more adult-like language forms. @goldstein2008social hypothesized that the contingent input was particularly useful because it occurred soon after infants' vocalizations, making it easier for them to compare any discrepancies. 

Converging support comes from research on children's early word learning where social-pragmatic theories of language acquisition have long emphasized the importance of social cues for reducing referential uncertainty [@bloom2002children; @clark2009first; @hollich2000breaking]. Empirical work by @yu2012embodied shows that young learners tend to retain words that are accompanied by clear referential cues (e.g., adults' pointing and gaze direction), which serve to make a single object dominant in the visual field  [@yu2013joint; @yu2005role]. Moreover, correlational studies show positive links between early vocabulary development and parents' tendency to refer to objects that children are already attending to (i.e., "follow-in" labeling) [@tomasello1986joint].

Together, these findings provide evidence that social contexts are likely to contain "useful" information. Similar to the attention/memory effects, these effects occur in-the-moment of learning. However, they are properties of the input, and their usefulness is derived from processes external to the learner, but internal to the learner's social partner (e.g., an adult reading the child's direction of gaze and providing a label).  Social contexts also shape learning by engaging a sophisticated set of social reasoning processes that change how much children learn from new evidence.

## Social contexts shape inferences and generalization

One defining feature of social learning is that people's actions are not random. Instead, people select behaviors with respect to some goal (e.g., to communicate a concept). If children are sensitive to others' goal-directed behavior, then they can reason about *why* someone chose an action. And this reasoning process can change how people interpret superficially similar behaviors.

Recent empirical and modeling work has formalized this social reasoning process within the framework of Bayesian models of cognition [@shafto2012learning; @frank2014inferring; @goodman2016pragmatic]. Under this account, social learning is as a process of belief updating that depends on two factors: the learner 's beliefs before seeing any evidence and what the learner thinks about the process that generated the evidence. If the learner assumes that someone selects an action with the intention to communicate, they can make "stronger" inferences. ^[Formally, these models change the likelihood term in Bayes theorem to capture a personâ€™s theory of how data are generated. I will discuss  links between this formalization and the active learning account in [Part IV](#p4).]

For example, @goodman2009cause presented adults with written descriptions of the following causal learning scenarios. Someone generates a causal effect (e.g., growing flowers) by performing two actions at the same time (e.g., pouring a yellow liquid and a blue liquid). The person who generated the effect was either the participant or another person who already knew the causal structure. The participants' task was to identify the correct causal structure. When participants thought the other person was knowledgeable, they were more likely to think that performing *both* actions was necessary. In contrast, when the participant-generated the causal effect on their own (not knowing the causal structure), adults were less sure that both actions were necessary. @shafto2012learning interpreted these results as a psychological reasoning process such as "if the other person were knowledgeable and wanted to generate the effect, then he would perform both actions." This finding also suggests that learners assume that others' goal-directed behaviors will be efficient since they should avoid performing extra actions (e.g., pressing two buttons). 

Similar effects of psychological reasoning on inference occur in word learning [@xu2007word; @frank2014inferring], selective trust in testimony [@shafto2012epistemic], tool use [@sage2011disentangling], and concept learning [@shafto2014rational]. Moreover, there is evidence that even young learners' inferences are sensitive to the presence of goal-directed behaviors. For example, @yoon2008communication showed that 8-month-olds encode an object's identity if attention was directed by a communicative point, but they will encode an object's spatial location if attention was directed by a non-communicative reach. And @senju2008gaze found that infants will follow another person's gaze only if the gaze event was preceded by relevant, communicative cues (e.g., infant-directed speech or direct eye contact). 

In addition to being easier to learn, information from other people is more likely to generalize beyond the current learning context. @csibra2009natural argue that an assumption of *generalizability* is fundamental to "Natural Pedagogy" -- a uniquely human communication system that allows adults to pass cultural knowledge to children. In these contexts, adults generate ostensive signals such as direct gaze, infant-directed speech, and infant-directed actions. These signals, in turn, direct infants' attention towards the adult, and bias infants to expect generalizable information.

Experimental work testing predictions of Natural Pedagogy shows that children tend to think that information presented in communicative contexts is generalizable [@yoon2008communication; @butler2012preschoolers]. For example,  @butler2012preschoolers showed that preschoolers were more likely to expect a novel causal property (e.g., magnetism) to generalize to new objects with the same shape if the causal property was demonstrated with pedagogical cues. Moreover, corpus analyses show that generic language (e.g., "birds fly") is common in everyday adult-child conversations [@gelman2008generic], suggesting that this generalizable information is prevalent in children's daily experience.

Across these studies, learners interpreted similar information in different ways depending on their assumptions about others' goals. These effects are different from the attentional (internal to the learner) and informational (external to the learner) explanations reviewed above in that the inferences based on social information are part of the underlying computations that support learning. However, parallel to Kuhl's Social Gating account, Natural Pedagogy argues that the presence of pedagogical cues enhances processes internal to the learner such as attention. These theories and empirical work receive additional support from evolutionary models that emphasize the importance of pedagogy for the accumulation of human cultural knowledge [@kline2015learn; @boyd2011cultural].

## Social learning summary

The work on social learning reviewed in this section highlight several points. First, from an early age, children are surrounded by other people who know more than they do. Moreover, these more knowledgeable agents are invested in children's development and motivated to provide good learning opportunities. Second, children are driven to interact with other people, and these interactions are engaging and social partners guide attention to relevant information. Finally, social learning triggers a set of psychological reasoning mechanisms that build off children's capacity for detecting goal-directed behavior. Critically, the output of this reasoning is stronger inferences, allowing children to get more information out of the same amount of input. 

However, it is clear that social input cannot account for all of children's rapid conceptual development, and that children are not just passive recipients of input from the world or other people. Instead, they actively process information and select behaviors that change what they learn. A parallel body of research on this topic -- under the umbrella term of "active learning" -- has developed alongside social learning theories. In the next section, I present the active learning account and the empirical work with the goal of clarifying the variety of ways that children shape their learning.


# Part II: Learning on your own {#p2}

The idea that children are "active" learners has also been an influential aspect of classic theories of cognitive development (e.g., @bruner1961act; @berlyne1960conflict). Moreover, recent theorizing has characterized cognitive development as a process of active hypothesis testing and theory revision following the principles of scientific inquiry [@schulz2012origins; @gopnik1999scientist]. Under this account, children drive their conceptual development by selecting actions that create meaningful learning experiences. 

The effects of active learning have also been the focus of a great deal of empirical work in education [@grabinger1995rich; @prince2004does], machine learning [@settles2012active; @ramirez2017active], and cognitive psychology [@castro2009human; @chi2009active]. The common thread across these diverse bodies of work is that active contexts -- where people have control over their experience -- lead to different (and often more rapid) learning outcomes when compared to passive contexts where people do not have control over the flow of information. 

But how does active control change the way people learn? In this section, I present evidence for three mechanisms. These pathways parallel the social learning effects reviewed in [Part I](#p1). First, active learning contexts enhance attention and memory, leading to stronger learning. Second, active learners use their uncertainty to select experiences that cater to their goals, beliefs, and capabilities. Third, active learning results in weaker inferences and generalization since there is no guarantee that self-generated examples will be informative.  I conclude [Part II](#p2) with a discussion of why active learning might be particularly challenging to study. These challenges motivate the formalization of human inquiry as Optimal Experiment Design that I present in [Part III](#p3).

## Active contexts enhances attention and memory

A growing body of research shows that active control changes processes such as attention and arousal that support learning.  In these experiments, researchers have compared learning outcomes for active and passive contexts across a variety of tasks such as episodic memory, casual intervention, and concept learning. The common finding is that active contexts result in faster and more robust learning. In a review of this literature, @markant2016enhanced propose that an increase in attention and memory drives these active learning advantages, with the precise effect determined by the type of control given to the learner (e.g., timing,  content, timing & content). 

For example, consider a child who is playing with a set of toys and turns to ask their parent, "What's this?" Here, the child is in control of both the selection (which toy gets labeled) and the timing (when the labeling event occurs) of information.  

One compelling demonstration of these different types of control comes from @markant2014deconstructing  where they "deconstructed" the active learning process. Participants were asked to memorize the identities and locations of objects hidden in a grid. @markant2014deconstructing varied the *level* of control that participants had over the learning experience. Participants could control either: (1) the next location in the grid, (2) which item to reveal next, (3) the duration of each learning trial, and/or (4) the time between learning trials (i.e., inter-stimulus-interval or ISI). There was also a "yoked"  control group of participants who saw the training data generated by the active learners. The yoked condition is critical for equating the informational content across learners while varying the level of control. There was an advantage in spatial memory for all levels of active control, including the lowest amount in the ISI-only condition. These results suggest that learners benefitted from being able to coordinate the timing of information with their attentional processes, starting the next trial after they finished processing the previous one and once they were ready to learn something new.

Developmental studies have also used this "decomposition" approach and found parallel active learning advantages for 6- to 8-year-oldsn in a spatial memory task [@ruggeri2016active]. Other work has found similar benefits of active control in word learning (@partridge2015young; see also @kachergis2013actively for evidence in adults) and understanding causal structures [@schulz2012origins]. For example, @sobel2006importance showed that preschoolers who generated interventions on a causal system learned more compared to yoked participants who either passively observed the same sequence of actions or re-created the same choices made by others (but see @mccormack2016children). Moreover, even young infants benefit from active engagement with the learning environment. For example, @begus2014infants found that 16-month-olds show better memory for information provided about an object they had demonstrated an interest in via pointing compared to an object that infants had previously ignored.

Additional evidence that active control enhances attention and memory comes from research on children's engagement with educational technology (for a review, see @hirsh2015putting). For example, @calvert2005control exposed preschool-aged children to two sessions of reading a computer storybook with an adult and manipulated whether the adult or the child controlled the mouse and could advance the story. Children in the adult-control condition showed a decrease in attention to the storybook materials in the second session. In contrast, children who were given control maintained a constant level of engagement across both sessions, suggesting that active control provided a buffer against children losing interest in a repetitive task.

These results parallel the literature on attention/memory effects in social learning reviewed in [Part I](#p1). That is, both active and social processes can modulate processes internal to the learner to facilitate in-the-moment learning. However, the effects of active control go beyond changing lower-level cognitive processes and modulate the quality of *information* that learners get from the world.  

## Active contexts provide "good" information

One defining feature of active learning is that people gather information that is useful for their development. This benefit arises because the learner has privileged access to their prior knowledge, current hypotheses, which they leverage to create more helpful learning contexts (e.g., asking a question about something that is particularly confusing). Research on this benefit of active learning focuses on how learners select actions to generate useful information, often comparing learning outcomes to passive contexts where the learner does not have control over the environment. 

For example, @castro2009human directly compared adults category learning in active vs. passive contexts to predictions from statistical learning theory to quantify how well active learners do when compared to a model of optimal active learning. Participants were shown a sequence of 3-D objects on a computer screen that varied along a single, continuous dimension (spiky to smooth) and given feedback as to which category the stimulus belonged to. Participants task was to learn the correct category boundary. In the active condition, learners could select which object they wanted to be labeled; whereas, in the passive condition, participants saw stimuli generated randomly from the correct categories. Active learning was always superior to passive learning with adults learning the category structure in less time and achieving higher levels of accuracy. However, human learners did not reach the performance of the ideal observer model, and the advantage for active over passive learning decreased in the more difficult (i.e., noisier) learning tasks. 

Using a similar approach, @markant2014better investigated the effects of active vs. passive hypothesis testing on the rate of adultsâ€™ category learning. They varied the difficulty of the learning task by testing two different types of category structures: a rule-based category, which differed along a single dimension (easier to learn), and an information-integration category, which varied along two dimensions (harder to learn). In the active condition, the learner could choose specific observations to test their beliefs; whereas, in the passive version, the sequence of data was generated randomly by the experiment. @markant2014better also included a "yoked" condition where participants saw sequences of observations created by active learners but did not have control over the sequence. Similar to the @castro2009human findings, active participants learned the category structure faster and achieved a higher overall accuracy rate compared to the passive learners and the yoked-passive learners. @markant2014better suggest that the active learning was better because self-generated observations take into account the learner's hypothesis. Importantly, the advantage for active learners over the yoked participants suggests that the information value was linked to the individual learner. Also, the active learning advantage only held for the more straightforward, rule-based category.

The effects of active engagement also show up in studies of language use. @schober1989understanding asked pairs of adults to complete a task where one person (the director) used natural language to inform another person (the matcher) what order to arrange tangrams (geometric objects, called tans, which are put together to form shapes) in a 4x4 matrix. The matcher had a different level of control depending on condition assignment: (1) could actively participate (i.e., talk to the director), (2) could listen to the recorded conversation of director-matcher and pause the tape, and (3) could listen to the entire discussion but not pause the tape. Results showed that active participation led to a marked advantage over passive listening. Interestingly, the ability to stop the tape did not improve accuracy, suggesting that the active advantage was caused by informational value and not by control over the timing/ pacing of information. Also, participants in the passive conditions reported frustration (e.g., "I don't know what 'this one' means!) with being unable to correct early failures of understanding the novel conventions developed by the director. This result highlights the point that no amount of control over timing could make up for the lack of control of information *content* in the overhearing conditions. @schober1989understanding propose that conversations are a form of active information gathering about other people's intentions, and when people are unable to participate, they lose access to critical information that supports later comprehension.

These findings on active learning illustrate several points. First, the quality of active exploration was fundamentally linked to the learner's understanding of the task: if the representation was weak, then self-directed learning was less useful.  Second, the benefits of active control were tied to the individual learner's prior knowledge and current hypotheses such that the same sequence of data did not provide "good" information for another person. And third, the benefits of active learning diminished with increased task difficulty because learners struggled to generate helpful examples. These challenges will come up again in [Part III](#p3) when I outline the formalization of human inquiry.

### Children's active learning

Are young children capable of generating useful information to support their learning? Recent research on children's pointing shows that young learners, who are not yet capable of more sophisticated information seeking behaviors such as verbal questions, can use nonverbal actions to facilitate learning. For example, @wu2015caregivers found that adults generate a higher number of object labels for objects that their 12-month-olds pointed to, suggesting that the infants' pointing elicited information that was especially useful for concrete word learning (for converging evidence, see @kishimoto2007pointing; @goldin2007young; and @olson2011infants). Moreover, work by @begus2012infant found that infants point more in the presence of a knowledgeable person compared to an incompetent person, suggesting that points signal a desire to learn as opposed to sharing attention. Finally, infants who produce more pointing gestures have larger vocabularies later in development [@rowe2009early], providing additional evidence that even young infants are capable of generating actions that elicit information to support learning. 

Later in development, when children being to acquire the requisite productive language skills, they start asking verbal questions to gather information. For example, in a corpus analysis of four children's parent-child conversations, @chouinard2007children found that children begin asking questions early in development (18 months) and at an impressive rate, ranging from 70-198 questions per hour of conversation. @chouinard2007children also coded the children's intent, finding that 71% of questions were to gather information, as opposed to seeking attention or clarification. Other corpus analyses provide converging evidence that questions are common in parent-child conversations [@davis1932form] and that children use them to gather knowledge [@bova2013investigating], persisting when they do not receive a satisfactory explanation [@frazier2009preschoolers]. 

Perhaps the most robust evidence that children are capable of efficient self-directed learning comes from research on causal learning. In these studies, children see a novel toy with an unknown causal structure. Then they play (design experiments) to figure out how the toy works. A nice feature of these studies is that the space of possible actions and hypotheses are constrained such that it becomes possible to quantify the usefulness of children's causal interventions compared to the predictions of formal models of optimal information seeking (see [Part III](#p3)). Specifically, empirical work has found that preschoolers integrate prior beliefs and evidence to alter how they explore a causal system (e.g., testing a toy to learn the concept of balance-relations) [@bonawitz2012children]. Children spend more time exploring an object for which they saw confounded evidence for its causal structure, i.e., where there was more to be learned [@schulz2007serious]. And children become more efficient in producing causal interventions, as measured by informativeness, as they get older (6-8 years of age) [@mccormack2016children]. 

Moreover, even 8-month-old infants selectively explore objects that violate their prior expectations. @stahl2015observing showed infants events that violated an expectation about objects, either solidity, continuity, or support. They coded the types of actions that infants chose to perform on the objects during subsequent free play. Infants explored differently depending on the type of violation (e.g., banging the object after seeing a violation of solidity). The infants also spent more time playing with objects that violated expectations, and as a result, learned more about them. These results demonstrate an early sensitivity to uncertainty with infants using actions to test specific hypotheses linked to their prior experience.

Converging evidence comes from research on selective visual and auditory attention. These studies start from two assumptions: that children possess limited cognitive resources and that children would benefit by attending to information that is likely to be learned. For example, @kidd2012goldilocks  measured 7- and 8-month-olds' visual attention to a monitor that displayed a sequence of familiar objects (e.g., a toy truck). Within each series, infants saw trials that varied along a continuum from low to high complexity.  Complexity was a measure of how surprising the current object was relative to the previous objects in that sequence. For example, if there were two objects (truck and ball) in a set, and the child saw [Truck-Truck-Truck-Truck] and the next trial was Truck, then this would be low surprisal/complexity. In contrast, if the child had seen the sequence [Truck-Ball-Ball-Ball] and the subsequent trial was a Truck, then this trial would be high surprisal/complexity. 

Infants looked longest on trials of intermediate complexity, choosing to disengage sooner when the object was either highly predictable or highly surprising. @kidd2014goldilocks extended these results to the auditory domain, showing a similar pattern of increased attention to sequences of intermediate complexity for nonsocial sounds such as a door closing or a train whistle. Kidd and her colleagues interpret these results as infants using prior experience to guide selective attention to find learnable information that is neither too simple (nothing to be gained) nor too complicated (too much to process).

There is also evidence that infants avoid spending time on information that is unlearnable. For example, @gerken2011infants tested whether 17-month-olds would increase attention to a stream of input that consisted of a learnable structure (i.e., Russian feminine words take the endings oj and u, and masculine words take the endings ya and yem) as opposed to a random stream of input without any information to extract (i.e., word endings that are not diagnostic of category structure). Infants dishabituated sooner when listening to the unlearnable stream, suggesting that they were tracking the pace of learning and choosing to stop information gathering if progress was low. 

## Active contexts shape inferences and generalization

Active learning contexts also change the strength of inferences and generalization.  In contrast to the social learning effects discussed in Part I, active learners show evidence of "weak" sampling assumptions, leading to less-restrictive inferences and generalization. That is, active learners are aware that there is no guarantee that the information they generate is informative, and they will adjust how much they update beliefs if there is a reason to think that the examples are not representative of the correct concept.

For example, @xu2007sampling tested 4-year-olds and adults' word generalization. In the task, participants learned the correct extension of a novel word after seeing three examples drawn from a set of 30 unfamiliar objects. The set of objects consisted of two basic-level categories (15 objects) and within each of the basic categories, there were three smaller, subordinate categories (5 objects) that varied in color, texture, and orientation. Participants saw three labeled examples from the subordinate category. The critical manipulation was whether the examples were selected by a teacher who knew the correct word extension (social) or by the learner (active) who did not know the appropriate extension. Both adults and children made stronger inferences in the teacher-driven condition, saying that the new word referred to the subordinate category; whereas, in the learner-driven case,  children/adults tended to generalize the word to the basic-level. 

@xu2007sampling explain these results as a sensitivity to the process that generated examples. When a knowledgeable teacher produced the labels, there was the good reason to think that the examples were linked to word meaning. Thus it would be surprising to see three examples from the smaller subordinate category. However, the active learners had no reason to think they generated examples from the true category, and therefore should extend the novel word more broadly to the basic-level. The upshot of this work is that even young children appear sensitive to the informativeness of the process that generates examples. And use this information to change how much they update beliefs based on new evidence. 

## Active learning summary

The work on active learning reviewed in this section highlights several points. First, from an early age, children are capable of efficient information seeking. Second, active learning is a complex area of research, covering a wide range of actions (e.g., pointing, visual attention, causal interventions, and verbal questions) and supported by a variety of cognitive processes. Moreover, active learning is by definition linked to the idiosyncrasy of individuals, and thus, does not function similarly across individuals, contexts, and learning domains. Finally, there is a multitude of factors that could influence the quality of children's active learning, creating a broad space of possibilities for researchers to test. 

One way to constrain the space of hypotheses is to construct a formal model of the information seeking process. One useful approach is to perform an ideal observer analysis [@geisler2003ideal] where a model is created to solve a task using all of the available information in the environment. That is, the model is not affected by processing constraints such as limited attention or memory, and as a result only produces errors based on the complexity or uncertainty present in the environment. By ignoring the process level, these models allow researchers to focus on the structure of the learning task and the information available in the world. Moreover, the "ideal" model performance can then be compared to human behavior to see how much of the available information do people use to solve the problem. This approach does not aim to make claims about human optimality; instead, the ideal-observer is a method for scientific progress since it forces researchers to explicitly define the process of active learning as separable, underlying components, which can become the target of more focused research. 

Over the past three decades, researchers in both developmental and cognitive psychology have used the ideal-observer approach to understand human inquiry. Researchers have leveraged formal models of scientific research that fall under the umbrella term Optimal Experiment Design (OED). The original purpose of the OED model was to help scientists select the best experiment from a set of possible experiments, where "best" is the most information to gain about a scientific phenomenon. Using this formalization, researchers have asked whether children's information seeking behaviors look qualitatively similar to predictions from OED models. 

Moreover, this approach has the benefit of using the same mathematical formalization as recent models of social learning: Bayesian ideal observer models [@shafto2012epistemic; @frank2009using; @goodman2016pragmatic]. These parallel formalizations suggest a way forward for integrating the active and social learning theories. This point is the focus of [Part IV](#p4).   

\afterpage{
```{r fig.pos = "H", out.width="100%",fig.cap = "\\textit{Schematic of an active causal learning context using the decomposition of Optimal Experiment Design. The learner generates an inquiry goal to learn how the toy works. She then considers hypotheses, including her subjective belief in each, placing stronger belief in the simpler, disjunctive hypotheses: only Button A or Button B. Next, she considers her possible queries (actions) and the potential outcomes if she took those actions. Together, these components quantify the expected usefulness of each action. If the learner chooses optimally, she picks the action that maximizes this expected utility. In this case, she chooses to press either Button A or B, but does not press both buttons since this action would produce confounded evidence and fail to reduce her uncertainty. See Part III in the text for mathematical details of the OED model.}"}

grid::grid.raster(png::readPNG("../cada_schematic/cada_schematic.001.png"))
```
\clearpage
}

# Part III: A formal account of active learning {#p3}

Optimal Experiment Design (OED) [@emery1998optimal; @nelson2005finding; @lindley1956measure] is a statistical framework for quantifying the "usefulness" of experiments.  @lindley1956measure described the approach as a transition from viewing statistics as binary decision making to a practice of gathering information about the "state of nature" (p. 987). The concrete proposal is to design studies that maximize expected information gain (a measure borrowed from Information Theory and discussed in more detail below) and continue to collect data until the information reaches a pre-determined threshold.

The OED approach allows scientists to make design choices that maximize the effectiveness of their experiments, reducing inefficiency and cost. Consider the following toy example borrowed from @ouyang2016practical where an experimenter is interested in designing the best experiment to figure out whether people think a coin is fair or biased (i.e., a trick coin). Here the researcher's hypotheses correspond to different models of the coin [$M_{fair}: Bern(\frac{1}{2})$] and [$M_{bias}: Bern(p)$ where $p \sim Uniform(0,1)$] and the experiments correspond to different sequences of coin flips that she could select as stimuli for the experiment. Imagine that the researcher has limited time or resources and can only show a sequence of four coin flips, creating a space of 16 possible experiments. An OED model allows the researcher to select the most informative experiment that maximally differentiates between the two hypotheses. More concretely, it provides an answer to the question of how much better it would be to use [$HHHH$] versus [$HTHT$] in the experiment. In this example, [$HHHH$] is more informative because both the bias and fair models make the same predictions for the [$HTHT$] experiment, meaning we would not learn much from this test.

An applied example comes from @nelson2010experience where they used an OED model to differentiate competing theories of information seeking during adults' category learning. They created an OED model of their task: the possible design choices (e.g., what combination of features to show participants), and the relevant behavioral hypotheses (i.e., different theories of category learning). And using the model, they were able to simulate the outcomes of using different stimulus sets and choose the stimuli for which the competing theories made very different predictions, thus speeding the rate of discovery.

@coenen2017asking provide a thorough review of the OED framework and its links to human information seeking. They outline the four critical parts internal to an OED model: (1) a set of hypotheses, (2) a set of queries (i.e., actions) to learn about the hypotheses, (3) a way to model the types of answers that each query could elicit, and (4) a way to score each response with respect to the learning goal. They also highlight the importance of understanding learners' inquiry goals (i.e., what do people want to learn) for engaging OED-like reasoning. The critical point is that without a clear learning goal, it becomes challenging to instantiate the hypotheses, questions, and answers that a learner should consider. In the rest of this section, I provide the mathematical details of the OED approach as described in @coenen2017asking. The goal is to provide a concrete foundation for the conceptual analysis of how social learning contexts can influence different components of the OED model. 

The goal of an OED model is to formalize the relevant hypotheses, queries, and answers such that the learner can quantify the *expected utility* of different actions. Formally, the set of queries is defined as $Q_1, Q_2,..., Q_n = \{Q\}$. And the expected utility of each query ($EU(Q)$) is a function of two factors: (1) the probability of obtaining a specific answer $P(a)$ weighted by (2) the usefulness of that answer for achieving the learning goal $U(a)$.

$$EU(Q) = \sum_{a\in q}{P(a)U(a)}$$
\noindent
There are a variety of ways to define the usefulness function to score each answer. An exhaustive review is beyond the scope of this paper, but for a detailed analysis of different approaches for modeling information seeking actions, see @nelson2005finding. However, one standard method is to use the *information gain* of an answer defined as the change in the learner's overall uncertainty before and after receiving an answer. One way to instantiate this is to compute the difference in entropy (uncertainty) conditioning on a particular answer.

$$P(h|a) = ent(H) - ent(H|a)$$

\noindent
Where $ent(H)$ can be defined using Shannon entropy ^[Shannon entropy is a measure of unpredictability or amount of uncertainty in the learner's probability distribution over hypotheses. Intuitively, higher entropy distributions are more uncertain and harder to predict. For example, if the learner believes that all hypotheses are equally likely, then they are in a state of high uncertainty/entropy. In contrast, if the learner firmly believes in one hypothesis, then uncertainty/entropy is low.] [@mackay2003information], which provides a measure of the overall amount of uncertainty in the learner's beliefs about the candidate hypotheses. 

$$ent(H) = -\sum_{a\in A}{P(h)log_2P(h)}$$
\noindent
The conditional entropy $ent(H|a)$ computation is the same, but takes into account the change in the learner's beliefs after seeing a specific answer.

$$ ent(H|a) = -\sum_{h\in H}{P(h|a)logP(h|a)} $$
\noindent
And to calculate the change in the learner's belief in a hypothesis $P(h|a)$, we use Bayes rule. 

$$ P(h|a) = \frac{P(h)P(a|h)}{P(a)} $$ 

\noindent
If the researcher defines all these parts of the OED model (hypotheses, questions, answers, and the usefulness function), then selecting the optimal query is straightforward. The learner performs the expected utility computation for each query in the set of possible queries and picks the one that maximizes utility. In practice, the learner considers each possible answer, scores the answer with the usefulness function, and weights the score using the probability of getting that answer. 

There are several benefits of the OED formalization for understanding active learning. First, it forces researchers to define the different components of the active learning problem, thus making assumptions more explicit. Second, if researchers develop an OED model,  they can ask whether people's behavior deviates from the optimal predictions. Finally, casting information seeking as rational *choice* links psychology with other fields (economics, statistics, computer science) that have made progress in formalizing decision-making as a process of utility maximization that considers the costs and benefits of actions.

Before reviewing the behavioral evidence for OED-like reasoning in adults and children, I will present a worked example of how to compute the expected utility of a single query. The goal is to provide simple calculations that illustrate how reasoning about hypotheses, questions, and answers can lead to selecting useful actions. This example is slightly modified from @nelson2005finding . ^[In the [appendix](#app), I include example code to show how a researcher could instantiate these calculations as functions in the R programming language.] 

Imagine that you are a biologist, and in your research, you come across a new animal that you think belongs to one of two species: "glom" or "fizo." You cannot directly query the category identity, but you can gather information about the presence or absence of two features (eats meat and is nocturnal) that you know from prior research are more or less prevalent for the different species. The following probabilities summarise this prior knowledge:

  * $P(eatsMeat \mid glom) = 0.1$  
  * $P(eatsMeat \mid fizo) = 0.9$
  * $P(nocturnal \mid glom) = 0.3$  
  * $P(nocturnal \mid fizo) = 0.5$. 

\noindent  
You also know from your previous research that the prior probability of seeing a glom or a fizo in the wild.

  * $P(glom) = 0.7$ 
  * $P(fizo) = 0.3$ 

\noindent  
Based on this information, which experiment should you choose? Intuitively, it seems better to test whether the creature eats meat because an answer to this question provides good evidence about whether the animal is a fizo since $P(eatsMeat \mid fizo) = 0.9$. However, the OED computation allows the biologist to go beyond this intuition and compute precisely how much better it is to ask the "eats meat?" question. All the scientist has to do is pass her knowledge about the hypotheses and features to the expected utility computation. 

Here are the steps of the OED computation for calculting the utility of the "eats meat?" question. First, we need to use Bayes rule to calculate how much our beliefs would change if we received a "yes" or a "no" answer. ^[Note that the $P(eatsMeat)$ term is computed by taking $P(eatsMeat) = [P(eatsMeat \mid glom)P(glom)] + [P(eatsMeat \mid fizo)P(fizo)] = (0.1 \times 0.7) + (0.9 \times 0.3) = 0.34$]

$$ P(glom \mid eatsMeat) = \frac{P(eatsMeat \mid glom)P(glom)}{P(eatsMeat)} = \frac{0.1 \times 0.7}{0.34} = 0.21 $$ 

\noindent
Next, we calculate the uncertainty over the Species hypothesis before doing any experiment. We do this by computing the prior entropy.

$$
\begin{aligned}
ent(Species) &= -\sum_{h\in H}{P(h) \times log_2P(h)} \\
 &= [-P(glom) \times log_2P(glom)]+[-P(fizo) \times log_2P(fizo)]\\
 &= [-(0.7 \times log_2(0.7)] + [-(0.3 \times log_2(0.3)]\\
 &= 0.8
\end{aligned}
$$

\noindent
To calculate information gain, we also need to compute our uncertainty over hypotheses conditional on seeing each answer, or the posterior entropy. First for the "yes" answer:

$$ 
\begin{aligned}
ent(Species|eatsMeat = yes) &= [0.21 \times log_2(0.21)] + [0.79 \times log_2(0.79)]\\
 &= [0.21 \times log_2(0.21)] + [0.79 \times log_2(0.79)]\\
 &=  0.15
\end{aligned}
$$
\noindent
Next for the "no" answer:

$$ 
\begin{aligned}
ent(Species|eatsMeat = no) &= -\sum_{a\in A}{P(Species \mid eatsMeat = no) \times log_2P(species \mid eatsMeat = no)}\\
&= [0.95 \times log_2(0.95)] + [0.04 \times log_2(0.04)]\\
&=  0.62
\end{aligned}
$$
\noindent
Finally, to get the overall information gain of the "eats meat" **question** we weight the utility of each answer by its prior probability:

$$ 
\begin{aligned}
EU(Q = eatsMeat) &= \sum_{a\in A}{P(a)U(a)} \\
&= [P(eatsMeat = yes) \times ent(Species \mid eatsMeat = yes)] + \\& \qquad \qquad \qquad [P(eatsMeat = no) \times ent(Species \mid eatsMeat = no)]\\
&= [0.34 \times 0.15] + [0.66 \times log_2(0.61)]\\
&= 0.43
\end{aligned}
$$
If we perform the same steps to compute the expected utility of the "sleeps at night?" question, we get $EU(Q = sleepsNight) = 0.026$. So if the biologist wants to maximize her chances of gaining useful information, she should select the "eats meat?" experiment since $EU(Q = eatsMeat) > EU(sleepsNight)$.

\afterpage{
```{r fig.pos = "H", out.width="100%",fig.cap = "\\textit{Schematic of an active word learning context using the decomposition of Optimal Experiment Design. Social input (hearing a novel word) triggers an inquiry goal. Then the learner considers potential hypotheses for the candidate word-object links, weighting each hypothesis by its prior probability. In this case, the learner thinks that the new word is less likely to refer to the familiar object BALL. Next, he considers possible queries (actions) and the potential outcomes of those actions. Note that in the word learning context, the child must direct queries towards a social partner, which provides the learner with more possible queries: both verbal (questions) and nonverbal (eye gaze; pointing). Note that the social partner must interpret the goal of the child's nonverbal queries. If the learner selects the action to maximize expected utility, then he would ask the most informative question, which removes all uncertainty for the meaning of 'dax' -- 'What's that called?' If he does select the relatively less informative action of asking about a single object, he would be unlikely to ask about the familiar object BALL since there is less information to be gained from this query based on his prior beliefs.}"}

grid::grid.raster(png::readPNG("../cada_schematic/cada_schematic.002.png"))
```
\clearpage
}

### Evidence of OED-like reasoning in human behavior

A growing body of psychological research has used the OED framework as a metaphor for active learning. The idea is that when people make decisions, they are engaging in a similar process of evaluating the "usefulness" of these different actions relative to some learning goal. And, in turn, they select behaviors that maximize the potential for gaining information. One of the significant successes of the OED model is that it can be used to account for a wide range of information seeking behaviors, including verbal question asking [@ruggeri2015children], planning interventions in causal learning tasks [@cook2011science], and decisions about where to look during scene understanding [@najemnik2005optimal]. 

One compelling demonstration of the OED metaphor for human behavior comes from @nelson2005finding model of eye movements during novel concept learning. The model combines Bayesian probabilistic learning, which represents the learner's current knowledge as a probability distribution over a concept, with an OED model of the usefulness of eye movements. Here eye movements are modeled as a type of question-asking behavior that gathers information about the target concept from the visual world.  @nelson2005finding found that participants' eye movements aligned with predictions from the OED model. Specifically, participants changed the dynamics of eye movements depending on how well they learned the target concepts. For example, early in learning, when the concepts were unfamiliar, the model predicted a broader, less efficient distribution of fixations to all candidate features that could be used to categorize the stimulus. However, after the model learned the target concepts, eye movement patterns shifted, becoming more efficient and focusing on a single stimulus dimension. This shift from exploratory to efficient eye movements is exactly what adults did in the category learning task. 

Recent developmental work has used OED models to test whether children are capable of selecting efficient behaviors that maximize learning goals. For example, @legare2013use used a modified question asking game where 4- to 6-year-old children saw 16 cards with a drawing of an animal on them. The animals varied along several dimensions, including type, size, and pattern. Children could ask the experimenter yes-no questions to figure out which animal card was hidden in a box. @legare2013use coded questions as either constraint-seeking (narrowing the set of possible cards by gathering information about a particular dimension (e.g., "Is it red?"), confirmatory (questions that provided redundant information), or ineffective that did not provide any useful information (e.g., "Does it have a tail?"). All children produced a high proportion of the more useful, constraint-seeking questions. Moreover, the number of constraint-seeking questions was correlated with accuracy in guessing the identity of the card hidden in the special box. @legare2013use interpreted these results as evidence for OED-like reasoning in children's question asking. Other work using the question-game finds that children prefer to direct questions to someone who is knowledgeable compared to someone who is inaccurate or ignorant, providing additional support for the OED hypothesis [@mills2011determining; @mills2010preschoolers].

Another example of a direct link between OED models and children's behavior comes from @cook2011science study of causal learning. They showed preschoolers a device that played music when beads were placed on top of it and manipulated the usefulness of different actions that children could take to test the device. Half of the children saw evidence that all types of beads could make the machine work, while the other half learned that only specific types of beads (defined by color) could make it go. Next, children could choose one of two sets of beads to test the machine. In one set the beads were stuck together, in the other, they could be separated. Children who learned that only some of the beads worked were twice as likely to select the separable beads.  This finding suggests that children were reasoning about the amount of information they could gain by choosing the detachable beads since this choice would allow them to test each bead independently. In contrast, the children who believed that all beads worked had less to gain by picking the separable set. This result is compelling because it provides evidence that children's were reasoning about a decision (separable vs. stuck together beads) that would influence a future opportunity to generate useful information.

Although the OED approach has provided a formal account of seemingly unconstrained information seeking behaviors, there are several ways in which it falls short as an explanation of human self-directed learning. @coenen2017asking argue that OED models make several critical assumptions about the learner and the learning task, including (1) the hypotheses/questions/answers under consideration, (2) that people are actually engaging in some expected utility computation in order to maximize the goal of knowledge acquisition, and (3) that the learner has sufficient cognitive capacities to carry out the calculations. 

In the next section, I argue that limitations of the OED approach can be productively reconstrued as opportunities for understanding how learning from other people can scaffold active learning. I focus on integrating research and theory on social learning with five key components of the OED model: inquiry goals, hypotheses, questions, answers, and stopping rules. The key insight is that learning from more knowledgeable others provides the building blocks for children to engage in productive self-directed learning.

# Part IV: Active learning within social contexts {#p4}

Why should social contexts shape active learning? First, children do not re-invent knowledge of the world, and while they can learn a tremendous amount from their behaviors, much of their generalization and abstraction is shaped by input from other people. Moreover, social learning can sometimes be the only way to learn something. And children are often surrounded by parents, other adults, and older peers â€“ all of whom may know more about the world than they do, creating contexts where the opportunity for social learning is ubiquitous. 

Second, there is a body of empirical work showing that active learning can be biased and ineffective in systematic ways. For example, work by @klahr2004equivalence showed that elementary school-aged children were less effective at discovering the principles of well-controlled experiments from their self-directed learning, but were capable of learning these principles from direct instruction. @markant2014better showed that active exploration provided no benefit over passive input in category learning when there was a mismatch between the target concept and adults' prior hypotheses going into the learning task. And @mccormack2016children found that 6-7 year-olds showed no benefit from active interventions on a causal system compared to observing another person perform the interventions.

In a comprehensive review of the self-directed learning literature, @gureckis2012self point out that the quality of active exploration is linked to aspects of the learnerâ€™s understanding of the task: if the representation is weak, then self-directed learning will be biased and ineffective. @coenen2017asking go a step further and propose specific challenges for research on active learning. Here is a sampling of those open questions that are most relevant to my argument:

  *  What triggers inquiry behaviors in the first place?
  *  How do people construct a set of hypotheses?
  *  How do people generate a set of queries?
  *  What makes a "good" answer?
  *  How do people generate and weight possible answers to their queries?
  *  How does learning from answers affect query selection and belief change?

\noindent
In the next section, I propose that social learning theories and findings have something to say in addressing these challenges. I use the OED model outlined in @coenen2017asking as a starting point for defining inquiry behavior and use it to integrate the social and active learning accounts. The benefit of this formalization is that it makes the different components of active learning explicit, making salient the aspects that might be particularly challenging for young learners with limited cognitive resources.  I propose that we can reconstrue the "limitations" of the OED account as opportunities for understanding the role of other people in children's active learning. In each sub-section, I first define the challenge of active learning. Then, I discuss how social contexts could address each challenge while highlighting prior research that connects the active and social learning accounts.

## Goals

An inquiry goal refers to the underlying motivation for people's information seeking behaviors. Often this is defined as a search for the correct hypothesis amongst a set of candidate hypotheses. Intuitively, an inquiry goal is what drives people to learn. Some examples of plausible inquiry goals include:

  * Is this person a reliable source of information? (selective learning)
  * What is this speaker referring to? (word learning)
  * What types of objects are called "daxes"? (category learning)
  * How does this toy work? (causal learning)
  * Where should I look next? (allocation of visual attention)

\noindent
Without an explicit inquiry goal, it becomes difficult for an active learner to compare the utility of different behaviors since the learner cannot evaluate how an action will lead to learning progress. @coenen2017asking illustrate this point by pointing out how researchers often go to great lengths to communicate the specific inquiry goal of an experimental task, saying: 

> The importance of such goals is made clear by the fact that in experiments designed to evaluate OED principles, participants are usually instructed on the goal of a task and are often incentivized by some monetary reward tied to achieving participants that goal. Similarly, in developmental studies, children are often explicitly asked to answer certain questions, solve a particular problem, or choose between a set of actions. (p. 32-33)

\noindent
Characterizing children's goals becomes critical for evaluating the role of self-directed behavior in cognitive development. However, this is not easy since children could be considering a wide range of goals at any moment and there is no guarantee that learning progress is one of them. In fact, one line of theorizing about the OED hypothesis as a model of human inquiry argues that we should only expect to see effective information seeking in contexts where there are precise tasks and learning goals. For example, when a parent gives their child a new toy with several buttons on it and says, "Let's figure out how this toy works!" In this case, it becomes possible to ask whether the child approaches the task efficiently by selecting actions that provide useful information about the toy's causal structure.   

This example illustrates how children's interactions with other people could play a role in triggering inquiry behavior. Both adults and older peers can construct contexts with clear learning goals to support children's information seeking. This connection draws on influential ideas in cognitive development that frame social learning as a form of scaffolding (Zone of Proximal Development [@vygotsky1987zone], Guided Participation [@rogoff1993guided], and Guided Play [@weisberg2013guided]). Under these accounts, adults place children in contexts that present something new to be learned but importantly contain learning goals that are achievable given children's current capabilities. 

For example, @weisberg2013guided define "guided play" as an intermediate learning context, falling between unstructured free play and constrained direct instruction. Unfortunately, the boundaries between these contexts are underspecified and challenging to define, but the critical dimension is the level of control that the adult exerts over the activity. They present the following example to illustrate the key difference between guided play and direct instruction.

> For example, a teacher with the goal of teaching new vocabulary words could take a direct instruction approach, by telling children the meanings of the new words they encounter in a storybook or by showing examples: "This is a helmet. A helmet goes on your head to stop your head from getting hurt if you fall off your bike." Or, she could take a guided-play approach, introducing the new words in the context of a child's play episode while encouraging children to think broadly about the word's meaning: "She's got a helmet on while riding her bike. What do you think would happen if she fell off her bike and wasn't wearing her helmet? (p. 106) 

\noindent
While these contexts appear quite similar, the key difference is whether the child initiated the activity. In free play, the child drives the interaction; whereas, in direct instruction, the more knowledgeable person explicitly tells the learner what to do, asks questions, and demonstrates new concepts. @weisberg2013guided hypothesize that the guided play context provides the right combination of structure with opportunity for exploration, leading to better learning outcomes.  

One less-emphasized feature of the Guided Play proposal is the adult initializing a clear learning goal. In the previous example, without the presence of a social partner, it is unclear what goals the child would pursue when playing with a storybook. However, the presence of an adult who has knowledge of the names of objects in the book and has the goal to teach changes the potential for the child to engage in information-seeking. We can frame this discussion in the terms the OED hypothesis, and say that one critical function of other people is to create contexts where there is something to learn. These settings trigger inquiry goals, which, in turn, sets the stage for children to reason about the actions could support learning (e.g., what question to ask or what object to point out).

In addition to communicating inquiry goals, the mere presence of others can affects children's tendency to detect whether they understand something. This capacity for explicitly reasoning about one's uncertainty is a component of metacognition and has been the focus of a great deal of developmental research (see @lyons2010metacognitive for a review). The upshot of this work is that while children might be capable of showing behaviors that are sensitive to uncertainty (e.g., selectively exploring an object with ambiguous causal structure), the ability to have explicit access to the underlying representation of uncertainty is slower develop. 

There are striking experimental demonstrations of children's failure to monitor their uncertainty. For example, @markman1979realizing had elementary school aged children read paragraphs with inconsistent information (e.g., "fish can't see without light, and there's no light at the bottom of the ocean, but some fish at the bottom of the ocean only know their food by its color."). After reading the paragraph, children answered 10 questions that gave them the opportunity to ask for clarification about the inconsistency. Overall, participants were not great at the task, as @markman1979realizing put it, "even highly motivated children" were unable to detect inconsistencies in the incoming information. However, if children were provided with a warning or a challenge to find a problem with the essay, they generated more questions, demonstrating higher rates of uncertainty monitoring.

While not discussed in these terms, @markman1979realizing "warning" manipulation can be reconstrued as an intervention of the social context on children's expectations. That is, children might approach social interactions with a default expectation that adults will provide complete information. ^[See the work on children's pedagogical sampling assumptions reviewed in [Part I](#p1)and the discussion of Answers later in this section for additional evidence that children's default assumption is that others will be helpful during communicative interaction.] But when the social context shifts these expections, then children are more likely to monitor the input for inconsistency, and in turn, more likely to generate inquiry goals. 

Converging evidence comes a study by @kim2016young's where they measured 3- to 4-year-olds' uncertainty monitoring in contexts where children either did or did not expect to communicate with another person. In the task, Children were either knowledgeable or ignorant about which toys an experimenter hid in a box. In the  "informing" condition, children had to tell another person about the contents of the box, but they were given the opportunity to "opt-out" of responding if they were unsure ("Max wants to know whatâ€™s inside the box. Can you help him? If you do not want to tell him, itâ€™s okay. I can tell him."). In the "explicit" condition, children just reported on their uncertainty. Interestingly, the children who had the potential to inform another person showed higher rates of uncertainty monitoring, opting-out of more often when they did not know what was inside the box. 
Similar to the @markman1979realizing finding, the social context shifted children's expectations, making them more likely to detect lack of knowledge.  These results also dovetail with work showing that the process of generating explanations for other people (and for ourselves) is a powerful way to reveal inconsistencies in our understanding [@lombrozo2006structure].

Another interesting link between social learning research and children's goals during learning comes from work exploring how input shapes implicit theories of intelligence [@dweck1988social]. Implicit theories of intelligence refer to children's internal working models of the world and provide general frameworks for processing information and generating predictions about behavior. @dweck1988social propose a cognitive model where holding different implicit theories of intelligence leads children to adopt different goal orientations, which manifest in different choice behavior during learning. For example, if a child holds the belief that intelligence is malleable (an incremental theory), they will want to increase competence (select a learning goal) and therefore be more likely to choose tasks that facilitate learning. 

Empirical work shows that social partners can directly intervene on children's learning vs. performance goals. For example, @elliott1988goals directly manipulated elementary school-aged children's goals by presenting them with a choice between one of two tasks described in the following ways:

  * *Performance task*. In this box we have problems of different levels. Some are hard, some are easier. If you pick this box, although you won't learn new things, it will really show me what kids can do.
  * *Learning task*. If you pick the task in this box, you'll probably learn a lot of new things. But you'll probably make a bunch of mistakes, get a little confused, maybe feel a little dumb at times â€” but eventually you'll learn some useful things.

\noindent
@elliott1988goals found that when children oriented towards the learning goal tended to choose the more difficult "learning" task even though they were likely to make mistakes and risk looking incompetent. In another study, @dweck1988social showed that children who already held performance goals viewed effort on a task as an index of ability, whereas children with learning goals viewed effort as a means for improvement. Moreover, both lab-based experiments and observational work provide evidence that the language adults choose to use when praising children influences their implicit theories [@cimpian2007subtle; @gunderson2013parent]. 

Taken together, the research on implicit theories suggests another way social contexts can trigger inquiry goals.  The @elliott1988goals finding -- that children who were oriented toward learning goals selected more challenging tasks -- directly maps onto behaviors that the OED framework aims to characterize. That is, the goal manipulation is an example of the social context pushing children towards an inquiry goal, which encourages behaviors that make progress towards learning. This process of triggering inquiry goals is an explicit pre-requisite in the OED model.

The social context can also introduce "social" goals that directly influence children's information seeking. The core OED framework only includes the goal of information seeking such that the utility of behavior is based solely on how actions lead to changes in the uncertainty about hypotheses. However, other empirical and modeling work has expanded on the basic information-seeking account to include *situation-specific utility functions* that include goals such as saving time, money, or cognitive resources. For example, @meder2012information designed a series of experiments where "pure" information seeking goals (e.g., maximizing accuracy) were placed at odds with the reward structure of the task. The critical manipulation was including asymmetric rewards for correct and incorrect categorization decisions in a binary classification task. Asymmetric rewards forced the learner to choose the less likely category to earn the highest reward (i.e., they must be willing to forego the goal of being accurate and make mistakes to get the highest score). When these goals were put in conflict, participants' behavior was mixed. Participants only reduced their preference for information seeking and improving accuracy when the asymmetric reward structure was made explicit via task instructions. However, @meder2012information speculate that people were able to consider goals other than pure information gain or reward maximization, taking the results as evidence for the need to consider additional factors when trying to understand the behaviors that people think are most useful.

One compelling aspect of social contexts is that they engage a process of psychological reasoning about others' mental lives. And once the learner starts thinking about the other person, they could begin to consider an additional set of "social" goals that may conflict with or support their learning goals. Consider the schematic active-social learning context in Figure 3. If Scott is worried about whether his social partner thinks he is smart, then he might prioritize actions that minimize the chance of making a mistake and perhaps not even attempt to make the toy work. Scott might seek out easy tasks to demonstrate his competence at the expense of choosing actions that help him learn about the world. On the other hand, Scott's social partner could explicitly communicate the learning goal using natural language, e.g., "Let's learn how this toy works!" This dovetails with the experimental results in @elliott1988goals reviewed above.  

Recent work by @yoonwon has aimed to include a broader range of goals in models of pragmatic communication. Specifically, they are interested in the topic of polite speech (e.g., people using indirect language such as "I donâ€™t think that dress looks phenomenal on you" as opposed to "It looks terrible") as a tradeoff between information and social goals. In their model, speakers reason about their actions concerning the information goal --
 to communicate information faithfully with as little effort as possible -- and a social goal -- to avoid harm to one's own or another's self-image. @yoonwon build on the Rational Speech Act (RSA) framework for pragmatic reasoning ^[RSA models language comprehension and production as, "a process of recursive reasoning about what speakers would have said, given a set of communicative goals" (p.819). ] [@goodman2016pragmatic].  We can draw a direct connection between the polite RSA model and the OED account. Both assume that people produce actions to maximize utility, but the polite RSA expands the utility function, modeling overall utility of an utterance as a weighted combination of social and informational goals. 

An intriguing possibility for future research would be to adapt the utility-theoretic approach used by @yoonwon to children's information seeking behaviors in social contexts. We can also connect these ideas to the effects of task framing (performance vs. learning oriented) on children's decisions to try more challenging tasks. The presence of another person could be modeled as an increase in the weight that children place on maximizing social goals, leading children to select easier tasks where they can appear competent. This is an interesting extension of the goal-orienting account reviewed above in that it frames these effects as a mixture of goals as opposed to the social context triggering either a performance or a learning goal.

One important gap in the current understanding of children's inquiry goals is a reasonable estimate of how often children participate in contexts with clear learning goals in their daily lives. Moreover, we do not yet have a theory of the kind of settings that would lead children to generate inquiry goals. However, work on rates of *Guided participation* across cultures provides an interesting counter-example [@rogoff1993guided]. @@rogoff1993guided coded the amount of "caregiver orienting" behavior present in parent-child interactions with their 12- to 24-month-old infants across four different cultural communities (a Mayan Indian town in Guatemala, a middle-class urban group in the United States, a tribal village in India, and a middle-class urban neighborhood in Turkey) that varied along the dimensions of how separated children were from adult activities and whether formal schooling was emphasized. Caregiver orienting was defined as,

> Caregiver orients child involved introducing new information or structure to the child (at any point in the episode) regarding the overall goals or a key part of the event or what was expected in the situation. Orienting framed a major goal, not just specific little directives for particular actions. (p. 43)

\noindent
@rogoff1993guided found that parents in all four communities produced high rates of structuring and orienting behaviors (with the lowest rate of structuring being 81% of play episodes). Thus, when placed in a structured activity, adults make sure children are aware of the goal (e.g., learning the function of the novel toy). However, the communities differed in how often children were directly involved with adult activities in day-to-day life, with the children raised in rural villages often having early access to adult economic and social events. An interesting open question is whether older peers and adults need to be directly engaging with the child to trigger inquiry goals. Perhaps increased access to observing adult goal-directed behaviors can facilitate learning goals. For example, it could be generating lots inquiry goals would be a byproduct of seeing lots of adult activities (e.g., cooking, shopping, working) that they do not understand. 

In sum, understanding children's goals represent a critical step in characterizing the relative contribution active learning to cognitive development. Social contexts have the power to trigger inquiry goals, but also can introduce alternative social goals that might be at odds with children's decisions about what to learn. One important direction for future research is to map the space of children's goals during everyday learning contexts. It would be useful to know how much of children's daily activities involve settings where there is a clear learning goal either generated independently by the child or communicated by older peers and adults. It would also be useful to know how the distribution of these goals change as a function of development, especially as children enter school and across different cultural contexts where children have differential access to structured (e.g., lessons and sports) vs. unstructured activies (e.g., free play). Moving beyond the lab-based studies of OED-like reasoning is no easy task and will require leveraging recent advances in large-scale observational data collection about children's daily experiences. 


\afterpage{
```{r fig.pos = "H", out.width="100%",fig.cap = "\\textit{Schematic of active learning within a social context. Each panel shows how social information could influence a different component of the active learning process. These social effects occur in-the-moment of learning or over developmental time. Also, the cause of the social effect varies from the mere presence of another person to triggering a sophisticated psychological reasoning process about others' goal-directed behaviors. Note that the panels correspond to the different sub-sections in Part IV of the text.}"}

grid::grid.raster(png::readPNG("../cada_schematic/cada_schematic.003.png"))
```
\clearpage
}

## Hypotheses

After establishing learning goal, the next component of inquiry is deciding what hypotheses the learner should consider. Intuitively, a hypothesis is a candidate explanation about how the world works. For example, consider the schematic learning contexts shown in Figures 1 and 2. In the casual context, the hypotheses for how the toy works could include: (1) Button A, (2) Button B, (3) Buttons A and B simultaneously. In the word learning context, the child might think the new word "dax" means: (1) dax = object A, (2) dax = object B, or (3) dax = object C. ^[Note that this hypothesis space is simplified since it only considers the possibility of one-to-one word-object mappings.] 

The set of hypotheses under consideration is critical for effective self-directed learning. The usefulness function -- expected information gain -- outlined in [Part III](#p3) works by comparing the learner's uncertainty over hypotheses before and after she chooses an action. Without knowing what is in the hypothesis space, it becomes challenging to figure out the best choice for reducing uncertainty. Put another way; the OED framework does not readily deal with situations where learners might have to consider a large space of hypotheses, might hold the wrong hypotheses, or might perform actions without considering any hypotheses at all. This is an especially important challenge for developmental accounts that draw on OED principles since these scenarios seem quite plausible for young learners.

However, a critical function of social learning contexts is to provide a clear set of possible explanations for the actual state of the world. That is, adults and older peers, who might have access to the correct hypothesis, can restrict children's hypotheses to guide their information seeking. This effect of social context parallels the discussion of goals reviewed in the previous section. 

One relevant case study comes from work on children's early word learning. The learning challenge is that even the simplest of words, concrete nouns, are often used in complex contexts with multiple possible referents, which in turn have many conceptually natural properties that a speaker could talk about. This ambiguity creates the potential for an (in principle) unlimited amount of hypotheses that children could consider when trying to figure out the meaning a novel word. Remarkably, word learning proceeds despite this massive uncertainty, with estimates of adult vocabularies ranging from 50,000 to 100,000 distinct lexical concepts [@bloom2002children]. 

It does not seem plausible for children to entertain all hypotheses about possible word-object links. But which ones should they consider? One proposed solution is that word learners only consider a single word-object link at a time [@trueswell2013propose; @medina2011words]. Under this account, the child makes an initial guess about the word meaning, and then only stores that word-object link until she receives sufficient evidence that her initial hypothesis was incorrect. If she does see enough counter-evidence, then she will switch to a new, single hypothesis that better matches the statistics in the input. ^[This "propose-but-verify" account parallels work by @bonawitz2014win in the domain of causal learning, which suggests that a "Win-Stay, Lose-Sample" algorithm (inspired by efficient sampling procedures in computer science) provides a better explanation of children's hypothesis testing behaviors compared to an algorithm that enumerates the entire hypothesis space.] However, another influential account of early word learning, inspired by basic associative learning principles, argues that word learners store more than a single hypothesis. Under this theory, children's  hypothesis spaces are reduced gradually via the aggregation of word-object co-occurrence statistics across multiple labeling events [@siskind1996computational; @yu2012modeling]. Support for this account comes from experimental work showing that both adults and young infants can use word-object co-occurrence statistics to learn word meaning from individually ambiguous naming events [@smith2008infants]. Moreover, adults show evidence of being able to recall multiple word-object links from an initial naming event [@yurovsky2014algorithmic]. 

The critical difference between these proposals is how much information learners store in their hypothesis space. And understanding the nature of these hypotheses is essential for evaluating children's ability to seek information. Some of our own work provides evidence that the social context can modulate the content of the learner's hypothesis space [@macdonald2017social]. Inspired by ideas from Social-pragmatic theories of language acquisition that emphasize the importance of social cues for word learning [@clark2009first; @hollich2000breaking; @bloom2002children], we showed adults a series of word learning contexts that varied in ambiguity depending on whether there was a useful social cue to reference present (i.e., a gaze cue). We then measured learners' memory for alternative word-object links at different levels of attention and memory demands. Learners flexibly responded to the amount of ambiguity in the input, and as uncertainty increased, they tended to store more word-object hypotheses. Moreover, we found that learners stored representations with different levels of fidelity as a function of the reliability of the social cue and despite having the same amount of time to explore the objects during the initial labeling event. 

These results provide evidence that the content of learners' hypothesis spaces changed as a function of social information. Further suppport for this idea comes from experimental work showing that even children as young as 16 months prefer to map novel words to objects that are the target of a speakerâ€™s gaze and not their own [@baldwin1993infants], and analyses of naturalistic parent-child labeling events shows that young learners tended to retain labels accompanied by clear referential cues, which served to make a single object dominant in the visual field [@yu2012embodied]. One important direction for future research is to measure the full causal pathway from variation in social information through children's hypothesis spaces to their information seeking behaviors. For example, it would be interesting to know whether learners' subsequent questions or decisions about where to allocate attention would be affected by the social context in which they were first exposed to a new word.

A second case study that illustrates the importance of considering young learner's hypothesis spaces comes from work by @lucas2014children where they compared children and adult's capacity for learning different kinds of causal structures. In the task, participants saw a series of events that consisted of a training phase where an experimenter placed objects on a box that either played or did not play music. The participant's goal was to learn which objects, or combination of objects, made the box work. In the disjunctive condition, only single objects (A or C, but not A) made the toy play music. In the conjunctive condition, only the combination of two different objects (A and C) would make the toy play music. After seeing several demonstrations, both children and adults were tested on ambiguous events where they could either infer a disjunctive or conjunctive causal relationship. @lucas2014children found that only children showed evidence of learning the conjunctive relationship, even if the evidence favored this interpretation. The authors speculate that adults were more biased towards the disjunctive hypothesis since it is more common in everyday experience; whereas children's prior beliefs are more diffuse, leading them to be more sensitive to evidence in favor of the conjunctive hypothesis. ^[Figure 1 illustrates a  version of the active causal learning scenario. In this case, the learner believes that pressing both buttons to activate the toy is a less likely hypothesis. As a result, the query to test the conjunctive hypothesis "press both buttons" becomes less useful for gaining information since it would produce confounded evidence concerning her other, disjunctive hypotheses.]

Why should these findings matter for active learning? A key prediction of the OED account is that learners will select behaviors that maximally reduce uncertainty in their beliefs, which is often formalized as the difference in entropy between the prior and posterior probability distributions over hypotheses (i.e., $P(h|a) = ent(H) - ent(H|a)$). Thus, the content of the hypothesis space and the uncertainty over each hypothesis plays a direct role in evaluating the relative usefulness of different actions. Moreover, features of the social context could bias the content of children's hypothesis space. For example, @lucas2014children suggest that, 

> Most of the time, adults do not need to dramatically change their beliefs or abandon their hypotheses for dramatically different ones. Indeed, doing so would be a liability: adults are expected to make accurate predictions and good decisions, not bold inductive leaps. Adults are also unlikely to have caregivers to correct their errors and save them from poor choices. (p. 295)

\noindent
This proposal makes a testable prediction: that contexts in which learners "feel" safe to make mistakes would lead children to consider and test a broader range of hypotheses. Another effect of the social context highlighted in @lucas2014children's study is that the experimenters scaffolded children and adults consideration of the disjunctive and conjunctive hypotheses. That is, their actions constrained the hypothesis space to isolate learning and information seeking effects. The "Hypotheses" panel of Figure 3 presents a schematic illustration of this social context effect. Similar to the research on goals, the majority of the work on hypotheses has focused on lab-based studies. Thus, it is an open question as to how much of role adults play in communicating relevant hypotheses during everyday learning.

A final case study comes from research on children's conceptual [@gelman2009learning]. Conceptual change is a "radical" reconstruction of an intuitive theory about how the world works. For example, elementary school-aged children tend to hold a mixture of beliefs about the shape of the earth [@vosniadou1992mental]. These theories range from a flat earth theory that matches children's everyday perceptual experiences (i.e., walking on flat ground) to the adult-like, sphere model, which reflects the actual state of the world. Interestingly, some children hold intermediate beliefs such as a dual-earth theory where there are two earths: "a round one which is up in the sky and a flat one where people live" (p. 550). The fact that some children entertain a dual-earth theory suggests that they are actively integrating their initial theory with the information they get from other people who already have the correct, sphere theory. And for children to hold the sphere model, they must have learned it from social input. 

There is also experimental evidence for the importance of social input in children's reasoning about biological concepts. For example, the concept of "alive" takes years to fully develop, with younger children (under 10 years of age) often claiming that only animals, and not plants, are alive. @opfer2004revisiting tested the hypothesis that evidence of goal-directed movement is critical for children's extension of the "alive" concept. In their study, 5-year-olds' were trained in different ways to think about the concept of a "living thing" and then asked whether they believed that plants were alive. Children either learned that plants were capable of goal-directed movement (e.g., "The house plant is growing this way. It needs the sunlight over here."), that plants were capable of growth, or that plants need water to survive. Children in the goal-directed movement condition showed the most significant theory revision, saying plants were also living things more consistently on a post-intervention categorization task. 

Additional evidence comes from research on the links between language experience and performance on various cognitive tasks. For example, empirical work shows that deaf children without access to a natural language perform worse on Theory of Mind tasks [@peterson2000insights]; that Korean speakers perform better than English speakers on tasks that require categorizing based on tight vs. loose distinctions, which are lexicalized in Korean [@mcdonough2003understanding]; and that exposure to a first language reduces infants' capacity to detect non-native phonetic contrasts [@maurer2014perceptual]. 

Together, the findings reviewed in this section illustrate several points for the active-social learning account. First, the set of hypotheses that children consider are likely to be quite different from adults (and possibly different from what the experimenter thinks the child is considering). Second, children generate hypotheses using a mixture of prior knowledge, expectations about the task, and social input. There are (at least) two timescales through which social learning can shape hypotheses.  An in-the-moment timescale where others' behavior constrains hypotheses for the current task -- for example, referential gaze indicating candidate word-object mappings, or an adult suggesting a disjunctive (one-block) vs. a conjunctive (two-block) theory for how to make a toy work. And a developmental timescale where prior interactions with other people and cultural learning modify the hypotheses that children bring to the learning task (e.g., the conceptual change and language effects reviewed above). ^[We could make a further distinction between the developmental and the cultural timescales, where developmental refers to information acquired from interactions with others in the child's lifetime (e.g., disjunctive causal structures are more likely to occur in the world) and cultural refers to information that has accumulated throughout human evoluationary history (e.g., access to natural language or concepts such as the spherecial earth.)] 

## Questions

Queries in the OED framework refer to the experiments that a scientist could conduct to gather information about their hypotheses. Queries in human information seeking can refer to a variety of actions, including verbal questions, pushing a button to figure out how a toy works, and decisions about where to look. In fact, the capacity to provide general principles that explain such a broad range of behaviors is one of the strengths of the OED account.

The challenge for the young learner is to discover what behaviors are available and of those actions which might be particularly useful for gathering information. In this section, I illustrate how the social learning context provides valuable input to this learning process via demonstrations of the range of actions that learners could take to gather information. I suggest that this process unfolds by children imitating and by adults' modeling useful information seeking behaviors.  

It seems obvious that children would look to older peers or adults to learn what actions are possible and useful. However, a large body of empirical work suggests that even young infants will not imitate every action that they see. Instead, children show evidence of "rational imitation" and will look for cues about others' goals when acting and use this information to determine the behaviors worth imitating. For example, @gergely2002developmental measured how often 14-month-old infants imitated an adult's actions -- turning on a light with her head (less efficient) instead of her hands (more efficient) -- as a function of whether there was a relevant explanation for selecting the less efficient action (whether the adult's hands were occupied). They found a substantial difference in imitation rates across conditions (69% in the hands-free vs. 21% in the hands-occupied), suggesting that children recognized the reason for the inefficient action and chose to ignore the means and focus on the goal of turning the light on in the most efficient way possible.

The high rates of imitation in the hands-free condition highlight another component of learning from others' actions: that children tend to overimitate behaviors even when these actions are not directly relevant to the task. For example, @call2005copying compared imitation behaviors of 2-year-old children after they watched someone demonstrate how to open a tube using only the necessary actions or using the actions plus a style component unrelated to opening the tube (e.g., removing the tube's cap with an exaggerated twisting motion). Almost all children (93%) imitated the causally irrelevant action, providing evidence that they were focused on reproducing each of the experimenter's actions and not just reproducing the outcome of opening the tube.  

Empirical work shows that social factors matter for children's decisions to imitate. @carpenter1998fourteen showed that 14- and 18-month-olds were less likely to mimic an adult's action if the action was marked verbally as a mistake (e.g., "Whoops!"). @buchsbaum2011children provide evidence that the children are more likely to overimitate when the adult is described as a "knowledgeable teacher" as opposed to "naive." And @carpenter2002understanding showed that giving children explicit information about another person's goals before a causal demonstration leads to an increase in imitation and learning of the correct casual structure. 

The work on children's learning via imitation and their tendency to overimitate suggests that inferences about others' intentions play a critical role. These findings suggest that others' goal-directed behaviors constitute a rich source of input for children to learn what queries might be available and useful. 

Research on verbal question asking provides additional insight into how children learn to perform useful information seeking behaviors. Consider that to ask a helpful question in natural language children must possess the prerequisite language skills, which they acquire from the social input. Both experimental work and corpus analyses provide evidence that children's question-asking becomes more varied and productive over the first years of life (e.g., see @chouinard2007children and @legare2013use reviewed in [Part II](#p2)). Moreover, children improve in the timing of their turn-taking during question-answer exchanges, reducing the length of gaps between turns [@casillas2014turn]. Interestingly, @casillas2014turn also found that adults appeared to be sensitive to children's developing question-answering skills and waited to ask more difficult questions until children were older children. Adults also modified their questions if they confused children, producing sequences like, "Who is this? Whatâ€™s he called? Who is he? What is his name?". It is interesting to consider how children might internalize these modifications as part of their question asking repertoire. 

The majority of research on children's question asking has focused on the child's behavior, exploring how the type, content, and effectiveness of questions changes as children develop. However, several studies have measured aspects of caregivers question asking. For example, @yu2017peagogical coded parent-child interactions from the CHILDES database to measure the amount of "pedagogical" questions in children's input. They differentiate "pedagogical" from "information seeking" questions by coding whether the adult already knew the answer. For example, "Whatâ€™s that called?" would be pedagogical; whereas,  "What did you do at school?" would be information seeking. Approximately 30% of parents' questions were pedagogical, 60% were information seeking, and 10% were rhetorical (i.e., not intended to be answered verbally). Parents also directed a smaller proportion of pedagogical questions to older children. @yu2017peagogical speculate that the function of pedagogical questions is to help children learn. 

It would be interesting to know more about what children think about these questions and how they incorporate them into their behaviors. However, more experimental work linking adults' question-asking practices to children's behaviors is needed. This is especially interesing since observational studies have found that that parents' use of wh-questions predicts children's later vocabulary and verbal reasoning outcomes [@rowe2017going] and children of parents who were trained to ask "good" questions during bookreading episodes at home also asked better questions during bookreading sessions at school [@birbili2009helping]. One explanation for these associations is that wh-questions challenge children to produce more complex responses that build verbal abilities. However, another intriguing causal pathway is that the frequency and type of questions that parents shape children's information seeking skills by providing templates for useful questions.

Generating possible questions is the first step. Next, children have to evaluate the relative "usefulness" (i.e., utility) of the different queries. But how do children learn the features of a good question? One solution is for children to observe other people's question asking behaviors, recognize which questions are useful, and leverage their imitation skills to model those behaviors.  

In fact, there is evidence from work with adults showing a substantial difference between people's question-generating (harder) and question-evaluation (easier) skills. For example, @rothe2015asking asked a group of adults to play a modified "Battleship" game where they had to find the location of three ships that consisted of 2-4 tiles and could be oriented in either the vertical or horizontal direction on a 6x6 grid. Participants gathered information sequentially by uncovering one tile at a time. At different points in the task, the game would stop and participants could ask any question using natural language. @rothe2015asking used a formal OED model to measure the expected information gain of each question, and people rarely produced high information value questions. However, in a follow-up experiment @rothe2015asking had a different group of adults play the Battleship game, but this time participants had access to the list of questions generated by participants the free-form version, In this contexts, adults were quite good at recognizing and selecting high information value questions.   

Developmental work provides additional evidence of this production-comprehension asymmetry. For example, children younger than the age of three have difficulty generating appropriate verbal questions compared to their older peers in "Twenty Questions" style tasks that are designed to measure question-asking skills [@mills2011determining; @mills2010preschoolers]. However, when @mills2012little tested 3- to 5-year-old's capacity to learn from observing third-party question-answer exchanges, they found that even the youngest children were capable of using information elicited by others' yes/no questions to identify the contents of a box. Interestingly, children recognized the value of others' question-answer exchanges, paying more attention to them as compared to third-party exchanges that did not include question-answer exchanges.

These results suggest that even at an age where generating questions "from scratch" might be difficult, children can observe and learn from questions that occur in their social environment. @mills2011determining also explored this phenomenon by directly manipulating whether children were exposed to a training phase where adults modeled useful questions before playing the question asking game. They found that even though the youngest children were not successful at constructing good questions, they were able to ask useful questions at a much higher rate following exposure to explicit modeling.
  
Work with elementary-school-aged children in the domain of scientific inquiry also shows that generating a good question is a challenging aspect of inquiry skills. One relevant example comes from @kuhn2008needs's intervention study comparing children trained on scientific inquiry skills (e.g., understanding the objectives of inquiry and identifying questions) to a group of slightly older students who had not participated in the direct instruction training. Children in the training group showed progress. In contrast, children in the comparison group failed to develop these formal scientific inquiry skills in the absence of a particular kind of input. kuhn2008needs summarizing the key results, 

> Consistent with the findings of Kuhn and Dean (2005), identifying a question appears to play a key role in making the rest of the inquiry cycle productive ... Like other components of the inquiry process, this skill is not one a student learns once and has mastered. (p. 555)


A final example of how social contexts influence queries is that the mere presence of another person adds a "social target" for information seeking. This effect differs from the findings discussed until this point since in those examples social input shaped subsequent information seeking from the world. Intuitively, if a child is trying to learn how a toy works, they could try actions to test the system directly (i.e., seek information from the world). But if another person is present, then they can choose to ask verbal questions or to seek help via nonverbal means (i.e., seek information from other agents). The "Questions" panel in Figure 3 highlights this aspect of social contexts.

Recent empirical work has explored the factors influencing whether children seek information from the world or other people. For example, @fitneva2013development measured 4- to 6-year-old's decision making to learn about novel social category: "moozles." Critically, the target concept was either visible (the color of hair) or invisible (an internal preference). Children could look directly at the moozle or ask a moozle expert. Children tended to select the "look" option for the visible property and to select the "ask" option for an invisible property. These results suggest that children have some meta-understanding of the kinds of information that is particularly good to learn from social partners. 

Additional evidence comes from work by @lockhart2016could where they demonstrated that 5- to 11-year-old children could articulate the kinds of information that a person could learn growing up on their own (e.g., that the sky is blue) compared to the types of information that require other people (e.g., that the earth is round). Note that the items in this study did not test children's appreciation for more indirect forms of social learning: that is, to learn that the sky is blue relies on having a conventional language system for referring to concepts. @gelman2009learning refers to this as "a hidden level of cultural input" (p. 2). The critical point is that even in learning contexts that appear entirely self-directed, children's massive amounts of accumulated experience with other people shape the hypotheses and questions that children consider.

Another set of relevant examples comes from work on children's help-seeking behaviors. @vredenburgh2016young had children build toys that required multiple steps, and on each each step, children were given the opportunity to ask for help from the experimenter. Each step varied in difficulty and children naturally varied in their toy building skill. Children asked for help when the step on more challenging steps, suggesting that preschoolers sought help systematically. Moreover, work by @gweon201116 found that 16-month-old infants are selective help-seekers, turning to a social target to request information or acting on the world depending on which information source was more likely to help them achieve their current goal. In this case, the infants' goal was to make a malfunctioning toy produce music and the critical manipulation was whether children saw evidence that explained the likely cause of failure being the toy versus their capacity for making the toy play music. When the toy was likely to be broken, they reached for a new object (queried the world), but in contrast, when the evidence suggested that the child was the issue, then they sought help from a nearby adult. 

Some of our work has explored how the presence of another person changes the set of information seeking behaviors available to the learner [@macdonald2017info]. Specifically, we proposed an information seeking account of eye movements in grounded spoken and signed language comprehension: that fixations to a speaker can provide valuable information concerning the goal of rapid language understanding. We tested our information-seeking account using three case studies that manipulated the value of different fixation behaviors in the visual world: (1) a comparison of processing a visual-manual vs. a spoken language in children, (2) a comparison of processing printed text vs. spoken language in adults, and (3) a comparison of processing degraded vs. clear speech. We found that, compared to English-learners, young signers delayed their gaze shifts away from a language source, were more accurate with their eye movements, and produced a smaller proportion of nonlanguage-driven shifts. These results suggest that the signers were sensitive to the higher value of seeking visual information from the signer.English-speaking adults produced fewer nonlanguage-driven shifts when processing printed text compared to spoken language. And English-speaking children and adults allocated more fixations to a speaker and achieved higher language recognition accuracy when processing degraded speech. Together, these data provide evidence that listeners adapted to the value of seeking visual information from social targets to increase the chance of rapid and accurate language understanding.

In sum, questions provide the tools for children's information seeking. However, we need more research to understand the link between social input and how children generate possible questions. One explanation discussed in this section is that children might use powerful imitative learning abilities to model the question-asking behaviors demonstrated by more knowledgeable others. Moreover, social contexts can fundamentally change the set of actions available to the learner by providing a social target for information seeking behaviors. 

## Answers

In the OED framework,  answers are possible states of the world in response to a learner's query. An answer is useful if it results in a substantial decrease in uncertainty about the actual state of the world. The challenge for the active learner can be separated roughly into two parts: (1) figure out what which answers are likely and (2) decide how much you should learn from an answer after seeing it. The social context plays a role in each component and is the focus of the current section.

Defining the specific features of a "good" answer is challenging. Intuitively, a good answer gives the learner information that they did not already know, that they were interested in learning, and that is likely to be useful beyond the current context (i.e., to generalize). Even within the formal OED framework, there have been a variety of ways to instantiate the utility function (e.g., information gain, probability gain, and Kullback-Leibler divergence) to compute the value of an answer (see @nelson2005finding). All of these information-theoretic utility functions take into account the learner's prior beliefs represented as probability distributions over hypotheses and calculate the impact that an answer would have on the learner's beliefs represented as conditional probability distributions. 

Several social learning accounts argue that a key function of social information is to provide useful answers. For example, evolutionary models of cultural learning argue that the human capacity for efficiently transferring knowledge between individuals allows for the gradual accumulation of small improvements that eventually lead to complex tools, beliefs, and practices that would be difficult, if not impossible, for any individual to discover on their own [@kline2015learn]. @boyd2011cultural provide the following example,

> For example, a rare chance observation might allow a hunter to associate a particular spoor with a wounded polar bear, or to link the color and texture of ice with its stability on windy days just after a thaw. Such rare cues allow accurate low-cost inferences about the environment. However, most individuals will not observe these cues, and thus making the same inference will be much more difficult for them. Organisms that cannot imitate must rely on individual learning, even when it is difficult and error-prone. They are stuck with whatever information that nature offers. (p. 10921)

\noindent
The fundamental idea in these models is that there is a good reason to think that communicating useful and difficult to acquire information enhanced evolutionary fitness. Thus, there is an a priori reason to expect that the information we acquire from other people will be useful. 

This concept is critical to @csibra2009natural's theory of "Natural Pedagogy" reviewed in [Part I](#p1). Specifically, they argue that an assumption of *generalizability* is a fundamental component of adults' communication with children. Their account has three elements: adults transmit generic information, adults provide ostensive cues to signal generalizable knowledge, and children show sensitivity to these cues, treating information differently when they are present. Evidence for a bias towards generalizability comes from a set of empirical studies showing that infants will generalize more often when learning information accompanied by ostensive communicative cues such as eye gaze or child-directed speech. For example, infants are more likely to generalize the positive vs. negative valence associated with a specific object-person pairing to a new person if the valence was demonstrated with pedagogical cues [@gergely2007pedagogy]. Also,  infants are more likely to encode the stable features of an object, as opposed to its location in space, if a communicative signal such as a point guided their attention [@yoon2008communication].

Even if learning occurs in a social context with a default assumption of useful and generalizable information, not all answers are equally informative. Thus, the second challenge for information seekers is to evaluate possible responses to a query to figure out how much they would update beliefs. This challenge is perhaps one of the more developed connections between the formal social and active learning accounts. Researchers have made progress in modeling the influence of different assumptions that a learner could make about the generative process of answers. For example, @shafto2012learning lay out a continuum of sampling assumptions:

  * *Weak sampling*: answers generated at random from the set of all possible answers (independent of target hypothesis)
  * *Strong sampling*: answers generated at random from the set of answers that are true of the correct hypothesis (linked to target hypothesis)
  * *Pedagogical sampling*: answers generated that maximize the learnerâ€™s belief in the correct hypothesis (linked to target hypothesis and consider alternative hypotheses)
  
\noindent
Critically, if the learner assumes strong or pedagogical sampling, then they can make stronger inferences that speed learning. For example, if we see someone press two buttons to activate a device, we are more likely to think that both buttons were necessary if that person knew how the machine worked and wanted to communicate to us how it worked. Otherwise, if one of the buttons would have been sufficient, then it would not make sense for them to perform the more inefficient action of pressing both buttons. 

Empirical support for the pedagogical sampling account comes from a range of domains/tasks, including word learning [@frank2009using], pragmatic inference [@frank2012predicting], and causal reasoning [@bonawitz2011double] (see the section on inferences and generalization in social learning Part I). We can also revisit these findings and connect them directly to specific components of the OED model of human inquiry. Consider @xu2007sampling finding: that learners are "sensitive" to the sampling process that generated the examples. When a knowledgeable teacher selected the examples, learners assumed the examples indicated the true word meaning. And if this were the case, then it would be surprising to see three examples drawn from the smaller subordinate category. Formally, they modeled sensitivity to sampling assumptions by modifying the likelihood function in their Bayesian cognitive model: $p(x_i \mid m) \propto p(l_i \mid o_i, m)$. Intuitively, this changes the probability of hearing a particular label ($l_i$) given a specific object ($o_i$) and word meaning ($m$). In this case, the likelihood function for the teacher-driven condition was designed to capture the idea that learners prefer "smaller" or more restrictive hypotheses if they are confident that the teacher generated labels based on the actual word meaning.

This formalization provides a direct connection with the OED model of human inquiry. Specifically, when a learner is simulating the possible answers that she could receive, she considers how much each answer will update her beliefs. This reasoning process is modeled by computing the difference between the learner's prior and posterior uncertainty (i.e., entropy): $P(h|a) = ent(H) - ent(H|a)$. The learners' sampling assumptions naturally enter the information seeking calculus through the posterior entropy term $ent(H|a) = -\sum_{h\in H}{P(h|a)logP(h|a)}$. Intuitively, this part of the model captures the idea that not all answers are equally useful, and answers that are linked to the correct hypothesis and generated for you are more likely to be informative and should lead to a stronger change in beliefs.

The approach of building more sophisticated likelihood functions has also been used to capture another challenge for evaluating the utility of an answer: that some people are more reliable sources than others. That is, when learning from the testimony of other people, there is always a possibility that this information could be inaccurate or even misleading. This reasoning process might be especially important for young learners who acquire much of their information via interactions with others. However, a growing body of evidence suggests that even very young infants are capable of *selective* learning, rejecting answers that conflict with their knowledge [@pea1982origins] and seeking information from people who tend to provide good answers [@koenig2004trust]. 

For example, empirical work shows that preschoolers track and integrate a speaker's prior instances of accuracy to figure out if they are trustworthy and will use this information to guide subsequent learning from that speakerâ€™s future claims [@koenig2004trust]. In these studies, children evaluate a speakerâ€™s current testimony after the speaker establishes a record of reliability or unreliability by labeling or mislabeling familiar objects. Across these studies, preschoolers are consistently less likely to direct questions towards and learn from a previously unreliable person. Moreover, @chow2008see found that 14-month-olds are less likely to follow the gaze of a person who had been unreliable in the past, i.e., someone who had consistently directed gaze towards an empty location in space. Finally, children's selective learning appears sensitive to external cues, preferring to learn familiar over unfamiliar teachers [@corriveau2009choosing], adults over peers [@rakoczy2010bigger], and ingroup over outgroup members [@macdonald2013my].

Converging evidence comes from @gweon2014sins work on children's exploration behavior after seeing pedagogical demonstrations of varying quality. In this study, children played with toys that either had one of four functions (e.g., spinning globe or flashing light) until they independently discovered the correct number of functions. Then, depending on condition assignment, they saw a puppet teach one or four of the novel functions to another puppet. Finally, the puppet teacher introduced a new toy to the participant and demonstrated a single novel function. Critically, when the puppet teacher had left out information in the previous teaching episode (only showing one out of four novel functions), children spent more time exploring the object functions that the teacher did not demonstrate. That is, when the teacher was under-informative, children did not make the strong inference that there were no other functions to discover. 

The critical insight from the selective learning literature is that children are not entirely incredulous when they encounter information. Instead, the evidence suggests that they actively reason about the expertise that another person brings to the learning context and will choose to ignore information that they deem unreliable. Interestingly, standard outcome measures in studies of selective learning are children's information-gathering decisions, e.g., whom to direct questions towards and how many actions to take on an object. These behaviors map directly onto the choices that the OED model of human inquiry is trying to explain and suggests that children consider the expected utility of others' answers when deciding to gather information. 

Similar to the pedagogical reasoning effects, the selective learning phenomena have also been modeled using modifications to the likelihood function in a Bayesian cognitive model. Again, this maps onto a hypothesis about the assumptions that learners make about other people generate answers. For example, @shafto2012epistemic propose that selective learning in these object labeling scenarios can be explained as children reasoning about both the helpfulness and knowledgeability of speakers when they produce a given label, $l$. Here the child's goal is to select a speaker that increases the chance that they get good information that matches the true state of the world ($label=correct$). Formally, they specify this likelihood function as: 

$$P(l \mid s,k,h) = \sum_b P(l \mid b,h)P(b \mid k,s)$$

\noindent
This term captures the idea that the probability of a label depends on the true state of the world, the speaker's knowledge ($k$) and helpfulness ($h$). This is decomposed into two parts: (1) the speaker's belief ($b$) about the label $P(b|k,s)$, which depend on their knowledge ($k$) and the true label ($s$), and (2) the speaker's probability of producing a label that matches their belief, which depends on their helpfulness ($h$). Using this model, @shafto2012epistemic were able to capture several qualitative findings from the selective trust literature, including children's demonstrated preference for accurate over inaccurate speakers. While the precise mathmetical details of the model are less important, the key takeaway is that the same modeling approach -- reasoning about the generative process of others' behavior -- can account for children's behavior both when they get an answer and have to update beliefs but also prior to receiving an answer when children are making decisions about whom to seek information from.

One consequence of the ideas discussed in this section is that features of the individuals who are present in a social learning context can change whether information seeking occurs at all. That is if a child is in a setting that is unlikely to provide useful answers, then generating an information-seeking behavior, even if the action has the potential to return good information, becomes less valuable. Thus, a challenge for the self-directed learner is to figure out whether answers are likely to occur. However, this is currently a less-developed area of research, and as a result, we know little about how the expected usefulness of an answer might make the cost of generating high expected utility information seeking behaviors less useful. The dual consideration of costs and benefits has been the focus of recent work in active machine learning [@haertel2008return] and other areas of developmental psychology [@jara2015children]. It would be interesting to merge these cost-based approaches with ideas from social learning theory to increase our understanding of how social contexts can modify the costs of different behaviors.

## Stopping rules

When should we stop collecting information and make a decision? A stopping rule describes an information or time-based threshold that if crossed causes people to cease information seeking and generate a behavior. The concept draws on ideas from probability theory that have been used to model how random variables change as a function of time. For example, when researching for a paper, a student might generate the time-based stopping rule -- read for two hours and then start writing. The goal of an efficient learner is to figure out the stopping rule that balances achieving a learning goal by reducing extra time or effort put into the task.

Studies of children's information seeking have primarily focused on measuring whether children persist if their initial request is not satisfied. For example, @frazier2009preschoolers analyzed parent-child question-answer exchanges from the CHILDES database to see if children show evidence of seeking causal explanations when they ask *how* and *why* questions. To address this hypothesis, @frazier2009preschoolers measured the probability of children re-asking the same question and the likelihood of asking a different, follow-up question after receiving either an explanatory response (e.g., CHILD: "Why you put yogurt in there?" ADULT: "Yogurt's part of the ingredients") or a non-explanatory response (e.g., CHILD: "How do you get sick?" ADULT: "I don't know."). Children were more than twice as likely to re-ask a question after getting a non-explanatory response (24%) compared to an explanatory answer (9.4%), providing evidence that they continued to collect information until their inquiry goal was satisfied.  

Converging evidence comes from @deborah2004children's work exploring children's intended meaning when they ask "What is it?" about objects. Children's propensity for asking follow-up questions was measured after they were given either a name or a functional explanation in response to an ambiguous request ("What is it?" Or "What's this?"). Similar to @frazier2009preschoolers's findings, 2- to 4-year-olds asked more follow-up questions when adults provided an object label, suggesting that they intended to ask about the object's function and persisted to get this information. Children were also more likely to change the form of their ambiguous questions to more specifically target functional explanations in the object label condition. Together, these studies suggest that young children are sensitive to when they have gathered sufficient information to address their questions. In the majority of this work, the social context influenced children's stopping decisions by giving them the information they desired. 

However, this is not the only way the social context can change stopping decisions. In fact, a recent body of research has tested the effects of adults' demonstrations of pedagogy on children's decisions about whether to persist in exploratory behavior within novel learning contexts. For example, @bonawitz2011double showed that preschoolers would spend less time exploring an object and are thus less likely to discover alternative object-functions after an adult explicitly demonstrated a single function [@bonawitz2011double]. The explanation for this effect is similar to the pedagogical inference work reviewed in the "Answers" section: that a demonstration from a knowledgeable teacher provides evidence for that function and against the existence of other features; otherwise, a helpful teacher would have demonstrated the other features as well. We can reconstrue this finding as an effect on stopping rules: that is, the social context is communicating that there is less information to learned and children are adopting a lower threshold for terminating their search.

It is not the case that information learned in social contexts always reduced information search. In fact, evidence for the opposite pattern -- i.e., a pedagogical demonstration leading to an increase in subsequent exploration -- comes from work by @butler2012preschoolers on children's inductive inferences. In this study, preschoolers were presented with an unfamiliar object and shown a novel causal property (e.g., that the object could magnetically pick up paper clips) using either a pedagogical ("Look, watch this!") or an accidental ("Oops!") demonstration. Children were then given the opportunity to play with a set of identical looking objects that did not have the magnetic property to see if how they would react to the negative evidence linking the objects to the underlying causal property. @butler2012preschoolers found that, after a pedagogical demonstration, children spent more than twice as much time exploring the objects and generated three times as many attempts to make the objects pick up the paper clips. Put another way, the strength of evidence in the pedagogical condition led children to increase their information gathering threshold in the face of new, negative evidence. 

The opposite effect of pedagogy on children's stopping rules across these two studies might seem like a puzzle. However, they are both driven by the power of socially transmitted information to be more informative and lead to stronger inferences. In the causal learning case, the stronger inference about the lack of alternative object-functions results in less exploration, but in the inductive inference case, the stronger inference about the generalizability of the causal property results in more exploration. These findings also highlight a useful distinction for social learning effects: that information seeking decisions can be altered by features of the immediate social context and by the way information social partners communicated information in a previous learning context.


Exploring the factors that influence children's decisions to stop gathering information is a promising area for future research.  I think it will be useful to design studies that test children's developing capacity to reason about the cost of actions. This cost term is critical to deciding whether to gather additional information. In fact, recent theorizing in the field of social cognition has begun to take the idea of "reasoning" about costs seriously to understand how children reason about others actions. @jara2016naive describes the idea of Naive Utility Calculus as, "... human social cognition is structured around a basic understanding of ourselves and others as intuitive utility maximizers." (p. 589). 

Moreover, there has been a growing interest in developing "cost-sensitive" active learning algorithms in the field of machine learning [@haertel2008return]. And researchers have started to define costs in increasingly sophisticated psychological terms. For example, @settles2008active point out that cost should not be measured as a reduction in the number of training trials if those training trials vary in length. Thus, an efficient active learner should take into account the "cost" to another person for providing some information, creating a computation of how valuable this information is for me weighted by how long it would take to get or how difficult it would be for somebody else to give it to me. It remains an interesting and open question as to how children develop the capacity to reason about costs other than time or difficulty, including social costs such as reputation.  

# Conclusions

The goal of this paper was to suggest a way forward for integrating ideas from two influential accounts of cognitive development: active and social learning. Social learning theories emphasize the importance of learning from rich social input tuned to the cognitive capacities of the learner and likely to contain generalizable information. In contrast, active learning accounts emphasize children's powerful self-directed learning skills, arguing that children are capable of generating and efficiently testing a broad range of hypotheses.

I argued that Optimal Experiment Design (OED) is a useful tool for making scientific progress on an integrative account of active learning within social contexts. The OED framework provides a decomposition of information seeking into four model components -- goals, hypotheses, questions, and answers -- and other factors that are important but exist outside the model such as stopping rules. I used the OED decomposition to bring social learning models and findings into contact with active learning theory. I argued that the social context can influence children's active learning by: 

  1. communicating and/or triggering a diverse set of goals both informational and/or social, 
  2. shaping the content of children's hypothesis spaces via in-the-moment behaviors or accumulation of cultural input over developmental time
  3. serving as a model of useful queries
  4. providing useful and generalizable answers
  5. modulating when children decide to stop collecting information 


The heart of this proposal is that both social and active learning theories have much to be gained from analyzing the other. For example, social learning research can enrich our understanding of what factors the active learner considers in the cost-benefit calculus that learners consider during real-world learning that is characterized by social interaction. On the other hand, researchers interested in the effects of social contexts can benefit from active learning research by drawing on advances in the fields of machine learning, decision theory, and statistics to continue building a formal framework for understanding social learning phenomena. Practically, this integrative account suggests that our experiments should move beyond studying active learning in the absence of a social context and treating learners as shifting between states of active and passive learning. Moreover, I suggest that active learning research would benefit from characterizing the presence of learning goals, constrained hypothesis spaces, and distribution of information vs. social goals in children's everyday experience. This new approach represents a shift from relying on highly-controlled lab-based tests of children's active learning skills to focusing on large-scale observational datasets.

And while this integrative approach adds complexity to our experiments and models, I argue that the benefit will be a far better capacity to predict how learning will unfold in children's everyday lives, which consist of many repeated instances of active learning that operates over fundamentally social input.  

\newpage

# References

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = 'refs'></div>

\newpage

# Appendix {#app}

\setlength{\parindent}{0in}
\setlength{\leftskip}{0in}

R code to implement the worked example of OED presented in Part 3. First, we define some functions to make the computation of conditional probability, entropy, and information gain easier.

```{r, echo = T}
# bayes rule to compute conditional probability
compute_bayes <- function(prior_a, 
                          prior_b, 
                          likelihood) {
  (prior_a * likelihood) / prior_b
}

# entropy functions
compute_symbol_ent <- function(probability) {
  if(probability == 0) {
    0
  } else {
    (probability * log2(probability)) * -1  
  }
}

compute_entropy <- function(probability_vector) {
  sapply(probability_vector, compute_symbol_ent) %>% 
    sum() %>% 
    round(digits = 2)
}

# compute intormation gain of a single answer
compute_utility_answer <- function(prior_entropy, 
                                   posterior_entropy) {
  prior_entropy - posterior_entropy %>% 
    round(digits = 2)
}

# compute intormation gain of a question
compute_utility_question <- function(prior_entropy, 
                                     utility_answers, 
                                     probability_answers) {
  posterior_entropy <- (utility_answers * probability_answers) %>% 
    sum() %>% 
    round(digits = 2)
  prior_entropy - posterior_entropy
}
```

Next, we instantiate our prior knowledge of the world as global variables that will get passed to the expected utility functions.

```{r, echo = T}
# prior probabilities of species
prior_prob_glom <- 0.7
prior_prob_fizo <- 1 - prior_prob_glom

# conditional probabilities of features for each species
prob_meat_glom <- 0.1
prob_meat_fizo <- 0.9
prob_nocturnal_glom <- 0.3
prob_nocturnal_fizo <- 0.5
```

\noindent
Next, we use Bayes rule to compute how much our beliefs would change if we saw evidence of eating meat. To do 

$$
\begin{aligned}
P(glom \mid eatsMeat) &= \frac{P(eatsMeat \mid glom)P(glom)}{P(eatsMeat)},\\
where,\\
P(eatsMeat) &= [P(eatsMeat \mid glom)P(glom)] + [P(eatsMeat \mid fizo)P(fizo)]
\end{aligned}
$$

\noindent
In R code, we compute the prior probability of the presence and absence of the "eats meat" feature as:

```{r, echo = T}
# compute probability of the presence of eating meat
prob_meat <- (prob_meat_glom * prior_prob_glom) + 
  (prob_meat_fizo * prior_prob_fizo)

# compute probability of the absence of eating meat
prob_notMeat <- 1 - prob_meat
```

\noindent
Next, we use Bayes rule to compute the change in beliefs about species if we observed the creature eating meat.

```{r, echo = T}
# use bayes rule to compute conditional probability that glom 
# given that eats meat answer is yes
cond_prob_glom_meat <- compute_bayes(prior_a = prior_prob_glom, 
                                     prior_b = prob_meat, 
                                     likelihood = prob_meat_glom)

# use bayes rule to compute conditional probability that fizo 
# given that eats meat answer is yes
cond_prob_fizo_meat <- compute_bayes(prior_a = prior_prob_fizo, 
                                     prior_b = prob_meat, 
                                     likelihood = prob_meat_fizo)
```

\noindent
Next, we compute the expected utility of getting a specific answer ($U(eatsMeat = yes)$). Recall that we define an answer's utility as it's information gain, which is a function of the prior and posterior entropy.

```{r, echo = T}
# compute prior and posterior entropy
prior_entropy <- compute_entropy(c(prior_prob_fizo, 
                                   prior_prob_glom))

posterior_entropy <- compute_entropy(c(cond_prob_fizo_meat, 
                                       cond_prob_glom_meat))

# compute information gain
utility_yes_meat <- compute_utility_answer(prior_entropy, 
                                           posterior_entropy)
```

\noindent
Next, we apply the same procedure to get the utility of the answer "no" for the "eats meat?" question ($U(eatsMeat = no)$).

```{r, echo = T}
# use bayes rule to compute conditional probability that glom 
# given that eats meat answer is no
cond_prob_glom_notMeat <- compute_bayes(prior_a = prior_prob_glom, 
                                        prior_b = 1 - prob_meat, 
                                        likelihood = 1 - prob_meat_glom)

# use bayes rule to compute conditional probability that fizo 
# given that eats meat answer is no
cond_prob_fizo_notMeat <- compute_bayes(prior_a = prior_prob_fizo, 
                                        prior_b = 1 - prob_meat, 
                                        likelihood = 1 - prob_meat_fizo)

# compute prior and posterior entropy
prior_entropy <- compute_entropy(probability_vector = c(prior_prob_fizo, 
                                                        prior_prob_glom))

posterior_entropy <- compute_entropy(probability_vector = c(cond_prob_fizo_notMeat, 
                                                            cond_prob_glom_notMeat))

# compute information gain for the answer
utility_no_meat <- compute_utility_answer(prior_entropy, posterior_entropy)
```

\noindent
Finally, to compute the overall expected utility of the "eats meat?" question ($EU(Q)$), we weight the utility of each answer by the prior probability of getting that answer.

```{r, echo = T}
utility_meat_q <- compute_utility_question(prior_entropy,
                                           c(utility_yes_meat, utility_no_meat),
                                           c(prob_meat, 1 - prob_meat))

paste0("The expected utility of the eats meat question is: ", utility_meat_q)
```