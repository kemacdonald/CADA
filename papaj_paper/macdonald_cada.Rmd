---
title             : "How social contexts shape active learning"
shorttitle        : "Active learning is social"

author: 
  - name          : "Kyle MacDonald"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Stanford University"

author_note: |
  Conceptual Analysis of Dissertation Area. 
  
  Readers: Michael C. Frank, Hyowon Gweon, and Anne Fernald

abstract: |
  Children's rapid conceptual development is one of the more remarkable features of human cognition. How do they learn so much so quickly? Social learning theories argue for the importance of learning from rich input provided by more knowledgeable others. In contrast, active learning accounts focus on children's efficient information seeking skills as a path to knowledge acquisition via self-directed exploration. In this paper, I argue that an important step towards a complete theory of early learning is to understand how active learning behaviors unfold within social learning contexts. To integrate the two theoretical accounts, I use the theory of Optimal Experiment Design (OED), which formalizes human inquiry as a process of expected utility maximization with respect to the goal of gaining new information. The heart of my argument is that in order to characterize the usefulness of active learning behaviors (e.g., causal interventions, eye movements, and verbal question-asking) we must consider recent insights into how decisions and learning are shaped by our interactions with other people.
  
keywords          : "active learning, social learning, decision making, theory"
wordcount         : "X"

bibliography      : ["cada_library.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
---

```{r load_packages, include = FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo=F, warning=F, cache=T, message=F, sanitize=T)
library("papaja")
library(knitr); library(tidyverse); library(spelling); library(xtable)
```

# Introduction 

Human learning is remarkable. Consider that children, despite their limitations on general processing capabilities, are able to acquire new lexical concepts at a high rate, eventually reaching an adult vocabulary ranging between 50,000 to 100,000 words [@bloom2002children]. And they accomplish this all while also developing motor skills, learning social norms, and building causal knowledge. How can we explain children's prodigious learning abilities?  

Social learning accounts offer a solution by pointing out that children do not solve these problems on their own. Instead, children are typically surrounded by parents, other knowledgeable adults, or older peers – all of whom likely know more than they do and are interested in facilitating their learning. Social learning accounts also emphasize that social contexts can bootstrap children's learning via several mechanisms. For example, work on early language acquisition shows that social partners provide input that is tuned to children's cognitive abilities [@fernald1987acoustic; @eaves2016infant], that guides children's attention to important features in the world [@yu2007unified], and that increases levels of sustained attention, which result in better learning [@yu2016social; @kuhl2007speech]. 

Social contexts also change the computations (i.e., inferences) that support children's learning from evidence. Recent work in the fields of concept learning and causal intervention suggests that the presence of another person engages a set of psychological processes where the learner reasons about *why* other people performed certain actions. The key insight is that knowledge that another person selected examples to help you learn, allows children to make stronger inferences that speed learning [@frank2009using; @bonawitz2016computational; @shafto2014rational]. For example, people will learn at different rates after observing the same action depending on whether they thought the behavior was accidental (less informative) or intentional (more informative. Moreover, adults and children will make even stronger inferences if they think that another person's actions were selected with the goal of helping them learn (i.e., teaching) [@shafto2012learning].

However, children are not merely passive recipients of information -- from people or from the world. Instead, children actively select behaviors -- for example, asking questions or choosing where to allocate visual attention -- that change the content, pacing, and sequence of their learning experience. Recent theories of cognitive development have proposed the metaphor of "child as an intuitive scientist" and characterized early learning as a process of exploration and hypothesis testing following principles of the scientific method [@gopnik1999scientist; @schulz2012origins]. Moreover, recent empirical work across a variety of domains -- education [@grabinger1995rich], machine learning [@settles2012active; @castro2009human], and cognitive science [@markant2014better] -- has directly compared learning trajectories in contexts marked by self-directed choice (active learning) as compared to contexts where the learner has less control (passive learning). The upshot of this work is that active contexts often lead to faster learning rates by enhancing basic processes related to learning such as attention and arousal or by providing learners with better information that is more tightly linked to their current goals, beliefs, and interests (see @gureckis2012self for a review). 

Thus, children are capable of guiding their own learning and social contexts provide particularly good learning environments. How can we integrate these two proposals? Answering this question represents an important step towards a complete theory of early learning.  And important step because children's active learning often occurs within social learning contexts. And an efficient learner should integrate information from other people when deciding what to learn next. 

In this paper, I propose an integrative account of active learning within social contexts. I use the formal framework of Optimal Experiment Design [@emery1998optimal; @lindley1956measure] as a conceptual tool to bring social learning effects into contact with the underlying decision processes that support active learning. The key insight is that learning in the presence of other people plays a direct role in determining the *usefulness* of active learning behaviors. The paper is organized as follows. First, I define what the terms "active" and "social" learning and provide limits on the scope of phenomena that the integrative account aims to address. Then, I review the behavioral evidence showing that social (Part I) and active (Part II) contexts change how learning unfolds. From there I present the theory of Optimal Experiment Design (OED) (Part III) as a formal framework for understanding the decision-making process of active learning. Finally, I outline a series of links between social learning and self-directed choice, taking a step towards understanding active learning within social contexts (Part IV).

# The scope of the problem

Many influential theories of cognitive development have tried to understand the relative contributions of "active" learning and "social" input to children's cognitive development. As a result, the terms are semantically "overloaded" making it difficult to know precisely what researchers mean. So before reviewing the empirical evidence for the social and active learning accounts, it is worth defining  "active learning" and "social contexts." In this section, I also scope the behaviors that the integrative account attempts to explain and highlight several important distinctions that come up throughout the paper, including the different *timescales* through which social contexts shape active learning and the importance of other people’s goals and intentions for explaining social learning phenomena. 

Learning can be "active" in a variety of ways. First, a child could be physically active, and this movement could change what information they extract from the experience. There is a large body of research that explores the effects of action experience on infants' learning (see @kontra2012embodied for a review of work on embodied cognition). One classic example from @needham2002pick shows that infants who physically hold and manipulate objects will outperform a control group who did not have the equivalent physical experience on measures of object attention and exploration. Second, active learning could refer to children's contributions to processing incoming information. For example, young learners do not just passively accept other people's claims and will reject answers that conflict with their own knowledge [@pea1982origins]. Third, children might engage in self-generated "active" explanations. @lombrozo2006structure review evidence that 'self-explanation' (i.e., explaining novel information to oneself) can lead to better learning. Finally, active learning could refer to the output of a decision-making process where learners select, sequence, and pace their own learning experiences (see @gureckis2012self for a review).

Here, I focus on active learning effects that arise via decision making. The key assumption is that active learners are trying to maximize the usefulness of their actions when choosing to gather information. By scoping the paper to information seeking *decisions*, we do not aim to ignore the importance of other forms of active learning; rather, my goal is to constrain the space of possible connections between active and social learning theories. Moreover, decisions during active learning still capture a rich variety of behaviors, including pointing, eye movements, verbal question asking, and causal interventions. 

Learning can also be "social" in a variety of ways. First, children could learn with another person present but without attending to or directly interacting with that person. Research in social psychology shows that the mere presence of other people can facilitate performance of simple tasks and impair the performance of complex tasks [@uziel2007individual; @cottrell1968social]. Second, children could learn by looking to others as a guide, observing or imitating their behavior. In fact, children's capacity for faithful imitation is a critical feature separating human from non-human learning [@call2005copying]. Finally, children could both attend to the person and directly interact with them, entering a communicative learning context that engages powerful psychological reasoning that change learning processes. 

In this paper, I define a "social context" as a learning environment where another agent is present. This definition includes all of the social learning behaviors -- observation, imitation, and learning from direct interaction -- discussed above. I use a broad definition to highlight the variety of ways that social contexts could shape children's decisions during learning. It is important to point out that the effects of social input could operate on at least three timescales: (1) an in-the-moment timescale (e.g., imitating another person), (2) a developmental timescale (e.g., prior social input shaping current decisions), and (3) a cultural/evolutionary timescale (e.g., learning language). The paper is not organized around these timescales, but in certain sections, I highlight when they are particularly relevant to the discussion. 

In sum, the goal of this paper is to propose an integrative active and social learning account. I use a specific definition of active learning -- choices maximizing information gain -- and show that a broad suite of social learning effects could shape these decisions. Before presenting the integrative account, I review evidence that both social and active learning (a) modulate basic learning processes such as attention and memory, (b) provide information that might be especially "good" for learning, and (c) change the strength of children's inferences and generalization that support learning.


# Part I: Learning from other people

Social learning theories argue that children's rapid conceptual development is facilitated by the uniquely human capacity to transmit and acquire information from other people. One primary benefit of learning from other people is that children gain access to knowledge that has accumulated over many generations; information that would be far too complex for any individual person to figure out on their own [@boyd2011cultural]. In addition to these cumulative effects, social contexts facilitate "in-the-moment" learning since more knowledgeable others can select input that best supports learning [@shafto2012learning; @kline2015learn] and is likely to be generalizable beyond the current context [@csibra2009natural].

There is a large body of empirical work on social learning across a variety of domains, e.g., language acquisition, causal learning, and concept learning. Importantly, these social learning effects manifest via different pathways such as guiding attention, increasing arousal, providing better information, and changing the strength of children's inferences. In this section, I briefly review the evidence for each pathway, with the goal of providing a high-level taxonomy of social learning effects. 

```{r table1, results = "asis"}
learning_type_table <- read_csv(file = "tables/active_social_overview.csv", trim_ws = T)
bold <- function(x) {paste('{\\textbf{',x,'}}', sep ='')}
print(xtable(learning_type_table,
             align = c('l', 'p{1.5in}', '|', 'p{2in}', '|', 'p{2in}'),
             label = "act_soc",
             caption = "High level summary of three different paths through which active and social contexts influence learning. See Part I (social learning) and Part 2 (active learning) for more details and reviews of the behavioral evidence."
             ),
      include.rownames=FALSE, 
      hline.after=c(0,1,2,3),
      sanitize.text.function=function(x){x},
      sanitize.colnames.function=bold,
      caption.placement = 'top', 
      table.placement = "tb",
      comment = F)
```

## Social contexts enhance attention and memory

From infancy humans preferentially attend to social information. For example, newborn infants prefer to look at face-like patterns compared to other abstract configurations [@johnson1991newborns] and even show a preference for faces that make direct eye contact compared to faces that avert gaze [@farroni2002eye]. In the auditory domain, newborns prefer to listen to speech over non-speech [@vouloumanos2007listening], their mother's voice over strangers' voices [@decasper1987human], and infant-directed speech over adult-directed speech [@cooper1990preference; @pegg1992preference; @fernald1987acoustic]. Moreover, recent work by @yu2016social, using head-mounted eye trackers to record parent-child interactions, shows that one-year-olds will sustain visual attention to an object longer when their parents had previously looked at that object.

These early attentional biases lead to differential learning in the presence of another person. For example, 4-month-olds show better memory for faces if that face gazed directly at them as compared to memory for a face with averted gaze  [@farroni2007direct]. They also show enhanced memory for objects if an adult gazed at that object during learning [@reid2005adult; @cleveland2007joint]. Converging evidence comes from @thiessen2005infant's work, showing that 7-month-olds perform better at word segmentation if the words are presented in infant-directed speech compared to adult-directed speech.

@kuhl2007speech refer to these effects as "social gating" phenomena since the presence of another person activates or enhances children's underlying computational learning mechanisms. One particularly striking piece of evidence for the social gating hypothesis comes from @kuhl2003foreign's study of infants' foreign-language phonetic learning. In this experiment, 9-
 to 10-month-old English-learning infants listened to Mandarin speakers either via live interactions or audiovisual recordings. When their ability to discriminate Mandarin-specific phonemes was assessed two months later, only the infants who were exposed to Mandarin from social interactions were able to discriminate successfully. In contrast, infants in the audiovisual recording condition showed no evidence of learning. @kuhl2003foreign also found that infants in the social interaction condition showed higher rates of visual attention to the speaker, suggesting that the social context enhanced learning by increasing children's attention to the input.
 
Converging evidence comes from studies showing that when adults interact with an avatar that is controlled by a person rather than a computer, they experience higher levels of arousal, learn more, and pay more attention [@okita2008mere]. And recent work by @roseberry2014skype found that children learn equally well from interactions with a person in a video chat (e.g., Skype) if social contingency was established, but they did not learn from watching a digital interaction between the adult and another child.

The common thread across these findings is that the presence of another person increases attention. And as a result, social input becomes more salient and more likely to come into contact with general learning mechanisms. These changes occur within the child, i.e., they are endogenous social context effects. However, social contexts often provide better learning environments, leading to exogenous effects on learning. In fact, social learning theories often start from the premise that early learning environments are unique because children are surrounded by people who know more than they do and are invested in their learning. These features come together to create contexts where more knowledgeable others select learning experiences that are particularly beneficial -- either because the information is tuned to children's current cognitive abilities or because the information is likely to generalize. 

## Social contexts provide "good" information

The idea that children's input might be shaped to facilitate their learning is a key aspect of several influential theories of cognitive development (e.g., Zone of Proximal Development [@vygotsky1987zone], Guided Participation [@rogoff1993guided], and Natural Pedagogy [@csibra2009natural]). But how exactly do social interactions provide particularly useful information? 

One particularly compelling set of evidence comes from research on the ways that caregivers alter their communication style when speaking to young children. The work on infant-directed speech shows that adults do not speak to children in the same way as they speak to other adults; instead, they exaggerate prosody, reduce speed, shorten utterances, and elevate both pitch and affect (for a review, see @fernald1984expanded). Subsequent empirical work has shown that these features of infant-directed speech can help infants solve a variety of language acquisition challenges, including vowel learning [@adriaans2017prosodic; @de2003investigating], word segmentation [@fernald1991prosody; @thiessen2005infant], word recognition [@singh2009influences], and word learning [@graf2013infant]. 

Additional evidence that social contexts provide information tuned to individual learners comes from work on infants' early vocal production. For example, @goldstein2008social measured whether infants modified their babbling to produce more speech-like sounds after interacting with caregivers who provided either contingent or non-contingent responses to their infants' babbling. They found that only infants in the contingent feedback condition changed their vocalization behavior to produce more adult-like language forms. @goldstein2008social hypothesized that the contingency effect was driven by infants' receiving input that was particularly useful for solving this learning problem. Specifically, the contingent feedback was close in time to infants' vocalizations, making it easier for them to compare discrepancies between the two. 

A third piece of evidence comes from research on children's early word learning. Social-pragmatic theories of language acquisition emphasize the importance of social cues for reducing the referential uncertainty present when children are trying to acquire novel words [@bloom2002children; @clark2009first; @hollich2000breaking]. Empirical work by @yu2012embodied shows that young learners tend to retain words that are accompanied by clear referential cues (e.g., adults' pointing and gaze direction), which serve to make a single object dominant in the visual field  [@yu2013joint; @yu2005role]. Moreover, correlational studies show positive links between early vocabulary development and parents' tendency to refer to objects that children are already attending to (i.e., "follow-in" labeling) [@tomasello1986joint].

Taken together, these findings provide a compelling set of evidence that social contexts benefit learning by providing especially "good" input. Similar to the attention/memory effects, these effects occur in-the-moment of learning. In contrast, they are properties of children's input, that is, their usefulness is driven by processes that are external to the learner, but internal to the learner's social partner. A third way social contexts shape learning is by engaging a powerful set of social reasoning processes that change how much learners learn from new evidence.

## Social contexts shape inferences and generalization

One defining feature of social learning is that people's actions are not random. Instead, people select behaviors with respect to some goal (e.g., to communicate a concept), and in turn, learners can reason about *why* someone chose to perform a particular action. The key point is that social learning contexts engage a process of reasoning about others' goal-directed actions that change how people interpret superficially similar behaviors, thus altering the learning process. 

Recent empirical and modeling work has formalized this social reasoning process within the framework of Bayesian models of cognition [@shafto2012learning; @frank2014inferring; @goodman2016pragmatic]. Social learning is characterized as a process of belief updating that depends on two factors: the learner 's beliefs before seeing any evidence and what the learner thinks about the process that generated the evidence. If the learner assumes that information is generated with the intention to communicate (or teach), then they can make "stronger" inferences. ^[Formally, these models change the form of the likelihood term in Bayes theorem in order to capture a person’s theory of how data are generated. Links between this formalization and active learning accounts will be discussed in more detail in Part IV. ]

For example, @goodman2009cause presented adults with written descriptions of the following causal learning scenarios. Someone generates a causal effect (e.g., growing flowers) by performing two actions at the same time (e.g., pouring a yellow liquid and a blue liquid). The person who generated the effect was either the participant or another person who already knew the causal structure. The participants' task was to identify the correct causal structure. When participants thought the other person was knowledgeable, they were more likely to think that performing *both* actions was necessary. In contrast, when the participant generated the causal effect on their own (not knowing the causal structure), adults were less sure that both actions were necessary. @shafto2012learning interpreted these results as a psychological reasoning process such as "if the other person was knowledgeable and wanted to generate the effect, then he would definitely perform both actions." These effects also suggest that learners assume that other people's goal-directed behaviors will be efficient since they should avoid performing the extra action (pressing two buttons) if it was unnecessary. 

Similar effects of psychological reasoning on inference have been shown in the domains of word learning [@xu2007word; @frank2014inferring], selective trust in testimony [@shafto2012epistemic], tool use [@sage2011disentangling], and concept learning [@shafto2014rational]. Moreover, there is evidence that even young learners' inferences are sensitive to the presence of goal-directed behaviors. For example, @yoon2008communication showed that 8-month-olds will encode an object's identity if their attention was directed by a communicative point, but they will encode an object's spatial location if their attention was directed by a non-communicative reach. And @senju2008gaze found that infants will follow another person's gaze only if the gaze event was preceded by their social partner providing a relevant, communicative cue (e.g., infant-directed speech or direct eye contact). 

In addition to being easier to learn, information acquired in social contexts is also more likely to generalize, i.e., be useful beyond the current learning context. @csibra2009natural argue that this assumption of *generalizability* is a fundamental component of "Natural Pedagogy" -- a uniquely human communication system that allows adults to efficiently pass along cultural knowledge to children. These contexts are marked by adults providing ostensive signals to the child such as direct gaze, infant-directed speech, and infant-directed actions. These actions direct infants' attention towards the sources of the ostensive signals, and bias infants to expect generalizable knowledge.

Experimental work testing predictions of the Natural Pedagogy account show that children tend to think that information presented in communicative contexts is generalizable [@yoon2008communication; @butler2012preschoolers]. For example,  @butler2012preschoolers showed that preschoolers were more likely to expect a novel causal property (e.g., magnetism) to generalize to new objects with the same shape if the causal property had been demonstrated with pedagogical cues. Moreover, corpus analyses show that generic language (e.g., "birds fly") is common in everyday adult-child conversations [@gelman2008generic], suggesting that these powerful learning contexts are prevalent in children's experience.

Across these studies, learners interpreted similar information in different ways depending on their assumptions about other people's goals. These effects are different from the attentional (internal to the learner) and informational (external to the learner) explanations reviewed above in that the inferences based on social information are part of the underlying computations that support learning. However, it is important to point out that, similar to the Social Gating account, Natural Pedagogy also argues that the presence of pedagogical cues enhances processes internal to the learner such as attention. Finally, these accounts dovetail with evolutionary models that emphasize the importance of pedagogy for the accumulation of human cultural knowledge [@kline2015learn; @boyd2011cultural].

## Social learning summary

Taken together, the work reviewed in this section highlight several points about social learning. First, from an early age, children are surrounded by other people who know more than they do. Moreover, these more knowledgable agents are invested in children's development and motivated to provide rich learning opportunities. Second, from infancy children are motivated to interact with other people, and these interactions are exciting and guide attention to relevant information in the environment. Finally, social learning contexts engage a sophisticated set of psychological reasoning mechanisms that build off children's capacity for detecting others' goal-directed behavior. Critically, the output of this social reasoning process is that learners are able to make stronger inferences about observed evidence, and in effect, extract more information out of their input. 

However, it is clear that social input does not account for all of children's rapid conceputal development. Put another way, children are not just passively receiving input from the world and from other people. Instead, they actively process incoming information and select behaviors that change what they learn. A parallel body of research on children's "active learning" has developed alongside the social learning work. Thus, in the next section, I review this work with the goal of answering the question: how do children shape their own learning experiences? 

# Part II: Learning on your own 

The idea that children are "active" learners has been an influential aspect in many classic theories of cognitive development (e.g., @bruner1961act; @berlyne1960conflict). Moreover, recent theorizing has directly linked cognitive development to a process of active hypothesis testing and theory revision that follows the principles of scientific inquiry [@schulz2012origins; @gopnik1999scientist]. Under these accounts, children are not just passive recipients of information; instead, children drive their own conceptual development by generating meaningful learning experiences via their own actions. 

In addition to playing a prominent role in developmental theory, the effects of active learning have been the focus of a great deal of empirical work in education [@grabinger1995rich; @prince2004does], machine learning [@settles2012active; @ramirez2017active], and cognitive psychology [@castro2009human; @chi2009active]. The common thread across these diverse literatures is that active learning contexts -- where people have control over the learning environment -- lead to different (often more rapid) learning when compared to passive contexts where people do not have control over the flow of information. 

But how does active control change the way people learn? In this section, I review the evidence for three mechanisms that parallel the social learning effects reviewed in Part I. First, active learning contexts enhance the underlying processes of attention and memory, leading to stronger learning. Second, active learners can use their own uncertainty to select learning experiences that will be tailored to their own goals, beliefs, and capabilities. Third, active learning can result in weaker inferences and generalization since there is no guarantee that self-generated examples will be informative.  I conclude Part II with some discussion of why studying active learning might be particularly challenging to motivate the Optimal Experiment Design formaliztion presented in  Part III.

## Active contexts enhances attention and memory

A growing body of research has demonstrated that giving people control over the learning process can change the basic processes -- e.g., attention and arousal -- that support learning.  In these experiments, learning outcomes for active and passive contexts are directly compared to see the effects on various types of learning tasks such as episodic memory, casual intervention, and concept learning. In a review of this literature, @markant2016enhanced propose that the active learning advantage is driven by an increase in attention and memory with the precise pathway determined by the type of control (e.g., timing,  content, timing & content) given to the learner. 

For example, consider a child who is playing with a set of toys and turns to ask their parent, "What's this?" In this case, the child is in control of both the selection (which toy gets labeled) and the timing (when the labeling event occurs) of the incoming information.  One nice empirical demonstration comes from a study by @markant2014deconstructing where they "decomposed" the different active learning effects. In their task, participants were asked to memorize the identities and locations of objects that were hidden in a grid. @markant2014deconstructing varied the *level* of control that participants had over the learning experience. Participants could control either: (1) the next location in the grid, (2) the next item to be revealed, (3) the duration of each learning trial, and/or (4) the time between learning trials (i.e., inter-stimulus-interval or ISI). Importantly, @markant2014deconstructing included a "yoked"  control group with participants who saw the training data generated by the active group, thus equating the informational content but varying the level of control. There was an active learning advantage for all levels of control, including the lowest amount of control in the ISI-only condition. These results suggest that active control allowed learners to generate information when they had processed the previous trial and were ready to attend and learning something new.

Developmental studies have also used this "decomposition" approach and found parallel active learning advantages in spatial memory tasks for 6- to 8-year-olds [@ruggeri2016active]. Other empirical work has found similar benefits of active control in word learning (@partridge2015young; see also @kachergis2013actively for evidence in adults) and understanding causal structures [@schulz2012origins]. For example, @sobel2006importance showed that preschoolers who designed their own interventions on a causal system learned more compared to yoked participants who either passively observed the same sequence of actions or re-created the same choices made by others (but see @mccormack2016children for counter-evidence). Moreover, even young infants benefit from active engagement with the learning environment. For example, @begus2014infants showed that 16-month-olds exhibit stronger memory for information that was provided about an object they had demonstrated an interest in via pointing compared to an object that they had previously ignored.

Additional evidence that active control enhances attention and memory comes from research on children's engagement with educational technology (for a review, see @hirsh2015putting). For example, @calvert2005control exposed preschool-aged children to two sessions of reading a computer storybook with an adult and manipulated whether the adult or the child controlled the mouse and could advance the story. Children in the adult-control condition showed a decrease in attention to the storybook materials in the second session. In contrast, children who were given control over the experience maintained a constant level of attention across both sessions, suggesting that active control provided a buffer against children's disengagement from the task.

These results parallel the literature on attention/memory effects in social learning reviewed in Part 1. That is, both active and social processes can modulate processes internal to the learner to facilitate in-the-moment learning. However, the effects of active control go beyond changing lower-level cognitive processes and modulate the quality of *information* that learners get from the world.  

## Active contexts provide "good" information

One defining feature of active learning is that people gather information that is particularly "useful" for their own learning. This benefit relies on the fact that learners have privileged access to their own prior knowledge, current hypotheses, and ability level, which they can leverage to create more helpful learning contexts (e.g., asking a question about something that is particularly confusing). Research on this component of active learning focuses on how learners select actions to create learning content that is more useful compared to passive contexts where the learner has less control. 

For example, @castro2009human directly compared adults category learning in active vs. passive contexts to predictions from statistical learning theory to quantify how well active learners do when compared to a model of optimal active learning. Participants were shown a sequence of 3-D objects on a computer screen that varied along a single, continuous dimension (spiky to smooth) and given feedback as to which category the stimulus belonged to. Participants task was to learn the correct category boundary. In the active condtion, learners could select which object they wanted labeled; whereas, in the passive condition, participants saw stimuli generated randomly from the true category boundaries. Active learning was always superior to passive learning with adults learning the category structure in less time and achieving higher levels of accuracy. However, the human active learners did not reach the performance of the ideal observer model and the advantage for active over passive learning decreased in the more difficult (i.e., noisier) learning tasks. 

Using a similar approach, @markant2014better investigated the effects of active vs. passive hypothesis testing on the rate of adults’ category learning. They varied the difficulty of the learning task by testing two different types of category structures: a rule-based category, which varied along a single dimension (easier to learn), and an information-integration category, which varied along two dimensions (harder to learn). In the active condition, the learner could choose specific observations from the category to test their beliefs; whereas, in the passive condition, the sequence of data was generated randomly by the experiment. @markant2014better also included a "yoked" passive condition where participants saw sequences of obbservations generated by active learners, but did not have control over the sequence. Similar to the @castro2009human findings, participants in the active condition learned the category structure faster and achieved a higher overall accuracy rate compared to the passive learners and the yoked-passive learners. @markant2014better explain the active learning advantage in terms of the higher informational value of self-generated observations that take into account learners' own hypotheses. Importantly, the advantage for active learners over the yoked participants suggests that the information value is funamentally linked to the individual learner. Also, it is important to point out that an active learning advantage was only found for rule-based category, the simpler learning task.

The effects of active engagement have also been shown in studies of discourse understanding. @schober1989understanding has pairs of adults complete a "tangram" task where one person (director) used natural language to inform another person (matcher) what order to arrange tangrams (geometric objects, called tans, which are put together to form shapes) in a 4x4 matrix. The matcher was given different levels of control over the conversation: (1) could actively participate (i.e., talk to the director), (2) could listen to the recorded conversation of director-matcher and pause the tape, and (3) could listen to the entire conversation but not pause the tape. Results showed that active participants had a marked advantage as compared to overhearers. Interestingly, the ability to pause the tape in the passive condition did not help accuracy, suggesting that the active advantage is driven by informational value, and not just control over the timing and pacing of incoming information. Also, passive participants reported frustration with being unable to correct early failures of understanding novel conventions developed by the director (e.g., "I don't know what 'this one' means!). That is, no amount of control over timing can make up for lack of control of the information content in the overhearing conditions. @schober1989understanding point out that conversations can be construed as active information gathering about other people's intentions, and when people are unable to actively participate, they lose access to critical information that supports later comprehension.

Taken together, these findings on active learning illustrate several important points for understanding the effects of active learning on information value. First, the quality of active exploration was fundamentally linked to the learner's understanding of the task: if the representation was poor, then self-directed learning was less effective.  Second, the benefits of active control were tied to the aspects of the individual learner -- i.e., their prior knowledge and their current hypotheses under consideration -- such that the same sequence of data did not provide "good" information for another learner. And third, the benefits of active learning diminished with increased task difficulty because learners struggled to generate "helpful" examples. These points will be important for the ideas discussed in Part III of this paper when I outline the formalization of human active learning.

Given these considerations about the link between aspects of the learner (e.g., prior knowledge and understanding of the task) and the quality of active learning, are young children capable of generating useful information to support their learning? A recent body of developmental work on children's pointing provides insight into this question. Specifically, this work asks whether young learners, who might not be capable of more sophisticated information seeking behaviors such as verbal questions, can use actions at their disposal (i.e., pointing) to change the flow of information and boost learning. For example, @wu2015caregivers found that adults generate a higher number of object labels for objects that their 12-month-olds pointed to, suggesting that the infants' pointing elicited information that was particularly useful for early concrete word learning (for converging evidence, see @kishimoto2007pointing; @goldin2007young; and @olson2011infants). In addition, experimental by @begus2012infant found that infants point more in the presence of a knowledgeable person compared to in the presence of an incompetent person, suggesting that the pointing behavior is driven by a desire to learn as opposed to a desire to share attention. Finally, infants who produce more pointing gestures have larger vocabularies later in development [@rowe2009early], providing additional evidence that even young infants are capable of generating actions that elicit information to support learning. 

Later in development, when children being to acquire the requisite productive language skills, they start asking verbal questions. The evidence suggests that children use questions to gather information. For example, in a corpus analysis of four children's parent-child conversations, @chouinard2007children found that children begin asking verbal questions early in development (18 months) and at an impressive rate, ranging from 70-198 questions per hour of conversation. @chouinard2007children also coded the intent of children's questions, finding that 71% were for the purpose of gathering information, as opposed to seeking attention or clarification. Other corpus analyses provide converging evidence that question asking is a common behavior in parent-child conversations [@davis1932form], that children are seeking knowledge with their questions [@bova2013investigating], and that children will persist in asking questions if they do not receive a satisfactory explanation [@frazier2009preschoolers]. 

Perhaps the strongest evidence that children are capable of effective self-directed learning comes from research on children's causal learning. In these studies, children are presented with a novel toy that has some unknown causal structure and given the opportunity to play with the toy (i.e., design interventions) to figure out how it works. A nice feature of these experiments is that the space of possible actions and hypotheses are constrained such that it becomes possible to directly quantify the usefulness of children's causal interventions compared to the predictions of formal models of optimal information seeking (e.g., see Part III).

For example, @cook2011science showed preschoolers a device that played music when beads were placed on top of it. To test whether children would choose interventions that generated useful information, they manipulated the usefulness of the different actions that children could take in order to test the device. Half of the children saw evidence that all types of beads could make the machine work, while the other half of children learned that only specific types of beads (defined by color) could make it go. Next, children were given the opportunity to choose between two sets of beads to make the machine play music: (1) a set of two beads that were stuck together or (2) a set of two beads that could be separated. Children who learned that only some of the beads made the machine play music were twice as likely to choose the separable beads to test the device.  This suggests that children were reasoning about the amount of information to be gained from selecting the separable beads, which allowed them to test each bead independently. In contrast, the children who believed that all the beads worked had less information to be gained by picking the separable beads. This result is especially compelling because it provides evidence that children's were capable of reasoning about a decision (separable vs. stuck together beads) that would influence their future opportunity to generate useful information by testing both beads independently.

Other work in the domain of causal inference shows that preschoolers integrate prior beliefs and evidence to alter how they explore a causal system (e.g., testing a toy to learn the concept of balance-relations) [@bonawitz2012children], spend more time exploring an object for which they saw confounded evidence for its causal structure [@schulz2007serious], and became more efficient in producing causal interventions, measured by informativeness, as they get older (6-8 years of age) [@mccormack2016children].

Moreover,  even 8-month-old infants selectively explore objects that violate their prior expectations. For example, @stahl2015observing showed infants events that violated an expectation about objects, either solidity, continuity, or support, and then coded the kinds of actions that infants chose to perform on the objects during a free play. They found that infants exploratory actions were linked to the type of violation (e.g., banging the object after seeing a violation of solidity). The infants also learned more effectively about objects that committed violations and spent more time exploring those objects. Together, these results are a compelling demonstration that infants were sensitive to their own uncertainty and used actions to test specific hypotheses that were linked to their previous experience.

Converging evidence of infants' sensitivity to the value of seeking certain kinds of information comes from research on selective visual and auditory attention. This work starts from two assumptions: that children possess limited cognitive resources with which to process information from the world and that learning is facilitated by attending to information that is particularly likely to be learned. For example, @kidd2012goldilocks  measured how long 7- and 8-month-olds visually attended to a monitor displaying a sequence of images of different familiar objects (e.g., a toy truck). Within each sequence, infants saw trials that varied along a continuum from low to high complexity. The complexity of specific trial was defined by a computational model that took into account the sequence of objects that infants had already seen and to compute how surprising the current object was relative to that sequence. For example, if there were two objects (truck and ball) in a set, and the child had seen the sequence of [Truck-Truck-Truck-Truck], if the next trial was another Truc, then this would receive a low surprisal/complexity score. In contrast, if the child had seen the sequence [Truck-Ball-Ball-Ball] and the next trial was a Truck, then this trial would receive a high surprisal/complexity score. 

Interestingly, infants spent the most time looking at trials of intermediate complexity, somewhere between the ends of the continuum in the toy example above. Specifically, they chose to look away sooner when the object was either highly predictable or highly surprising based on the prior sequence of objects. @kidd2014goldilocks extended these results to the auditory domain, showing a similar pattern of increased attention to sequences of intermediate complexity for nonsocial sounds such as a door closing or a train whistle. Kidd and colleagues interpret these results as infants leveraging their prior experience to guide selective attention during the learning moment in order to seek out information that is likely to be useful. Here useful is defined as information that has a higher probability of being learned because it is neither too simple (no information to be gained) nor too complex (too much information to process).

In addition to seeking learnable information, infants also avoid spending time on information that is unlearnable. For example, @gerken2011infants tested whether 17-month-olds would increase attention to a stream of input that consisted of a learnable structure (i.e., Russian feminine words take the endings oj and u, and masculine words take the endings ya and yem) as opposed to a random stream of input without any information to extract (i.e., word endings that are not diagnostic of category structure). Results showed that infants were quicker to dishabituate when listening to the unlearnable information stream, suggesting that they might be tracking their learning progress and using it to decide when to stop gathering information if progress was sufficiently low. 

## Active contexts shape inferences and generalization

Active learning also changes the strength of inferences and generalization based on evidence. However, in contrast to the social learning effects discussed in Part I, active learners show evidence of "weak" sampling assumptions, leading to less restrictive inferences and generalization. Put another way, active learners are aware that there is no guarantee that the information they generate is likely to be informative, and they will adjust how much they update their beliefs if there is a reason to think that the examples they generate are not representative of the correct concept or belief.

For example, in @xu2007sampling study of 4-year-olds and adults' word generalization, participants were asked to learn the correct extension of a novel word after seeing examples drawn from a set of 30 novel objects. The set of objects was constructed such that there were two basic-level categories (15 objects) and within each of the basic categories, three smaller subordinate categories (5 objects) that varied in color, texture, and orientation. The key manipulation was whether participants saw three labeled examples from the subordinate category that were selected by a teacher who knew the correct word extension (social learning) or by the learner themselves (active learning) who did not know the correct word extension. Both adults and children made a stronger inference that the new word referred to the narrower subordinate category in the teacher-driven condition; whereas, in the learner-driven case,  behavior was reversed and children/adults were more likely to generalize to the larger basic-level category. 

@xu2007sampling explain these results as a "sensitivity" to the sampling process that generated the examples. When there was the good reason to think that the examples were linked to the word meaning, i.e., because they were selected by a knowledgeable teacher, then it would be surprising to have seen three examples drawn from the smaller subordinate category. However, if the learner selects the examples, then she has no reason to think they are drawn from the true category, and therefore should generalize more broadly by extending the novel word meaning to the basic-level category.The upshot of this work is that even young children appear sensitive to the informativeness of the sampling process. And when it does not convey additional information about the to-be-learned concept, children do not use it modify their belief updating. 

## Active learning summary

Taken together, the work on active learning reviewed in this section highlights several points that motivate our integrative active- social learning account. First, from an early age, children are capable of engaging in behaviors with the goal of seeking useful information. Second, active learning is a complex topic of research. It captures a wide range of behaviors (pointing, visual attention, and verbal questions) and is supported by a variety of reasoning processes. Related to this point, since active learning by definition to linked to the idiosyncrasies of the specific learner, it does not unfold similarly across individuals, contexts, and content domains. Finally, there is a multitude of factors that could influence active learning, creating a large set of possibilities for researchers to explore. 

One way to reduce this complexity is to use formal mathematical models and conduct an ideal observer analysis of human inquiry. Theere are several benefits to this approach for understanding cognition. 

  * First, to write a mathemtai model necessarily abstracts away some details in order to highlight general factors that affect active learning. 
  * Second, formal models allow researchers to decompose the process of active learning into separable, underlying components, which can become the target of research. 
  * compairson of human to optimal model predictions tells you how much information people are actually using to solve the problem. 
  * Important to point out that this approach is not making claims about optimality of human behavior. Instead, we are using the ideal observer as a tool for scientific progress.
  * The idea is that you focus on writing down the assumptions of how to solve the problem, and then remove the large space of possible alogorthims that might be usedover those representations, then you can focus on the structure of the learning problem. (marr) That is, you are constraining the hypotheses that you test about human active leanring.

Over the past two decades, researchers in both developmental and cognitive psychology have begun to leverage formal models of scientific inquiry as metaphors of human inquiry. These models fall under the umbrella of Optimal Experiment Design (OED). OED models were developed by statisticians with the goal of selecting the best experiment from a set of possible experiments to learn the most about a phenomenon of interest. With this formalization, researchers interested in human active learning have been able to make qualitative and quantitative comparisons between people's information seeking behavior and specific predictions from OED models, asking when and why people deviate from optimal active learning behaviors. 


```{r fig.pos = "tb", out.width="95%",fig.cap = "Schematic of an active causal learning context using the decomposition of Optimal Experiment Design. The learner generates an inquiry goal to learn how the toy works. She then considers hypotheses, including her subjective belief in each, perhaps placing more belief over the simpler, disjunctive hypotheses: only Button A or Button B. Next, she considers her possible queries (actions) and the potential outcomes if she took those actions. Together, these components quantify the expected usefullness of each action. If the learner chooses optimally, she picks the action that maximizes this expected utility. In this case, she chooses to press either Button A or B, but does not press both buttons since this action would produce confounded evidence and fail to reduce her uncertainty. See the Part III in the text for mathematical details of the OED model." }

grid::grid.raster(png::readPNG("../cada_schematic/cada_schematic.001.png"))
```

# Part III: A formal account of active learning

Optimal Experiment Design (OED) [@emery1998optimal; @nelson2005finding; @lindley1956measure] is a statisical framework that attempts to quantify the "usefulness" of each experiment within the set of possible experiments that an experimenter could conduct to improve their understanding of a phenomenon. The key insight was described by @lindley1956measure as a transition from viewing the practice of statistics as making binary decisions about what to do next to the practice of gathering information in order to sharpen one's understanding of the "state of nature" (p. 987), More concretely, he proposed that experiments should be designed to maximize a measure of expected information gain (derived from Information Theory and discussed in more detail below) and that researchers should continue the experiment until some pre-determined threshold of information is reached.

The benefit of using the OED approach is that it allows scientists to make design choices that maximize the effectiveness of their experiments, reducing inefficiency and the costs related to additional experimentation. Consider the following toy example borrowed from @ouyang2016practical where an experimenter is interested in designing the best experiment to figure out whether people think a coin is fair or biased (i.e., a trick coin). Here the researcher's hypotheses correspond to different models of the coin [$M_{fair}: Bern(\frac{1}{2})$] and [$M_{bias}: Bern(p)$ where $p \sim Uniform(0,1)$] and the experiments correspond to different sequences of coin flips that she could select as stimuli for the experiment. We can imagine that the researcher is constrained by time or resources and can only show a sequence of four coin flips, creating a space of 16 possible experiments. The value of the OED framework is that it allows the researcher to select the most informative experiment to maximize her ability to differentiate between her two hypotheses. More concretely, it provides an answer to the question of how much better it would be to do the experiment [$HHHH$] versus [$HTHT$]. In this toy example, [$HHHH$] is a more informative because the bias and fair models make the same predictions for the [$HTHT$] experiment, meaning the scientist would not learn much about her hypotheses from this experiment.

An applied example comes from @nelson2010experience. They used OED principles to differentiate competing theories of information seeking during adults' category learning. That is, they wrote down an OED model of their category learning task (classifying a set of images into one of two categories), the possible design choices (e.g., what combination of features to show participants), and the relevant behavioral hypotheses (i.e., different theories of category learning). And using the model, they were able to figure out the stimulus set where the competing theories made different predictions. 

A growing body of psychological research has used the OED framework as a metaphor for human active learning. The idea is that when people make decisions about how to act on the world, they are engaging in a similar process of evaluating the "goodness" of these different actions (i.e., experiments) relative to some learning goal, and in turn, select behaviors that maximize the potential for gaining information about the world. One of the major successes of the OED model is that it can be used to account for a wide range of information seeking behaviors, including verbal question asking [@ruggeri2015children], planning interventions in causal learning tasks [@cook2011science], and decisions about where to look during scene understanding [@najemnik2005optimal]. 

@coenen2017asking provide a thorough review of the OED framework and its links to research on the psychology of human information seeking. In their review, they lay out the four critical parts of an OED model: (1) a set of hypotheses, (2) a set of questions (i.e., actions) to learn about the hypotheses, (3) a way to model the types of answers that each question could elicit, and (4) a way to score each of the possible answers with respect to some usefulness metric. In addition to the components internal to the model, they highlight the importance of understanding learners' inquiry goals (e.g., "How does this toy play music?") for engaging in OED-like reasoning. The key point is that without a clear learning goal, then it becomes difficult to instantiate the hypotheses, questions, and answers that a learner should consider when deciding what to do next. In the rest of this section, I provide the mathematical details of the OED approach as described in @coenen2017asking. The goal is to provide structure for the concpetual analysis of how social learning contexts can intervene on different components of the OED model. 

The goal of an OED model is to formalize the reveleant hypotheses, queries, and answers such that the learner can quantify the *expected utility* of different actions she could take. Formally, the set of queries is defined as $Q_1, Q_2,..., Q_n = \{Q\}$. And the expected utility of each query ($EU(Q)$) is a function of two factors: (1) the probability of obtaining a specific answer to a question $P(a)$ weighted by (2) the usefulness of that answer for achieving the learning goal $U(a)$. Thus, the expected utility for a specific question $Q$ is defined as the sum of the utilities for each possible answer to that question weighted by the probability of getting that answer ($P(a)$).

$$EU(Q) = \sum_{a\in q}{P(a)U(a)}$$
\noindent
There are a variety of ways to define the usefulness function to score each answer. An exhaustive review is beyond the scope of this paper, but for a detailed analysis of different approaches to modelling the usefulness of actions with respect to information seeking, see @nelson2005finding. However, one common approach is to use the *information gain* of an answer, which is defined as the change in the learner's overall uncertainty before and after receiving the answer. One way to instanstiate this idea is to compute the change in entropy (i.e., uncertainty) after getting a particular answer.

$$P(h|a) = ent(H) - ent(H|a)$$

\noindent
Where $ent(H)$ can be defined using Shannon entropy ^[Information entropy can be thought of as a measure of unpredictability or the amount of uncertainty in the learner's probability distribution over hypotheses. Intuitively, higher entropy distributions are more uncertain and harder to predict outcomes. For example, if the learner believes that all hypotheses are equally likely, then they are in a state of high uncertainty/entropy. In contrast, if the learner strongly believes in one the hypothses, then her uncertainty/entropy is low.] [@mackay2003information], which provides a measure of the overall amount of uncertainty in the learner's beliefs about the candidate hypotheses. 

$$ent(H) = -\sum_{a\in A}{P(h)log_2P(h)}$$
\noindent
$ent(H|a)$ is computed the same way but takes into account how the learner's belief distribution would change after getting a specific answer.

$$ ent(H|a) = -\sum_{h\in H}{P(h|a)logP(h|a)} $$
\noindent
And the likelihood of a hypothesis $P(h|a)$ can be calculated using Bayes rule. 

$$ P(h|a) = \frac{P(h)P(a|h)}{P(a)} $$ 

\noindent
If all pieces of an OED model are defined (hypotheses, questions, answers, and the usefulness function), then selecting the optimal query is straightforward. All the learner must do is perform the expected utility computation for each query in the set of possible queries and pick the one that maximizes utility. In practice, the learner considers each possible answer, score the answer with the usefulness function, and weight the score using the probability of getting that answer. 

There are several benefits of the OED formalization for understanding human active learning. First, it forces researchers to define the different components of an active learning problem, thus making their assumptions about the phenomenon more explicit. Second, if researchers are able to develop an OED model,  they can ask whether people's behavior deviates from the optimal behavior predicted by the model. Finally, casting information seeking as rational *choice* links psychology with several rich research literatures (economics, statistics, computer science) that have attempted to formalize decision-making as a process of utility analysis that includes the costs and benefits of choosing a particular behavior for information gathering.

Before reviewing the behavioral evidence for OED-like reasoning, it is worth walking through a worked example of how to compute the expected utility  of different questions. The goal is to provide simple calculations that illustrate the full process of reasoning about the probabilities of hypotheses, questions, and answers can lead to selecting the most useful action. This example is borrowed from @nelson2005finding but slightly modified. I also include code blocks that show how you would instantiate these calculations as functions in the R programming language. 
Imagine that the you are a biologist, and in your research, you come aross a new aniimal that you think belongs to one of two species: "glom" or "fizo." You cannot directly query the category identity, but you can gather information about the presence or absence of two features (eats meat and is nocturnal) that you know from prior research are more or less prevalent for the different species. The following probabilities summarise this prior knowledge:

  * $P(eatsMeat \mid glom) = 0.1$  
  * $P(eatsMeat \mid fizo) = 0.9$
  * $P(nocturnal \mid glom) = 0.3$  
  * $P(nocturnal \mid fizo) = 0.5$. 

\noindent  
You also know from your previous research that the prior probability of seeing a glom is $P(glom) = 0.7$ and the prior probability of seeing a fizo is $P(fizo) = 0.3$. 

Based on all of this information, which experiment should you conduct? Intuitively, it seems better to test whether the creature eats meat because an answer to this question provides strong evidence about whether the creature is a fizo since because $P(eatsMeat \mid fizo) = 0.9$. However, the OED computation allows the scientist to go beyond this inuition and compute exactly how much better it is to ask the "eats meat?" question. To do this, all the scientist has to do is pass their knowledge about the hypotheses and the features through the expected utility computation. 

Here is an example of the steps of the OED computation. First, we need to use Bayes rule to calculate how much our beliefs would change if we received a "yes" or a "no" answer. ^[Note that the $P(eatsMeat)$ term is computed by taking $P(eatsMeat) = [P(eatsMeat \mid glom)P(glom)] + [P(eatsMeat \mid fizo)P(fizo)] = (0.1 \times 0.7) + (0.9 \times 0.3) = 0.34$]

$$ P(glom \mid eatsMeat) = \frac{P(eatsMeat \mid glom)P(glom)}{P(eatsMeat)} = \frac{0.1 \times 0.7}{0.34} = 0.21 $$ 

\noindent
Next, we calculate uncertainty over hypotheses before taking any actions by computing the prior entropy.

$$
\begin{aligned}
ent(Species) &= -\sum_{h\in H}{P(h) \times log_2P(h)} \\
 &= [-P(glom) \times log_2P(glom)]+[-P(fizo) \times log_2P(fizo)]\\
 &= [-(0.7 \times log_2(0.7)] + [-(0.3 \times log_2(0.3)]\\
 &= 0.8
\end{aligned}
$$

\noindent
In order to complete our information gain calculation, we need to calculate our uncertainty over hypotheses conditional on seeing each answer, or the posterior entropy. First for the "yes" answer:

$$ 
\begin{aligned}
ent(Species|eatsMeat = yes) &= [0.21 \times log_2(0.21)] + [0.79 \times log_2(0.79)]\\
 &= [0.21 \times log_2(0.21)] + [0.79 \times log_2(0.79)]\\
 &=  0.15
\end{aligned}
$$
\noindent
And for the "no" answer:

$$ 
\begin{aligned}
ent(Species|eatsMeat = no) &= -\sum_{a\in A}{P(Species \mid eatsMeat = no) \times log_2P(species \mid eatsMeat = no)}\\
&= [0.95 \times log_2(0.95)] + [0.04 \times log_2(0.04)]\\
&=  0.62
\end{aligned}
$$
\noindent
Finally, to get the overall information gain of the "eats meat" **question** we weight the utiliies of each answer by it's prior probability:

$$ 
\begin{aligned}
EU(Q = eatsMeat) &= \sum_{a\in A}{P(a)U(a)} \\
&= [P(eatsMeat = yes) \times ent(Species \mid eatsMeat = yes)] + [P(eatsMeat = no) \times ent(Species \mid eatsMeat = no)]\\
&= [0.34 \times 0.15] + [0.66 \times log_2(0.61)]\\
&= 0.43
\end{aligned}
$$
If we perform the same steps to compute the expected utility of the sleeps at night question, we get $EU(Q = sleepsNight) = 0.026$. So if the biologist wants to maximally reduce uncertainty about the species, she should select the "eats meat?" experiment since $EU(Q = eatsMeat) > EU(sleepsNight)$.

### Evidence of OED-like reasoning in human behavior

One nice demonstration of the benefits of an OED approach comes from @nelson2005finding model of eye movements during novel concept learning. The model combines Bayesian probabilistic learning, which represents the learner's current knowledge as a probability distribution over a concept, with an OED model of the usefulness of a particular eye movement (modeled as a type of question-asking behavior) for gathering additional information about the target concept from the visual world. Together, these model components allowed @nelson2005finding to predict changes in the pattern of eye movements at different time points in the learning task. Specifically, they found that early in learning, when the concepts were unfamiliar, the model predicted a wider, less efficient distribution of fixations to all candidate features that could be used to categorize the stimulus. However, after the model learned the target concepts, eye movement patterns shifted, becoming more efficient and focusing on a single stimulus dimension.

Recent developmental work has used OED models to test whether children are capable of selecting efficient behaviors that maximize learning goals. For example, @legare2013use used a modified question asking game where 4- to 6-year-old children saw 16 cards with a drawing of an animal on them. The animals varied along several dimensions, including type, size, and pattern on the animal. The child's task was to ask the experimenter yes-no questions in order to figure out which animal card the experimenter had hidden in a special box. Children's questions were coded as either constraint-seeking (narrowing the set of possible cards by gathering information about a particular dimension (e.g., "Is it red?"), confirmatory (questions that provided redundant information), or ineffective that did not provide any useful information (e.g., "Does it have a tail?"). All children produced a high proportion of the effective, constraint-seeking questions and the number of constraint-seeking questions was correlated with accuracy in guessing the identity of the card hidden in the special box. @legare2013use interpret these results as providing evidence that children can use questions to solve problems in an efficient manner. Converging evidence in support of this interpretation comes from experimental work using this approach finding that children prefer to direct questions to someone who is knowledgeable compared to someone who is inaccurate or ignorant [@mills2011determining; @mills2010preschoolers], 

Although the OED approach has provided a formal account of seemingly unconstrained information seeking behaviors, there are several ways in which it falls short as an explanation of human self-directed learning. @coenen2017asking argue that OED models make several critical assumptions about the learner and the learning task, including (1) the hypotheses/questions/answers under consideration, (2) that people are actually engaging in some kind of expected utility computation in order to maximize the goal of knowledge acquisition, and (3) that the learner has sufficient cognitive capacities to carry out the computations. 

In the next section, I argue that limitations of the OED approach can be productively reconstrued as opportunities for understanding how learning from other people can scaffold active learning. I focus on integrating research and theory on social learning with five key components of the OED model: inquiry goals, hypotheses, questions, answers, and stopping rules. The key insight is that learning from more knowledgeable others provides the building blocks for children to engage in effective self-directed learning.

```{r fig.pos = "tb", out.width="95%",fig.cap = "Schematic of an active word learning context using the decomposition of Optimal Experiment Design. Social input (hearing a novel word) triggers an inquiry goal. Then the learner considers potential hypotheses for candidate word-object links, weighting each hypothesis by its prior probability. In this example, the learner thinks that the new word is less likely to refer to the familiar object BALL. Next, he considers possible queries (actions) and the potential outcomes of those actions. Note that in the word learning context queries must be directed towards a social partner, providing the learner with more possible actions, both verbal (questions) and nonverbal (eye gaze; pointing). If the learner selects the action to maximize expected utility, then he would ask the most informative question, which removes all uncertainty for meaning of 'dax' -- 'What's that called?' If he does select the relatively less informative action of asking about a single object, he might be less likely to ask about the familiar object BALL since there is less information to be gained based on his prior beliefs."}

grid::grid.raster(png::readPNG("../cada_schematic/cada_schematic.002.png"))
```

# Part IV: Active learning within social contexts

Why integrate the social and active learning accounts? First, children do not re-invent knowledge of the world, and while they can learn a tremendous amount from their own behaviors, much of their generalization and abstraction is shaped by input from other people. Moreover, social learning can sometimes be the only way to learn something and sometimes it can be a faster or more efficient route for learning. Finally, children are often surrounded by parents, other knowledgeable adults, and older peers – all of whom may know more about the world than they do, creating contexts where the opportunity for social learning is ubiquitous. 

In addition, there is a body of empirical work showing that active learning can be biased and ineffective in systematic ways. For example, work by @klahr2004equivalence showed that elementary school-aged children were less effective at discovering the principles of well-controlled experiments from their own self-directed learning, but were capable of learning these principles from direct instruction. @markant2014better showed that active exploration provided no benefit over passive input in an abstract category learning task when there was a mismatch between the target concept and adults' prior hypotheses going into the learning task. And @mccormack2016children found that 6-7 year-olds showed no learning benefits when allowed to actively intervene in a causal system compared to observing another person performing the interventions, which the authors suggest might be due to the relative decrease in cognitive demands in the observational learning condition. 

In a comprehensive review of the self-directed learning literature, @gureckis2012self point out that the quality of active exploration is linked to aspects of the learner’s understanding of the task: if the representation is poor, then self-directed learning will be biased and ineffective. @coenen2017asking go a step further and outline the challenges of demonstrating efficient active learning behaviors. Might social learning accounts have something to say in addressing the mixed results and challenges in the self-directed learning literature? 

Here, I propose one solution to the challenge of characterizing children's learning as efficient information seeking guided by OED principles. I take the OED model outlined in @coenen2017asking as a starting point for defining efficient inquiry behavior, and use it to integrate social and active learning accounts. The benefit of this formal framework of self-directed learning is that it makes the different components of active learning explicit and highlights aspects that might be particularly challenging for young learners with limited cognitive resources.  

I propose that we can reconstrue the "limitations" of the OED account as a model of human learning as opportunities for understanding how social contexts (i.e., interactions with more knowledgeable others) can support information seeking. In each section, I highlight the developmental challenge for each component of the OED model and then discuss how features of the social learning context could influence play a role. I also highlight prior work that highlight the potential for social contexts to shape self-directed learning and point to interesting, open questions that are promising areas for future work.

```{r fig.pos = "tb", out.width="95%",fig.cap = "Schematic of active learning within a social context. Each panel shows how social information could influence a different aspect of the active learning process. The panels also correspond to the different sub-sections in Part IV of the text. "}
grid::grid.raster(png::readPNG("../cada_schematic/cada_schematic.003.png"))
```

## Goals

An inquiry goal refers to the underlying motivation for people's information seeking behaviors. Often this is simply defined as a search for the correct hypothesis amongst a set of candidate hypotheses. Intuitively, an inquiry goal is what drives people to learn. Some examples of plausible inquiry goals that span across a variety of learning tasks and developmental research literatures include:

  * Is this person a reliable source of information? (selective learning)
  * What is this speaker referring to? (referential uncertainty)
  * What types of objects are called "daxes"? (category learning)
  * How does this toy work? (causal learning)
  * Where should I look next? (allocation of visual attention)

\noindent
Without an explicit inquiry goal, it becomes difficult for an active learner to compare the quality of different behaviors since the learner cannot evaluate how an action will lead to learning progress. @coenen2017asking illustrate this point by highlighting how researchers often go to great lengths to communicate the specific inquiry goal of an experimental task, saying: 

> "The importance of such goals is made clear by the fact that in experiments designed to evaluate OED principles, participants are usually instructed on the goal of a task and are often incentivized by some monetary reward tied to achieving participants that goal. Similarly, in developmental studies, children are often explicitly asked to answer certain questions, solve a particular problem, or choose between a set of actions." (p. 32-33)

\noindent
Thus, characterizing children's goals during learning becomes critical for evaluating the quality of self-directed learning behaviors. However, this is no easy task since children could be considering a wide range of goals during any moment and there is no guarantee that learning progress should be one of the goals. In fact, one line of theorizing about OED as a model of human inquiry argues that we should only expect to see efficient information seeking behaviors in contexts where there is a clear task and learning goal. For example, when a parent gives their child a new toy with several buttons on it and the child's goal is to figure out how to make it work. In this case, we could ask whether the child approaches the learning task in an efficient way, selecting actions that are most likely to provide useful information about the toy's causal structure.   

In the section on Social learning, I reviewed evidence that children's interactions with more knowledgable others could play a role in triggering inquiry behavior. That is, adults and older peers have the capacity to construct contexts with clear learning goals in order to support children's own information seeking. This connection draws on influential ideas in cognitive development that frame social learning as a form of scaffolding where children are placed in contexts that present something new to be learned but importantly conatin learning goals that are achieveable given children's current capabilties (e.g., Zone of Proximal Development [@vygotsky1987zone], Rogoff's theory of Guided Participation [@rogoff1993guided], and more recently Guided Play [@weisberg2013guided]).

For example, @weisberg2013guided define guided play as an intermediate learning context that falls between totally unstructured free play and constrained direct instruction. The boundaries between these contexts are difficult to define, but the critical dimension is the level of control that the more knowledgable participant exerts over the activity. In free play, the child decides what to do next; whereas in direct instruction, the more knowledgable person explicitly tells the learner what to do, asks questions, or demonstrates new concepts. 

In their review, they present the following example to illustrate the key difference between guided play and direct instruction.

> For example, a teacher with the goal of teaching new vocabulary words could take a direct instruction approach, by telling children the meanings of the new words they encounter in a storybook or by showing examples: "This is a helmet. A helmet goes on your head to stop your head from getting hurt if you fall off your bike." Or, she could take a guided-play approach, introducing the new words in the context of a child's play episode while encouraging children to think broadly about the word's meaning: "She's got a helmet on while riding her bike. What do you think would happen if she fell off her bike and wasn't wearing her helmet?" (p. 106) 

\noindent
While these contexts appear quite similar, the key difference is whether the child initiated the activity. @weisberg2013guided hypothesize that guided play context provides the right combination of structure with the opportuntity for children's to exercise self-efficacy over learning, and leads to better learning outcomes.  

One less-emphasized feature of the Guided Play proposal is the importance of an adult initializing a clear learning goal. In the previous example, if we removed the adult and only provided the child with a storybook to explore, it is unclear what goals the child would pursue when deciding what actions to take. However, the very presence of an adult who has knowledge of the names of objects in the book and has the goal to teach those names to the child changes the potential for the child to engage in informations-seeking behaviors. More formally, we can connect this example to the OED framework of self-directed learning, and it becomes clear that one potentially important role of other people is to present children with a clear learning goal, which in turn sets the stage for children to reason about what actions to take next (e.g., what question to ask or what object to point out) and how those actions might best support the current learning goal (i.e., learning the names of objects in the storybook).  

In addition to communicating inquiry goals, the mere presence of others can affects children's tendency to detect whether they understand something. This capacity for explicitly reasoning about one's own uncertainty is a component of metacognition and has been the focus of a great deal of developmental research (see @lyons2010metacognitive for a review). The upshot of this work is that while children might be capable of showing behaviors that are sensitive to uncertainty (e.g., selectively exploring an object with ambigous causal structure), the ability to have explicit access and use of the underlying representation of uncertainty is slower develop. There are striking experimental demosntrations of children's failure to monitor their own uncertainty. For example, @markman1979realizing had elementary school aged children read paragraphs with inconsistent information (e.g., "fish can't see without light, and there's no light at the bottom of the ocean, but some fish at the bottom of the ocean only know their food by it's color."). After reading the paragraph, children were asked a series of 10 questions that gave them the opportunity to ask for clarification about the inconsistency. Overall, children were not great at the task, as @markman1979realizing put it, "even highly motivated children were unable to detect inconsistencies in the incoming information." However, when children were provided with a warning and "challenged to find a problem" with the essay, they generated more questions about the essay and performed better on the task. 

While not discussed in these terms, @markman1979realizing's "warning" manipulation can be reconstrued as an interevention of the social context on children's expectations. That is, children might approach social interactions with a default expectation about that adults and text written by adults that the information is complete and generated to help them learn. ^[See the work on children's pedagogical sampling assumptions reviewed in Part 1 and the discussion of Answers later in this section for additional evidence that children hold default assumptions about others' helpfulness.] But when the social context shifts these expections, children are more likely to engage uncertainty monitoring, and in turn, more likely to generate inquiry goals. 

Converging evidence comes a study by @kim2016young's where 3- to 4-year-olds' uncertainty monitoring was measured in contexts where they either did not did not have the expectation of communicating with another person. In the task, children were either knowledgable or ignorant about which toys were hidden in a box. In the critical "informing" condition, children asked if they wanted to tell another person about the contents of the box but they were given the opportunity to "opt-out" of responding if they were unsure ("Max wants to know what’s inside the box. Can you help him? If you do not want to tell him, it’s okay. I can tell him."). The "explicit" condition was identical but children were asked to report on their own uncertainty. Intrestingly, children who were asked to inform another person showed higher rates of uncertainty monitoring, opting-out of responding more often when they did not know what was inside the box. These findings dovetail with work showing that generating explanations for other people and for ourselves is a powerful way to reveal inconsistencies in our own knowledge [@lombrozo2006structure].

Another interesting link between social contexts and children's inquiry goals comes from work exploring how children's input shapes implicit theories of intelligence and the goals they choose to pursue [@dweck1988social]. Specifically, implicit theories of intelligence refer to children's internal working models of the world and provide general frameworks for processing information and generating predictions about behavior. @dweck1988social propose a causal model where implicit theories of intelligence cause different goal orientations, which interact with perceptions of present ability to generate different behaviors. For example, if children hold a belief that intelligence is malleable (an incremental theory), they will want to increase competence (select a learning goal) and therefore be more likely to select tasks that support learning (mastery-oriented). 

Empirical work has shown that children can be oriented toward learning goals by an experimenter. For example, @elliott1988goals directly manipulated elementary school-aged children's goals by presenting them with a choice between one of two tasks described in the following ways:

  * *Performance task*. In this box we have problems of different levels. Some are hard, some are easier. If you pick this box, although you won't learn new things, it will really show me what kids can do.
  * *Learning task*. If you pick the task in this box, you'll probably learn a lot of new things. But you'll probably make a bunch of mistakes, get a little confused, maybe feel a little dumb at times — but eventually you'll learn some useful things.

\noindent
@elliott1988goals found that when children were oriented towards the learning goal, they tended to choose the more difficult "learning" task even though they were likely to make mistakes and risk looking incompetent. In another study, @dweck1988social showed that children who already held performance goals viewed effort on a task as an index of ability, whereas children with learning goals view effort as a means for improvement. Morever, both lab-based experiments and observational work provide evidence that the language adults choose to use when praising chidren can shape how likely children are to hold implicit theories that emphasize learning over and above performance goals [@cimpian2007subtle; @gunderson2013parent]. 

Taken together, the research on implicit theories suggests another pathway through which social contexts can trigger inquiry goals. We can recast the @elliott1988goals finding -- that children oriented toward learning goals select harder tasks -- in terms of the OED framwork. That is, the goal manipulation is an instance of the social context initializing an inquiry goal, which in turn influences children's decision making, leading children to select behaviors that result in a higher chance of learning new concepts, an explicit prediction that falls out of the OED model of human inquiry.

Another interesting place where the social context of learning can impact information seeking is by introducing a set of "social" goals that directly impact information seeking behaviors. The basic OED framework only includes the goal of information seeking, meaning that the utility of an outcome is based solely on how answers change probabilities of hypotheses. However, other work has expanded on this basic information-seeking account to include *situation-specific utility functions* that allow for other goals such as saving time, money, or cognitive resources. For example, @meder2012information designed a series of experiments where "pure" information seeking goals (e.g., maximizing accuracy) were placed at odds with the reward structure of the task. To accomplish this, they used assymetric rewards for correct and incorrect categorization decisions in a binary classification task. Asymmetric rewards leads to a scenario where the learner must choose the less likely category in order to earn the highest reward (i.e., they must be willing to forego the goal of being accurate and make mistakes). When task-specific rewards were put in conflict with accuracy, participants' behavior was mixed -- only when the asymmetric reward structure was made explicit via language did participants seek inforation about the higher reward, but lower information gain feature. @meder2012information speculate that participants were not only considering information gain or pure reward maximization goals and take the results as evidence for the need to consider additional components in the utility function. 

One powerful feature of adding a social partner to a learning context is that it can engage a process of psychological reasoning about their mental life (e.g., beliefs and goals). Once the learner starts reasoning about the other person, they could start to consider an additional set of "social" goals that may conflict or support their information seeking goals. For example, if Scott is worried about whether his teacher thinks he is smart, then he might prioritize actions that maximize the probability of success in order to demonstrate his intelligence, perhaps at the expense of choosing actions that maximize his inquiry goal of learning how to make the toy play music.

Recent work by @yoonwon has modeled polite speech (e.g., people using indirect language: "I don’t think that
dress looks phenomenal on you" as opposed to "It looks terrible") as a process of trading off between information and social goals. Specifically, speakers reason about their actions with respect to the information goal -- communicate information faithfully and with as little effor as possible -- and a social goal -- avoid damage to your own or another person's self-image. To formalize this intuition, @yoonwon build on the Rational Speech Act framework for pragmatic reasoning [@goodman2016pragmatic], which models language comprehension and production as, "... a process of recursive reasoning about what speakers would have said, given a set of communicative goals" (p.819). The polite RSA model connects with the OED information seeking model in that both assume that people will produce an action (in RSA an utterance and in OED a query) to maximize utility, but the polite RSA expands the speaker's utility function, modeling overall utility of an utterance as a weighted combination of social and informational utility. 

It would be interesting to modify utility-theoretic approach used by @yoonwon to children's information seeking behaviors in social contexts. We can also connect these ideas to the effects of task framing (peformance vs. learning oriented) on children's decisions to try harder tasks. It could be that the presence of another person increases the weight children place on maximizing social utility, leading children to select easier tasks where they can appear competent. This is a subtle but interesting extension of the goal-orienting account reviewed above in that it frames these effects as a mixture of goals as opposed to the social context triggering either an performance or a learning goal.

One important gap in the literature on inquiry goals is a good estimate of how often children participate in contexts with clear learning goals in their daily lives, as opposed to contexts where learning goals are absent or contexts where children are clearly pursuing other non-learning related goals (e.g., some example here). Moreover, there is a need for more research on the kinds of events that lead children to generate inquiry goals. However, @rogoff1993guided's work on *Guided participation* provides an interesting counter-example where they coded the rate of "caregiver orienting" behaviors in parent-child interactions with their 12- to 24-month-old infants across four different cultural communities (a Mayan Indian town in Guatemala, a middle-class urban group in the United States, a tribal village in India, and a middle-class urban neighborhood in Turkey) that varied along the dimensions of how separated children were from adult activities and whether formal schooling was emphasized. Specifically, caregiver orienting was defined as doing the following behavior during parent-child interaction around a set of novel toys,

> Caregiver orients child involved introducing new information or structure to the child (at any point in the episode) regarding the overall goals or a key part of the event or what was expected in the situation. Orienting framed a major goal, not just specific little directives for particular actions. 

\noindent
@rogoff1993guided found that parents in all four communities produced high rates of structuring and orienting behaviors (with the lowest rate of structuring being 81% of play episodes). Thus, when placed in a structured activity, adults make sure children are aware of the goal (e.g., learning the function of the novel toy). However, the communities differed in how often children were directly involved with adult activities in day-to-day life, with the children raised in rural villages often having early acces to  adult economic and social activities. An interesting open question is whether older peers and adults need to be directly engaging with the child in order to trigger inquiry goals and efficient self-directed learning behaviors. Perhaps increased access to observing lots of adult goal-directed behaviors can faciliate children to generate leanring goals, for example as they see activies being completed that they do not understand. 

One important direction for future research to map the space of children's goals during everyday learning contexts. It would be interesting to know the proportion of children's daily activities that involve contexts where there is a clear learning goal either being demonstrated by the child or by older peers and adults. It would also be useful to know how the distribution of these tasks changes as a fnction of development, especially as children enter school and across different cultural contexts where children have differential access to structured (e.g., lessons and sports) vs. unstructured activies (e.g., free play). 

## Hypotheses

After establishing that there is something to be learned, the next key component of inquiry is deciding what hypotheses should be considered and tested. Intuitively, a hypothesis is a candidate explanation about how the world works. For example, if a child is in a concrete word learning context -- i.e., she hears a new word ("dax") and is surrounded by a three unfamiliar objects (A, B, and C) -- then she might entertain at least ^[This hypothesis space only considers the possibility of one-to-one word-object mappings.] the following hypotheses about the meaning of dax: dax = A, dax = B, or dax = C. 

The set of hypotheses under consideration is critical for measuring effective self-directed learning. The usefulness function outlined in Part II works by comparing the learner's uncertainty over hypotheses before and after the she performs some action on the world. Without knowing what is in the hypothesis space, it becomes challenging to figure out the best action for reducing uncertainty. Put another way, the OED framework does not easily deal with situations where learners might have to consider a large space of hypotheses, might actually hold the wrong hypotheses, or perform actions without considering any hypotheses at all. This scenarios seem plausible for young learners and thus present a challenge to using OED principles as a model of early active leanring. 

However, one important functions of social learning contexts is to provide a clear set of possible explanations for the true state of the world. That is, adults and older peers, who might have access to the correct hypothesis, can restrict the hypothesis space in order to help guide children information seeking behaviors. The effect of social contexts on hypotheses parallels the effect on goals reviewed in the previous section: that the behaviors of other people have the capacity to initialize and constrain. 

One relevant case study of the capacity for social contexts to constrain hypotheses comes from work on children's early word learning. The challenge for the young word learner is that even the simplest of words, concrete nouns, are often used in complex contexts with multiple possible referents, which in turn have many conceptually natural properties that a speaker could talk about. This creates the potential for an (in principle) unlimited amount of hypotheses that children could consider for the meaning a novel word. Remarkably, word learning proceeds despite this massive uncertainty, with estimates of adult vocabularies ranging between 50,000 to 100,000 distinct words [@bloom2002children]. 

It does not seem plausible for children to entertain all hypotheses about possible word-object links. But how might children constrain the hypotheses that they consider? One proposed solution is for word learners to only consider a single word-object hypothesis at a time [@trueswell2013propose; @medina2011words]. That is, the child could make an initial guess about the meaning of a new word, and then only consider that guess until she receives sufficient evidence that her initial hypothesis was incorrect. If she seees sufficient counter-evidence, then she will switch to a new hypothesis that better matches the statistics in the input. ^[This "propose-but-verify" account parallels work by @bonawitz2014win in the domain of causal learning, which suggests that a "Win-Stay, Lose-Sample" algorithm (inspired by efficient sampling procedures in computer science) provides a better explanation of children's hypothesis testing behaviors compared to an algorithm that enumerates the entire hypothesis space.] Another influential account of early word learning, inspired by basic associative learning principles, argues that children store more than a single hypothesis, suggesting that the hypothesis space is gradually reduced via the aggregation of word-object labels across multiple labeling events [@siskind1996computational; @yu2012modeling]. Support for this experimental work has shown that both adults and young infants can use word-object co-occurrence statistics to learn word meaning from individually ambiguous naming events [@smith2008infants]. Moreover, adults show evidence of being able to recall multiple word-object links from an initial naming event [@yurovsky2014algorithmic]. 

The key difference between these proposals is how much information learners store in their hypothesis space. Understading the nature of the hypotheses that learners consider is critical for evaluating children's ability to seek information with respect to those hypotheses. Some of our own work provides evidence that the social context can modulate the content of the learner's hypothesis space [@macdonald2017social]. Inspired by ideas from Social-pragmatic theories of language acquisition that emphasize the importance of social cues for word learning [@clark2009first; @hollich2000breaking; @bloom2002children], we showed adults a series of word learning contexts that varied in ambiguity depending on whether there was a useful social cue to reference (i.e., a gaze cue). We then measured learners' memory for alternative word-object links at different levels of attention and memory demands. Results showed that learners flexibly responded to the amount of ambiguity in the input, and as uncertainty increased, learners tended to store more word-object links. Morever, we found that learners stored representations with different levels of fidelity as a function of the reliability of the social cue and despite having the same amount of time to visually explore the objects during the initial labeling event. 

These results suggest that the content of learners' hypothesis spaces changed as a function of the quality of the social learning context. Further suppport for this idea comes from experimental work showing that even children as young as 16 months prefer to map novel words to objects that are the target of a speaker’s gaze and not their own [@baldwin1993infants], and analyses of naturalistic parent-child labeling events shows that young learners tended to retain labels that were accompanied by clear referential cues, which served to make a single object dominant in the visual field [@yu2012embodied]. One important direction for future research is to measure the full causal pathway from variation in social learning contexts to the nature of children's hypothesis spaces and their information seeking behaviors. For example, it would be interesting to know whether learners' subsequent information seeking behaviors would be affected by social context manipulations like the ones used in our task. 

A second case study that illustrates the importance of considering young learner's hypothesis spaces comes from work by @lucas2014children where they compared chidren and adult's capacity for learning different kinds of causal structures. In the task, participants were shown a series of events that consisted of a training phase where an experimenter placed objects on a box that either did not did not play music. The participant's goal was to learn which objects, or combination of objects, made the box work. In the disjunctive condition, only single objects (A or C, but not A) made the toy play music. In the conjunctive condition, only the combination of two different objects (A and C) would make the toy play music. After seeing several demonstrations, both children and adults were tested on ambiguous events where they could either infer a disjunctive or conjunctive causal relationship. @lucas2014children found that only children showed evidence of learning the conjunctive relationship, even if the evidence favored this interpretation. The authors speculate that children have less of a bias towards preferring the disjunctive relationship, which is more common in everyday experience, and are thus better able to learn from new evidence. 

Why might these findings matter for active learning? A key prediction of the OED account is that learners will select behaviors that maximally reduce uncertainty in their beliefs, which is often formalized as the difference in entropy between the prior and posterior probability distributions over hypotheses (i.e., $P(h|a) = ent(H) - ent(H|a)$). Thus, the content of the hypothesis space and the uncertainty over each hypothesis plays a direct role in evaluating the relative usefulness of different information seeking behaviors. Moreover, the social context could play a role in setting up the hypothesis space. For example, @lucas2014children suggest that, 

> Most of the time, adults do not need to dramatically change their beliefs or abandon their hypotheses for dramatically different ones. Indeed, doing so would be a liability: adults are expected to make accurate predictions and good decisions, not bold inductive leaps. Adults are also unlikely to have caregivers to correct their errors and save them from poor choices.

\noindent
This makes an interesting, testable prediction that contexts in which learners "feel" safe to make mistakes would lead children to consider and test a broader range of hypotheses. Moreover, another effect of the social context is highlighted in @lucas2014children's study: that the experimenters went to great lengths to ensure that children and adults would only consider the disjunctive and conjunctive hypotheses. That is, they constrained the hypothesis space to isolate learning and information seeking effects. It is an interesting and open question as to how often this type of process occurs in everyday learning contexts.  

A final case study demonstrating the link between social input and children's hypotheses comes from research on conceptual change during early childhood [@gelman2009learning]. Conceptual change refers to a "radical" reconstruction of an intuitive theory about how the world works based on some intervening factor. For example, elementary school-aged children tend to hold a mixture of beliefs about the shape of the earth [@vosniadou1992mental]. These theories range from flat earth theories that match children's everyday perceptual experiences (i.e., walking on flat ground) to the adult-like, sphere model, which must have been learned via social input. Intrestingly, children also show evidence of holding interemtidate beliefs such as a dual-earth theory where there are two earths, "a round one which is up in the sky and a flat one where people live" (p. 550). The fact that children entertain something like the dual-earth theory suggests that they are actively trying to integrate their initial theory with information they get from interactions with people who already have the correct, sphere theory. 

There is also strong experimental evidence for the importance of social input in children's theory revision. For example, in the domain of biological reasoning, the concept of "alive" takes years to fully develop, with younger children (under 10 years of age) often claiming that only animals, and not plants, are alive. @opfer2004revisiting tested the hypothesis that evidence of goal-directed movement is critical for children's extension of the "alive" concept. In their study, 5-year-olds' were trained on different ways to think about the concept of a "living thing" and then asked whether they believed that plants were alive. Children either learned that plants were capable of goal-directed movement (e.g., "The house plant is growing this way. It needs the sunlight over here."), that plants were capable of growth, or that plants need water to survive. Children in the goal-directed movement condition showed the strongest evidence theory revision, saying plants were also living things more consistently on a post-intervention categorization task. 

Additional evidence comes from research on the links between language experience and performance on various cognitive tasks. For example, empirical work has shown that deaf children without access to a natural language perform worse on Theory of Mind tasks [@peterson2000insights], that Korean speakers perform better than English speakers on tasks that require categorizing based on tight vs. loose distinctions, which are lexicalized in Korean [@mcdonough2003understanding], and that exposure to a first language reduces infants' capacity to detect non-native phonetic contrasts [@maurer2014perceptual]. 

Taken together, the findings reviewed in this section illustate several important points for the active-social learning acount. First, the set of hypotheses that children consider are likely to be quite different from adults (and different from what the experimenter thinks the child is considering). Second, children generate hypotheses using a mix of prior knowledge, expectations about the current task, and social input. Critical to this point is that there are (at least) two timescales through which social learning can shape hypotheses. (1) An in-the-moment timescale where other people's behavior can constrain the hypotheses that children consider for the current task -- for example, referential gaze indicating candidate word-object mappings, or an adult suggesting a disjunctive (one-block) vs. a cojunctive (two-block) theory for how to make a toy work. (2) A developmental timescale where prior interactions with other people and cultural learning modifies the hypotheses that children bring to a particular learning task (e.g., the conceptual change and language effects reviewed above). ^[We could make a further distinction between the developmental and the cultural timescales, where developmental refers to information acquired from interactions with others in the child's lifetime (e.g., disjunctive causal structures are more likely to occur in the world) and cultural refers to information that has accumulated throughout human evoluationary history (e.g., access to natural language or concepts such as the spherecial earth.)] 

## Questions

Questions in the OED framework refer to the experiments that a scientist can conduct in order to gather information with respect to their hypotheses about the world. When we consider "questions" in human informaion seeking, it's important to note that "questions" can map onto a range of information seeking behaviors, such as verbal questions, pushing a button to figure out how a toy works, and decisions about where to look. In fact, the capacity to provide general principles to explain such a broad range of behaviors is one of the strengths of the OED account as a model of human active learning.

The challenge for the young learner is to discover what behaviors are available and of those behaviors which might be particularly good for gathering information to support learning. In this section, I illustrate how the social learning context provides the input to this learning process via demonstrations of the range of actions that learners could take and by adults' modeling effective information seeking behaviors.  

It seems obvious that children would look to older peers or adults to learn what actions are possible and useful. However, a large body of empirical work suggests that even young infants will not imitate every action that they see. Instead, children show evidence of "rational imitation" and look for cues about other people's goal-directed behaviors and use this information to determine what behaviors are worth imitating . For example, @gergely2002developmental measured how often 14-month-old infants imitated an adult's inefficient action -- turning on a light with her head (less efficient) instead of her hands (more efficient) -- as a function of whether there was a relevant explanation for selecting the less efficient action (whether the adult's hands were occupied). They found a large difference in imitation rates across conditions (69% in the hands-free vs. 21% in the hands-occupied), suggesting that children recognized the reason for the inefficient action and chose to ignore the means and focus on the goal of turning on the light in the most efficient way possible.

The high rates of imitation in the hands-free condition highlight another important compoenent of learning from others' actions: that children tend to overimitate behaviors even when these actions are not directly relevant to the task. For example, @call2005copying compared imitation behaviors of 2-year-old children after they watched someone demonstrate how to open a tube using only the necessary actions or using the actions and a style component that was unrelated to opening the tube (e.g., removing the tube's cap with an exaggerated twisting motion). Children imitated the causally irrelevant action at a high rate (93% of children), providing evidence that they were focused on reproducing each of the experimenter's actions and not just reproducing the outcome of opening the tube.  

Other empirical work provides insight into the importance of considering the social factors that influence whether children choose to imitate. @carpenter1998fourteen showed that 14- and 18-month-olds were less likely to imitate adults' action if the action was accompanied by a verbal cue that flagged the action as a mistake (e.g., "Whoops!"). @buchsbaum2011children provide evidence that the children are more likely to overimitate when the adult is described as a "knowledgeable" teacher as oppossed to "naive." And @carpenter2002understanding showed that giving children explicit information about another person's goals prior to a causal demonstration leads to an increase in imitation and learning of the correct casual structure. 

Taken together, the work on children's learning via imitiation and their tendency to overimitate suggests that inferences about others' intentions plays a critical role in the actions that children will use in their own behaviors. For the purpose of this paper, this work provides a way forward for understanding the origin of the information seeking behaviors that might be available to children, i.e., what are the available actions that a learner could take to gather information. 

One domain where progress has been made in understanding how social contexts directly shape children's information seeking capacities is verbal question asking. Consider that in order to ask a useful question in natural language, children must possess the requisite language skills, which are learned from their language input. Both experimental work and corpus analyses provide evidence that children's question-asking becomes more varied and effective over the first years of life (e.g., see @chouinard2007children and @legare2013use reviewed in Part II). Moreover, children improve in the timing of their turn-taking during question-answer exchanges, reducing the length of gaps between turns [@casillas2014turn]. Interestingly, @casillas2014turn also found that adults appeared to be sensitive to children's developing question-answering skills by asking more difficult questions (i.e., questions that required more complex answers) as children to older children and by modifying questions that appeared to confuse children (e.g., "Who is this? What’s he called? Who is he? What is his name?"). It is interesting to consider how children might internalize these modifications as part of their own question asking behaviors. 

The majority of the work on children's question asking has focused on aspects of the child's behavior, exploring how the type, content, and effectiveness of questions changes as children develop. However, several studies have measured aspects of caregivers question asking. For example, @yu2017peagogical coded parent-child interactions from the CHILDES database to measure the amount of "pedagogical" questions in children's input. They differentiate "information seeking" questions from "pedagogical" questions, by coding whether the adult already knew the answer (e.g., "What’s that called?""; "What does this button do?" vs. "What did you do at school?"), and interpreted the goal of the pedagogical questions as helping the child learn. Results showed that approximately 30% of parents' questions were pedagogical, 60% were information seeking, and 10% were rhetorical (i.e., not intended to be answered verbally). Parents also directed a smaller proportion of pedagogical questions to older children. 

More experimental work linking adults' question-asking practices to children's behaviors is needed. This is especially interesing since observational studies have found that that parents' use of wh-questions predicts children's later vocabulary and verbal reasoning outcomes [@rowe2017going] and children of parents who were trained to ask "good" questions during bookreading episodes at home also asked better questions during bookreading sessions at school [@birbili2009helping]. One explanation for these associations is that wh-questions challenge children to produce more complex verbal responses that in turn builds verbal abilities. However, another interesting possibilty is that the frequency and type of questions that parents ask serve as models that could shape children's information seeking abilities by providing templates for useful behaviors.

Generating a set of questions represents the first step in efficient information seeking. Next, children have to evaluate the relative "goodness" (i.e., utility) of different behaviors. But how do children learn the features of a good question? One solution is for children to observe other people's question asking behaviors, recognize which questions are useful, and leverage their imitation skills to model those behaviors.  

In fact, there is evidence from work with adults that shows a large difference between people's question-generating (harder) and question-evaluation (easier) skills. For example, @rothe2015asking asked a group of adults to play a modified version of the game "Battleship" where they had to find the location of three ships that considted of 2-4 tiles and could oriented in either the vertical or horizontal direction on a 6x6 grid. Participants gathering information sequentially by uncovering one tile at a time. At different points in the task, the game would stop and participants were given the opportunity to ask any question using natural language. @rothe2015asking used a formal model of the expected information gain of each question (i.e., the expected reduction in uncertainty after getting the answer) to evaluate the quality of adults' free-form questions. Results showed that people rarely produced high information value questions. However, in a follow-up experiment @rothe2015asking had a different group of adults play the same game, but this time they provided the list of questions generated by participantsin the free-form version, and in this contexts, adults were quite good at selecting high information value questions.   

Developmental work provides evidence of the same generation-recognition asymmetry. First, experimental work has shown that children younger than the age of three have difficulty generating appropriate verbal questions compared to their older peers in "Twenty Questions" task designed to measure question-asking skill [@mills2011determining; @mills2010preschoolers]. However, when @mills2012little tested 3- to 5-year-old's capacity to learn from observing third-party question-answer exchanges. They found that even the youngest children were capable of using information elicited by others' yes/no questions to identify the contents of a box. Interestingly, children differentiated the usefulness of others' question-answer exchanges, paying more attention to them as compared to exchanges of irrelevant information. 

These results suggest that even at an age where generating questions "from scratch" might be difficult, children can observe and learn from questions that occur in their social environment. @mills2011determining also explored this phenomenon by directly manipulating whether children were exposed to a training phase where adults modeled effective questions prior to playing the question asking game. They found that even though children were not successful at constructing good questions on their own, they were able to ask effective questions at much higher rate following explicit modeling.
  
Work with elementary-school-aged children in the domain of scientific inquiry also shows that generating a good question is a challenging aspect of inquiry skills. One particular relevant example come from @kuhn2008needs's 3-year intervention study that compared children who were directly trained on inquiry skills (e.g., understanding the objectives of inquiry and identifying questions) to a group of slightly older students who had not participated in the training. Children in the training group showed progress in the skills, but children in the comparison group failed to develop these skills in the absence of the particular kinds of input. Summarizing one of the key results, 

> Consistent with the findings of Kuhn and Dean (2005), identifying a question appears to play a key role in making the rest of the inquiry cycle productive. In the probabilistic version of Ocean Voyage in year 2, for example, students floundered until they were helped to formulate a specific research question. Like other components of the inquiry process, this skill is not one a student learns once and has mastered.

\noindent
A final example of how social contexts change the set of possible questions is the very fact of having other people around adds a social "target" for information seeking behaviors. This differs from the effects of social context discussed until this point where in those examples the social input shaped subsequent information seeking behaviors. Intuitively, if a child is trying to learn how a toy works, they could try actions to test the system directly (i.e., seek information directly from the world). But if another person is present, then they can choose to ask questions or seek help via noverbal means (i.e., seek information directly from other agents). Thus, the mere presence of another person modifies the queries that are available to the learner.  

Recent empirical work has begun to explore the factors that affect children's decisions about whether to seek information from the world or from other people. For example, @fitneva2013development had 4- to 6-year-old children decide how toto learn about a novel social category: "moozles." The concept was either visible (e.g., the color of hair) or invisible (e.g., an internal preference). Children were given a choice of looking directly at the moozle or asking a moozle expert. Six-year-olds were more likely to select the "look" option for a visible property and to select the "ask" option for an invisible property. Four-year-olds behavior was a bit noisier but also showed a preference for the correct information gathering behavior with some additional scaffolding from the experimenter. These results provide preliminary evidence that children have some meta-understanding of the kinds of information that is particulary good to learn from social partners. Additional evidence comes from work by @lockhart2016could where they demonstrated that 5- to 11-year-old children are able to articulate the kinds of information that a person could learn growing up on their own (e.g., that the sky is blue) compared to the kinds of information that require other people (e.g., that the earth is round). 

It is important to note out that the items in this study did not test children's appreciation for more indirect forms of social learning: that is, in order to learn that the sky is blue relies on having a conventional language system for referring to concepts. @gelman2009learning refers to this as a "a hidden level of cultural input" (p. 2). The key point is that even in learning contexts that appear entirely self-directed, children's decision making processes have already been shaped by massive amounts of prior experience with other people. With that said, this evidence suggests that children are relatively skilled at deciding when to direct their information seeking behaviors towards social partners.  

Other relevant examples comes from work on children's help-seeking behaviors. @vredenburgh2016young had children build toys that required multiple steps, and on each each step children were given the opportunity to ask for help from the experimenter. Each step varied in difficulty and children naturally varied in their toy building skill. Children asked for help when the step was harder, and less competent children asked for help more often, suggesting that preschoolers sought help in a systematic way -- when they needed it and not when they didn't. Moreover, work by @gweon201116 found that 16-month-old infants are selective in help-seeking, turning to a social target to seek information or acting directly on the world depending on which information source ws more likely to help them reach their current goal. In this case, the infants' goal was to make a malfunctioning toy produce music and the critical manipulation was whether children saw evidence that explained the likely cause of failure being the toy versus their capacity for making the toy play music. When the toy was likely to be broken, they reached for a new object (queried the world), but in contrast, when the evidence suggested that the child was the issue, then they sought help from a nearby adult. 

Some of our own work has explored how the presence of another person changes the set of information seeking behviors available to the learner [@macdonald2017info]. Specifically, we proposed an information seeking account of eye movements in grounded spoken and signed language comprehension: that fixations to a speaker can provide valuable information with respect to the goal of rapid language understanding. We tested our information-seeking account using three case studies that manipulated the value of different fixation behaviors in the visual world: (1) a comparison of processing a visual-manual vs. a spoken language in children, (2) a comparison of processing printed text vs. spoken language in adults, and (3) a comparison of processing degraded vs. clear speech. We found that, compared to English-learners, young signers delayed their gaze shifts away from a language source, were more accurate with these shifts, and produced a smaller proportion of nonlanguage-driven shifts. These results suggest that the signers were sensitive to the higher value of seeking visual information from the signer.English-speaking adults produced fewer nonlanguage-driven shifts when processing printed text compared to spoken language. And English-speaking children and adults allocated more fixations to a speaker and achieved higher language recognition accuracy when processing degraded speech. Together, these data provide a compelling evidence that listeners adapt to the value of seeking visual information from social targets in order to increase the chance of rapid and accurate language understanding.

In sum, the set of questions that children consider provide the tools in their information seeking toolkit. However, we need more research to understand how children generate possible questions. One possible explanation explored in this section is that children might use their powerful imitiative learning skills to model the question-asking behaviors demonstrated by more knowlegable others present in their. Moreover, social contexts fundamentally change the set of behaviors that are available to the developing learner by providing a social target for information seeking behaviors. 

## Answers

Answers in the OED framework refer to the information that learners receive after asking a question. There are two components that influence the "value" of a answer. The probability of getting that answer given a specific question and the utility of the answer -- that is, how much does that answer reduce uncertainty over the learner's current hypotheses. The challenge for young learners can be separated into three parts: (1) figure out what which answers are likely to be good or useful, (2) estimate how likely good answers will be given the current learning context, and (3) decide how much beliefs should update after getting an answer. The social context plays a role in each of these components of answers and is the focus of the current section.

Defining the specific features of a "good" answer is challenging. Intuitively, a good answer provides the learner with information that they did not already know, they were interested in learning, and that is likely to be useful beyond the current context (i.e., generalize). Even within the formal OED framework there have been a variety of ways to write down utility functions (e.g., information gain, probaility gain, and Kullback-Leibler divergence) to compute the value of an answer (see @nelson2005finding). All of these information-theoretic utility functions take into account the learner's prior beliefs represented as probability distributions over hypotheses and try to calculate the impact of an answer on the shape and location of the learners beliefs represented as posterior probability distributions. 

Several theories of social learning discussed in Part 1 argue that a key function of social learning is to provide some guarantee about the utility of answers. For example, evolutionary models of cultural learning argue that the human capacity for efficiently transferring knowledge between individuals allows for the gradual accumulation of small improvements that eventually lead to complex tools, beliefs, and practices that would be difficult, if not impossible, for any individual to discover on their own [@boyd2011cultural; @kline2015learn]. An example from @boyd2011cultural illlustrating this point,

> For example, a rare chance observation might allow a hunter to associate a particular spoor with a wounded polar bear, or to link the color and texture of ice with its stability on windy days just after a thaw. Such rare cues allow accurate low-cost inferences about the environment. However, most individuals will not observe these cues, and thus making the same inference will be much more difficult for them. Organisms that cannot imitate must rely on individual learning, even when it is difficult and error prone. They are stuck with whatever information that nature offers. (p. 10921)

\noindent
The key idea is that there is good reason to think that human evolutionary fitness was enhanced by communicating useful and difficult to acquire information to subsequent generations. Thus, drawing on evolutionary theory, there is an a priori reason to expect that information acquired from other people will be useful. 

This concept is critical to @csibra2009natural theory of "Natural Pedagogy" discussed in Part 1. They argue that an assumption of *generalizability* is a fundamental component of adults' communication to children. Under their account, adults tend to communicate generic information, they provide ostensive cues to signal that upcoming information is generalizable, and children show sensitivity to these cues, treating information differently when they are present. Evidence for this bias towards generalizability comes from a set of empirical studies showing that infants will generalize more often when they learning some information accompanied by ostenstive communicative cues such as eye gaze or child-directed speech. For example, infants are more likely to generalize the positive vs. negative valence associated with an object to other people if the valence was demonstrated with cues to teaching [@gergely2007pedagogy]. And infants are more likely to encode the stable features of object, as opposed the location in space, if their attention was directed to the object via a communicative signal such as a pointing gesture [@yoon2008communication].

Even if the learner is in a social context where the default assumption might be that information is useful and generalizable, not all answers are created equal. Thus, a challenge for selecting information seeking behaviors is to evaluate possible answers and figure out how much a particular piece of information should update beliefs. This is perhaps one of the more-developed areas of research in terms of connecting features of the social context to self-directed learning. Specifically, researchers have made progress in modeling the influence of different assumptions that a learner could about the generative process of answers on the strength of learners' belief change.

For example, @shafto2012learning lay out a continuum of different assumptions that a learner could make about the process that generated an answer:

  * *Weak sampling*: answers are selected at random from the set of all possible answers: independent of target hypothesis.
  * *Strong sampling*: answers are generated at random from the set of answers that are true of the hypothesis: linked to target hypothesis.
  * *Pedagogical sampling*: answers are generated that will maximize the learner’s belief in the correct hypothesis: both linked to target hypothesis and consider alternative hypotheses.
  
\noindent
Critically, if the learner assumes strong or pedagogical sampling, then they are able to make stronger inferences that speed learning. For example, if we see someone press two buttons to activate a device, we are more likely to think that both buttons were necessary if that person knew how the device worked and wanted to communicate to us how it worked. Otherwise, if one of the buttons would have been sufficient, then it would not make sense for them to perform the more inefficient action of pressing both buttons. 

Empirical support for the pedagogical sampling account comes from a range of domains/tasks, including word learning [@frank2009using], pragmatic inference [@frank2012predicting], and causal reasoning [@bonawitz2011double] (see the section on inferences and generalization in social learning Part I). We can also revisit these findings and connect them directly to specific components of the OED model of human inquiry. Consider @xu2007sampling finding: that learners are "sensitive" to the sampling process that generated the examples and when there was good reason to think that the examples were linked to the word meaning, i.e., because they were selected by a knowledgable teacher, then it would be surprising to have seen three examples drawn from the smaller subordinate category. Formally, sensitivity to sampling assumptions was modeled as taking different forms of the likelihood function in a Bayesian cognitive model: $p(x_i \mid m) \propto p(l_i \mid o_i, m)$. Intuitively, this can be thought of as the probability of seeing a particular label ($l_i$) given a specific object ($o_i$) and word meaning ($m$). In this case, the likelihood function for the teacher-driven condition was designed to capture the idea that learners prefer "smaller" or more restrictive hypotheses if they are confident that the data were generated from the true word meaning.

This formalization provies a direct connection with the OED model of human inquiry. Specifically, when a learner is simulating the possible answers that she could receive, she considers how much each answer will update her beliefs. This reasoning process is modeled by computing the difference between the learner's prior and posterior uncertainty (i.e., entropy): $P(h|a) = ent(H) - ent(H|a)$. The learners' sampling assumptions naturally enter the information seeking calculus through the posterior entropy term $ent(H|a) = -\sum_{h\in H}{P(h|a)logP(h|a)}$. Intuitively, this part of the model captures the idea that not all answers are equally useful, and answers that are linked to the correct hypothesis and generated for you are more likely to be informative and should lead to a stronger change in beliefs.

The approach of building more sophisticated likelihood functions has also been used to capture another challenge for evaluating the utility of an answer: that some people are more reliable sources than others. That is, when we learning from the testimony of other people, there is always a possibility that this information could be be inaccurate or even misleading. This might be especially important for young learners who acquire much of their information via interactions with others. However, a growing body of evidence suggests that even very young infants are capable of *selective* learning, rejecting answers that conflict with their own knowledge [@pea1982origins] and seeking information from people who tend to provide good answers [@koenig2004trust]. 

For example, empirical work shows that preschoolers track and integrate a speaker's prior instances of accuracy to figure out if they are trustworthy and will use this information to guide subsequent learning from that speaker’s future claims [@koenig2004trust]. In these studies, children evaluate a speaker’s current testimony after the speaker establishes a record of reliability or unreliability by labeling or mislabeling familiar objects. Across these studies, preschoolers are consistently less likely to direct questions towards and learn from a previously unreliable person. Moreover, @chow2008see found that 14-month-olds are less likely to follow the gaze of a person who had been unreliable in the past, i.e., someone who had consistently directed gaze towards an empty location in space. Finally, children's selective learning appears sensitive to external cues, preferring to learn familiar over unfamiliar teachers [@corriveau2009choosing], adults over peers [@rakoczy2010bigger], and ingroup over outgroup members [@macdonald2013my].

Converging evidence comes from @gweon2014sins work on children's exploration behavior after seeing pedagogical demonstrations of varying quality. In this study, children played with toys that either had one of four functions (e.g., spinning globe or flashing light) until they independently discovered the correct number of functions. Then, depending on condition assignment, they saw a puppet teach one or four of the novel functions to another puppet. Finally, the puppet teacher introduced a new toy to the participant and demonstrated a single novel function. Critically, when the puppet teacher had left out information in the previous teaching episode (only demonstrating one out of four novel functions), children spent more time exploring the object functions that the teacher did not demonstrate. That is, when the teacher was under-informative, children did not make the strong inference that there were no other functions to discover. 

The key insight from the selective learning literature is that children are not entirely incredulous when they encounter information. Instead, the evidence suggests that they actively reason about the expertise that another person brings to the learning context and will choose to ignore information that they deem unreliable. Intrestingly, common outcome measures in studies of selective learning are children's informationg-gathering decisions, e.g., whom to direct questions towards and how many actions to take on an object. These behaviors maps directly onto the choices that the OED model of human inquiry is trying to explain and suggests that children consider the expected usefulness of others' answers deciding to gather information. 

Similar to the pedagogical reasoning effects, the selective learning phenomena have also been modeled using modifications to the likelihood function in a Bayesian cognitive model. Again, this maps onto a hypothesis about the assumptions that learners make about how answers are generated. For example, @shafto2012epistemic propose that selective learning in these object labeling scenarios can be explained as children reasoning about both the helpfulness and knowledgability of speakers when they produce a given label, $l$. Here the child's goal is to select a speaker that increases the chance that they get good information that matches the true state of the world ($label=correct$). Formally, they specify this likelihood function as: 

$$P(l \mid s,k,h) = \sum_b P(l \mid b,h)P(b \mid k,s)$$
This captures the idea that the probability of a label depends on the true state of the world, the speaker's knowledge ($k$) and helpfulness ($h$). This is decomposed into two parts: (1) the speaker's belief ($b$) about the label $P(b|k,s)$, which depend on their knowledge ($k$) and the true label ($s$), and (2) the speaker's probability of producing a label that matches their belief, which depends on their helpfulness ($h$). Using this model, @shafto2012epistemic were able to capture several qualitative behavioral findings from the selective trust literature, including children's demonstrated preference for accurate over inaccurate speakers. While the precise mathmetical details of the model are less important, the key takeaway is that the same modeling approach -- reasoning about the geneartive process of others' behavior -- is able to account for children's behavior both when they get an answer and have to update beliefs but also prior to receiving an answer when children are making decisions about whom to seek information from.

One important consequence of the ideas discussed in this section is that features of the individuals who are present in a social learning context have the capacity to change whether information seeking occurs at all. That is, if a child is surrounded by a context that is unlikely to provide good answers, then generating an information-seeking behavior, even if the action has the potential to return good information, becomes less useful. Thus, an important challenge for the self-directed learner is to figure out whether answers are likely to occur. However, this is currently a less-developed area of research, and as a result we know little about how the expected usefulness of an answer might make the cost of generating high expected utility information seeking behaviors less useful. The dual consideration of costs and benefits has been the focuse of recent work in active machine learning [@haertel2008return] and in other areas of developmental psychology [@jara2015children]. It would be interesting to merge these cost-based approaches with ideas from social learning theory to increase our understanding of how social contexts can also modify the costs of different behaviors.

## Stopping rules

When should we stop collecting information and make a decision? A stopping rule describes an information or time-based threshold that if crossed causes people to end information seeking and generate a behavior. The concept draws on ideas from probability theory that have been used to model how random variables change as a function of time. For example, when conducting research for writing a paper, a student might generate the time-based stopping rule: read for two hours and then start writing. The goal of an efficient learner is to figure out a stopping rule that maximizes the chance of achieving a learning goal while reducing the amount of extra time or effort put into the task.

Studies of children's information seeking have largely focused on measuring whether children presist in seeking information if their initial request is not met. For example, @frazier2009preschoolers analyzed parent-child question-answer exchanges from the CHILDES database to see if children show evidence of seeking causal explanations when they ask *how* and *why* questions. To address this hypothesis, @frazier2009preschoolers measured the probability of children re-asking the same question and the probaility of asking a different, follow-up question after receiving either an explanatory response (e.g., CHILD: "Why you put yogurt in there?" ADULT: "Yogurt's part of the ingredients") or a non-explanatory response (e.g., CHILD: "How do you get sick?" ADULT: "I don't know."). Children were more than twice as likely to re-ask a question after getting a non-explantory answer (24%) compared to an explantory answer (9.4%), providing evidence that they continued to collect information until their inquiry goal was satisfied.  

Converging evidence that children persist in collecting information comes from @deborah2004children's work exploring children's intended meaning when they ask "What is it?" about objects. Children's propensity for asking follow-up questions was measured after children were given a name or a functional explanation in response to their ambiguous requests (e.g., "What is it?" Or "What's this?"). Parallel to @frazier2009preschoolers findings, 2- to 4-year-olds asked more follow-up questions when adults provided an object label. Children were also more likely to change the form of their initially ambiguous questions to more specifically target functional explanations. 

Thus, there is evidence that young children are sensitive to when they have gathered sufficient information to address there questions. In the majority of this work, the social context influenced children's stopping decisions by giving them the information they were searching for. However, this is not the only pathway through which the social learning context can influence stopping decisions. In fact, a recent body of research has tested the effects of adults' demonstrations of pedagogy on children's decisions about whether to persist in exploratory behavior within novel learning contexts. For example, @bonawitz2011double showed that preschoolers will spend less time exploring an object and are thus less likely to discover alternative object-functions after an adult explicitly demonstrated a single function [@bonawitz2011double]. The explanation for this effect is similar to the pedagogical inference work reviewed in the "Answers" section: that a demonstration from a knowledgeable teacher provides evidence for that function and against the existence of other functions; otherwise, a helpful teacher would have demonstrated the other functions as well. We can consture this finding in the language of stopping rules, the social context is communicating that there is less information to learned and children are adopting a lower threshold for terminating their search.

It is not the case that information learned in social contexts always reduced information search. In fact, evidence for the opposite pattern -- i.e., a pedagogical demonstration leading to an increase in subsequent exploration -- comes from work by @butler2012preschoolers on children's inductive inferences. In this study, preschoolers were presented with an unfamiliar object and shown a novel causal property (e.g., that the object could magnetically pick up paper clips) using either a pedagogical ("Look, watch this!") or an accidental ("Oops!") demonstration. Children were then given the opportunity to play with a set of identical looking objects that did not have the magnetic property to see if how they would react to the negative evidence linking the objects to the underlying causal property. @butler2012preschoolers found that, after a pedagogical demonstration, children spent more than twice as much time exploring the objects and generated three times as many attempts to make the objects pick up the paper clips. Put another way, the strength of evidence in the pedagogical condition led children to increase their information gathering threshold in the face of new, negative evidence. 

The opposite effect of pedagogy on children's stopping rules across these two studies might seem like a puzzle. However, they are both driven by the power of socially transmitted information to be more informative and lead to stronger inferences. In the causal learning case, the stronger inference about the lack of alternative object-functions results in less exploration, but in the inductive inference case, the stronger inference about the generalizability of the causal property results in more exploration. These findings also highlight an important distinction within the social learning effects: that information seeking decisions can be altered by features of the immediate social context and by the way information was acquired from previous social interactions.

Exploring the factors that influence children's decisions to stop gathering information is a promising area for future research. TOD (talk about work with adults -- Juni/time horizon stuff/naive utility calculus)

# Conclusions

The goal of this paper has been to suggest a way to integrate key ideas from two influential theories of cognitive development: active and social learning. Social learning theories emphasize the importance of learning from rich social input that is tuned to the cognitive capacities of the learner and likely to contain information that generalizes to other contexts. In contrast, Active learning accounts emphasize children's powerful self-directed learning skills, arguing that children are capable of generating and efficiently testing a broad range of hypotheses akin to the process of formal scientific inquiry. 

I reviewed a formal model of human inquiry developed from ideas based on Optimal Experiment Design (OED) in statistics. The OED approach has been a useful tool for designing the best experiments to tease apart different scientific hypotheses. It has also provided a successful account of human information seeking behaviors across a wide range of  domains (e.g., causal learning, categorization, spatial learning, and visual search) and behaviors from verbal questions to eye movements. Moreover, the OED framework provides a useful decomposition of the information seeking process into the following core model components -- goals, hypotheses, questions, and answers -- and factors that are equally important but exist outside the immediate decision making calculus, such as stopping rules. Finally, I used the OED decomposition to bring social learning effects into contact with active learning theory. I argued that the social context can influence children's active learning by (1) communicating or triggering goals, (2) constraining the hypothesis space, (3) serving as a model for useful questions, (4) providing useful, generalizable answers, and (5) modulating when children decide to stop collecting information. 

The heart of the proposal is that both social and active learning theories have much to be gained from considering the other. For example, social learning research can enrich active learning researchers' understanding of the cost-benefit calculus that learners consider during real world learning that is characterized by social interaction. On the other hand, researchers interested in the effects of social contexts can benefit from active learning research by drawing on advances in the fields of machine learning, decision theory, and statistics in order to contineu buidling a formal framework to understand social learning phenomena. Practically, we need to move beyond studying active learning in the absence of a social context and treating learners as moving back and forth between states of active and pssive learning. While this integrative approach will adds complexity to our experiments and models, the benefit will be a far greater capacity to predict how learning will unfold in the real world, which often consist of rich mixtures of active and social input.  

\newpage

# References

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = 'refs'></div>

\newpage

# Appendix

\setlength{\parindent}{0in}
\setlength{\leftskip}{0in}

R code to implement the worked example of OED presented in Part 3. First, we define some functions to make the computation of conditional probability, entropy, and information gain easier.

```{r, echo = T}
# bayes rule to compute conditional probability
compute_bayes <- function(prior_a, 
                          prior_b, 
                          likelihood) {
  (prior_a * likelihood) / prior_b
}

# entropy functions
compute_symbol_ent <- function(probability) {
  if(probability == 0) {
    0
  } else {
    (probability * log2(probability)) * -1  
  }
}

compute_entropy <- function(probability_vector) {
  sapply(probability_vector, compute_symbol_ent) %>% 
    sum() %>% 
    round(digits = 2)
}

# compute intormation gain of a single answer
compute_utility_answer <- function(prior_entropy, 
                                   posterior_entropy) {
  prior_entropy - posterior_entropy %>% 
    round(digits = 2)
}

# compute intormation gain of a question
compute_utility_question <- function(prior_entropy, 
                                     utility_answers, 
                                     probability_answers) {
  posterior_entropy <- (utility_answers * probability_answers) %>% 
    sum() %>% 
    round(digits = 2)
  prior_entropy - posterior_entropy
}
```

Next, we instantiate our prior knowledge of the world as global variables that will get passed to the expected utility functions.

```{r, echo = T}
# prior probabilities of species
prior_prob_glom <- 0.7
prior_prob_fizo <- 1 - prior_prob_glom

# conditional probabilities of features for each species
prob_meat_glom <- 0.1
prob_meat_fizo <- 0.9
prob_nocturnal_glom <- 0.3
prob_nocturnal_fizo <- 0.5
```

\noindent
Next, we use Bayes rule to compute how much our beliefs would change if we saw evidence of eating meat. To do 

$$
\begin{aligned}
P(glom \mid eatsMeat) &= \frac{P(eatsMeat \mid glom)P(glom)}{P(eatsMeat)},\\
where,\\
P(eatsMeat) &= [P(eatsMeat \mid glom)P(glom)] + [P(eatsMeat \mid fizo)P(fizo)]
\end{aligned}
$$

\noindent
In R code, we compute the prior probability of the presence and absence of the "eats meat" feature as:

```{r, echo = T}
# compute probability of the presence of eating meat
prob_meat <- (prob_meat_glom * prior_prob_glom) + 
  (prob_meat_fizo * prior_prob_fizo)

# compute probability of the absence of eating meat
prob_notMeat <- 1 - prob_meat
```

\noindent
Next, we use Bayes rule to compute the change in beliefs about species if we observed the creature eating meat.

```{r, echo = T}
# use bayes rule to compute conditional probability that glom 
# given that eats meat answer is yes
cond_prob_glom_meat <- compute_bayes(prior_a = prior_prob_glom, 
                                     prior_b = prob_meat, 
                                     likelihood = prob_meat_glom)

# use bayes rule to compute conditional probability that fizo 
# given that eats meat answer is yes
cond_prob_fizo_meat <- compute_bayes(prior_a = prior_prob_fizo, 
                                     prior_b = prob_meat, 
                                     likelihood = prob_meat_fizo)
```

\noindent
Next, we compute the expected utility of getting a specific answer ($U(eatsMeat = yes)$). Recall that we define an answer's utility as it's information gain, which is a function of the prior and posterior entropy.

```{r, echo = T}
# compute prior and posterior entropy
prior_entropy <- compute_entropy(c(prior_prob_fizo, 
                                   prior_prob_glom))

posterior_entropy <- compute_entropy(c(cond_prob_fizo_meat, 
                                       cond_prob_glom_meat))

# compute information gain
utility_yes_meat <- compute_utility_answer(prior_entropy, 
                                           posterior_entropy)
```

\noindent
Next, we apply the same procedure to get the utility of the answer "no" for the "eats meat?" question ($U(eatsMeat = no)$).

```{r, echo = T}
# use bayes rule to compute conditional probability that glom 
# given that eats meat answer is no
cond_prob_glom_notMeat <- compute_bayes(prior_a = prior_prob_glom, 
                                        prior_b = 1 - prob_meat, 
                                        likelihood = 1 - prob_meat_glom)

# use bayes rule to compute conditional probability that fizo 
# given that eats meat answer is no
cond_prob_fizo_notMeat <- compute_bayes(prior_a = prior_prob_fizo, 
                                        prior_b = 1 - prob_meat, 
                                        likelihood = 1 - prob_meat_fizo)

# compute prior and posterior entropy
prior_entropy <- compute_entropy(probability_vector = c(prior_prob_fizo, 
                                                        prior_prob_glom))

posterior_entropy <- compute_entropy(probability_vector = c(cond_prob_fizo_notMeat, 
                                                            cond_prob_glom_notMeat))

# compute information gain for the answer
utility_no_meat <- compute_utility_answer(prior_entropy, posterior_entropy)
```

\noindent
Finally, to compute the overall expected utility of the "eats meat?" question ($EU(Q)$), we weight the utility of each answer by the prior probability of getting that answer.

```{r, echo = T}
utility_meat_q <- compute_utility_question(prior_entropy,
                                           c(utility_yes_meat, utility_no_meat),
                                           c(prob_meat, 1 - prob_meat))

paste0("The expected utility of the eats meat question is: ", utility_meat_q)
```